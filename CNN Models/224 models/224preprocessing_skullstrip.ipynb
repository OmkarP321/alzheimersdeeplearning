{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fedb60f312154e749c541a2cec1fa6f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2294.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "815b779ce7bf49f2bfcf8e8415d61077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1181.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torchio\n",
    "from torchio import AFFINE, DATA, PATH, TYPE, STEM\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from torchvision import transforms, datasets, models\n",
    "from train import train_model, train_loss, train_accuracy, val_loss, val_accuracy\n",
    "from torchsummary import summary\n",
    "import time\n",
    "import copy\n",
    "import enum\n",
    "import random; random.seed(42)\n",
    "import warnings\n",
    "import tempfile\n",
    "import subprocess\n",
    "import multiprocessing\n",
    "from pathlib import Path\n",
    "import nibabel as nib\n",
    "from unet import UNet\n",
    "from scipy import stats\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import sys\n",
    "from deepbrain import Extractor\n",
    "import cv2\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def create_paths(datapath):\n",
    "    #     Create paths to all nested images\n",
    "    imagepaths = []\n",
    "    for root, dirs, files in os.walk(datapath, topdown=False):\n",
    "        for name in files:\n",
    "            imagepaths.append(os.path.join(root, name))\n",
    "    return imagepaths\n",
    "\n",
    "def get_label(imagepath, csvpath):\n",
    "    #     Get the diagnosis label for path\n",
    "    table = pd.read_csv(csvpath)\n",
    "    idpath = imagepath.split('/')[13]\n",
    "    img_id = idpath[idpath.find('_I') + 2:-4]\n",
    "    group = table.loc[table['Image Data ID'] == int(\n",
    "        img_id)][\"Group\"].reset_index(drop=True)[0]\n",
    "    group_to_label = {'CN': 0, 'AD': 1, 'MCI': 2}\n",
    "    label = group_to_label[group]\n",
    "    return label\n",
    "\n",
    "class ADNI(Dataset):\n",
    "    def __init__(self, datapath, csvpath, labels = [0, 1, 2]):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            datapath (string): Directory with all the images.\n",
    "            csvpath (string): Path to CSV. \n",
    "            labels (list): labels to retrieve. 'CN': 0, 'AD': 1, MCI': 2\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        all_imagepaths = create_paths(datapath)[:-1]\n",
    "        self.csvpath = csvpath\n",
    "        self.imagepaths = [path for path in tqdm(all_imagepaths) if get_label(path, csvpath) in labels] \n",
    "\n",
    "    def __len__(self):\n",
    "        #         Returns the length of the dataset\n",
    "        return len(self.imagepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #         Returns a tuple of the image and its group/label\n",
    "        imgsize = 224\n",
    "\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        imagepath = self.imagepaths[idx]\n",
    "        label = get_label(imagepath, csvpath)\n",
    "        \n",
    "        #         create imgbatch with three different perspectives\n",
    "        imgbatch = []\n",
    "        \n",
    "        imgdata = nib.load(imagepath).get_fdata()\n",
    "        prob = Extractor().run(imgdata) \n",
    "        mask = prob > 0.5\n",
    "        imgdata[~mask] = 0\n",
    "         \n",
    "        imgdata1 = cv2.resize(imgdata[imgdata.shape[0]//2, :, :], (imgsize, imgsize))\n",
    "        imgdata1 = torch.from_numpy(imgdata1)\n",
    "        imgdata1 = torch.stack([imgdata1, imgdata1, imgdata1], 0)\n",
    "        imgbatch.append(imgdata1.reshape(3, imgsize, imgsize))\n",
    "        \n",
    "        imgdata2 = cv2.resize(imgdata[:, imgdata.shape[1]//2, :], (imgsize, imgsize))\n",
    "        imgdata2 = torch.from_numpy(imgdata2)\n",
    "        imgdata2 = torch.stack([imgdata2, imgdata2, imgdata2], 0)\n",
    "        imgbatch.append(imgdata2.reshape(3, imgsize, imgsize))\n",
    "        \n",
    "        imgdata3 = cv2.resize(imgdata[:, :, imgdata.shape[2]//2], (imgsize, imgsize))\n",
    "        imgdata3 = torch.from_numpy(imgdata3)\n",
    "        imgdata3 = torch.stack([imgdata3, imgdata3, imgdata3], 0)\n",
    "        imgbatch.append(imgdata3.reshape(3, imgsize, imgsize))\n",
    "        \n",
    "        sample = (imgbatch, torch.tensor(label))\n",
    "        return sample\n",
    "    \n",
    "\n",
    "datapath = r\"/media/swang/Windows/Users/swang/Downloads/ADNI1_Complete_1Yr_1.5T\"\n",
    "csvpath = r\"/media/swang/Windows/Users/swang/Downloads/ADNI1_Complete_1Yr_1.5T_7_08_2020.csv\"\n",
    "dataset = ADNI(datapath, csvpath, labels = [0,1])\n",
    "\n",
    "data = [sample for sample in tqdm(dataset)]\n",
    "torch.save(data, '224skulldataset.pt')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
