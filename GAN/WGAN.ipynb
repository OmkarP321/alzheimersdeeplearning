{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset = torch.load(\"../normalizeddataset.pt\")\n",
    "\n",
    "\n",
    "lengths = [\n",
    "    int(len(dataset) * 0.8),\n",
    "    int(len(dataset) * 0.1),\n",
    "    int(len(dataset) * 0.1) + 1\n",
    "]\n",
    "\n",
    "# trainset, valset, testset = random_split(dataset, lengths)\n",
    "# image_datasets = {'train': trainset, 'val': valset, 'test': testset}\n",
    "# dataloaders = {x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "#               for x in ['train', 'val', 'test']}\n",
    "# dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val', 'test']}  \n",
    "\n",
    "\n",
    "NC = []\n",
    "AD = []\n",
    "for data in dataset:\n",
    "    if data[1] == 0:\n",
    "        NC.append(data)\n",
    "    else:\n",
    "        AD.append(data)\n",
    "        \n",
    "NC = [sample[0] for sample in NC]\n",
    "NCgan1 = [torch.unsqueeze(sample[0][0], 0) for sample in NC]\n",
    "NCgan2 = [torch.unsqueeze(sample[1][0], 0) for sample in NC]\n",
    "NCgan3 = [torch.unsqueeze(sample[2][0], 0) for sample in NC]\n",
    "\n",
    "batch_size = 16\n",
    "dataloader1 = DataLoader(NCgan1[:-1], batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "dataloader2 = DataLoader(NCgan2[:-1], batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "dataloader3 = DataLoader(NCgan3[:-1], batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "n_epochs = 200\n",
    "lr=0.00005\n",
    "n_cpu = 8\n",
    "latent_dim = 100\n",
    "img_size = 64\n",
    "channels = 1\n",
    "n_critic = 2\n",
    "clip_value = 0.01\n",
    "sample_interval = 400\n",
    "\n",
    "\n",
    "img_shape = (channels, img_size, img_size)\n",
    "\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.shape[0], *img_shape)\n",
    "        return img\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.shape[0], -1)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity\n",
    "\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.RMSprop(generator.parameters(), lr=lr)\n",
    "optimizer_D = torch.optim.RMSprop(discriminator.parameters(), lr=lr)\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/200] [Batch 0/44] [D loss: -0.048885] [G loss: -0.010611]\n",
      "[Epoch 0/200] [Batch 2/44] [D loss: 0.002292] [G loss: -0.010627]\n",
      "[Epoch 0/200] [Batch 4/44] [D loss: 0.005499] [G loss: -0.010612]\n",
      "[Epoch 0/200] [Batch 6/44] [D loss: 0.006127] [G loss: -0.010639]\n",
      "[Epoch 0/200] [Batch 8/44] [D loss: 0.006159] [G loss: -0.010632]\n",
      "[Epoch 0/200] [Batch 10/44] [D loss: 0.005807] [G loss: -0.010619]\n",
      "[Epoch 0/200] [Batch 12/44] [D loss: 0.004198] [G loss: -0.010611]\n",
      "[Epoch 0/200] [Batch 14/44] [D loss: 0.006733] [G loss: -0.010595]\n",
      "[Epoch 0/200] [Batch 16/44] [D loss: 0.006999] [G loss: -0.010603]\n",
      "[Epoch 0/200] [Batch 18/44] [D loss: 0.005503] [G loss: -0.010629]\n",
      "[Epoch 0/200] [Batch 20/44] [D loss: 0.005787] [G loss: -0.010607]\n",
      "[Epoch 0/200] [Batch 22/44] [D loss: 0.007644] [G loss: -0.010623]\n",
      "[Epoch 0/200] [Batch 24/44] [D loss: 0.005483] [G loss: -0.010629]\n",
      "[Epoch 0/200] [Batch 26/44] [D loss: 0.006771] [G loss: -0.010637]\n",
      "[Epoch 0/200] [Batch 28/44] [D loss: 0.007565] [G loss: -0.010610]\n",
      "[Epoch 0/200] [Batch 30/44] [D loss: 0.004283] [G loss: -0.010615]\n",
      "[Epoch 0/200] [Batch 32/44] [D loss: 0.007328] [G loss: -0.010621]\n",
      "[Epoch 0/200] [Batch 34/44] [D loss: 0.002988] [G loss: -0.010604]\n",
      "[Epoch 0/200] [Batch 36/44] [D loss: 0.004807] [G loss: -0.010629]\n",
      "[Epoch 0/200] [Batch 38/44] [D loss: 0.005943] [G loss: -0.010625]\n",
      "[Epoch 0/200] [Batch 40/44] [D loss: 0.005926] [G loss: -0.010634]\n",
      "[Epoch 0/200] [Batch 42/44] [D loss: 0.005225] [G loss: -0.010605]\n",
      "[Epoch 1/200] [Batch 0/44] [D loss: 0.004614] [G loss: -0.010624]\n",
      "[Epoch 1/200] [Batch 2/44] [D loss: 0.005749] [G loss: -0.010619]\n",
      "[Epoch 1/200] [Batch 4/44] [D loss: 0.006238] [G loss: -0.010610]\n",
      "[Epoch 1/200] [Batch 6/44] [D loss: 0.007730] [G loss: -0.010620]\n",
      "[Epoch 1/200] [Batch 8/44] [D loss: 0.004378] [G loss: -0.010630]\n",
      "[Epoch 1/200] [Batch 10/44] [D loss: 0.007411] [G loss: -0.010614]\n",
      "[Epoch 1/200] [Batch 12/44] [D loss: 0.005406] [G loss: -0.010619]\n",
      "[Epoch 1/200] [Batch 14/44] [D loss: 0.007679] [G loss: -0.010603]\n",
      "[Epoch 1/200] [Batch 16/44] [D loss: 0.006022] [G loss: -0.010606]\n",
      "[Epoch 1/200] [Batch 18/44] [D loss: 0.006206] [G loss: -0.010624]\n",
      "[Epoch 1/200] [Batch 20/44] [D loss: 0.004239] [G loss: -0.010631]\n",
      "[Epoch 1/200] [Batch 22/44] [D loss: 0.004537] [G loss: -0.010622]\n",
      "[Epoch 1/200] [Batch 24/44] [D loss: 0.005663] [G loss: -0.010618]\n",
      "[Epoch 1/200] [Batch 26/44] [D loss: 0.005344] [G loss: -0.010638]\n",
      "[Epoch 1/200] [Batch 28/44] [D loss: 0.006881] [G loss: -0.010632]\n",
      "[Epoch 1/200] [Batch 30/44] [D loss: 0.005928] [G loss: -0.010606]\n",
      "[Epoch 1/200] [Batch 32/44] [D loss: 0.004720] [G loss: -0.010612]\n",
      "[Epoch 1/200] [Batch 34/44] [D loss: 0.006885] [G loss: -0.010604]\n",
      "[Epoch 1/200] [Batch 36/44] [D loss: 0.005004] [G loss: -0.010615]\n",
      "[Epoch 1/200] [Batch 38/44] [D loss: 0.003621] [G loss: -0.010612]\n",
      "[Epoch 1/200] [Batch 40/44] [D loss: 0.005181] [G loss: -0.010619]\n",
      "[Epoch 1/200] [Batch 42/44] [D loss: 0.005290] [G loss: -0.010605]\n",
      "[Epoch 2/200] [Batch 0/44] [D loss: 0.003857] [G loss: -0.010606]\n",
      "[Epoch 2/200] [Batch 2/44] [D loss: 0.006151] [G loss: -0.010602]\n",
      "[Epoch 2/200] [Batch 4/44] [D loss: 0.004706] [G loss: -0.010611]\n",
      "[Epoch 2/200] [Batch 6/44] [D loss: 0.006589] [G loss: -0.010613]\n",
      "[Epoch 2/200] [Batch 8/44] [D loss: 0.004756] [G loss: -0.010630]\n",
      "[Epoch 2/200] [Batch 10/44] [D loss: 0.003425] [G loss: -0.010612]\n",
      "[Epoch 2/200] [Batch 12/44] [D loss: 0.003457] [G loss: -0.010593]\n",
      "[Epoch 2/200] [Batch 14/44] [D loss: 0.006925] [G loss: -0.010632]\n",
      "[Epoch 2/200] [Batch 16/44] [D loss: 0.006308] [G loss: -0.010620]\n",
      "[Epoch 2/200] [Batch 18/44] [D loss: 0.005516] [G loss: -0.010606]\n",
      "[Epoch 2/200] [Batch 20/44] [D loss: 0.006445] [G loss: -0.010628]\n",
      "[Epoch 2/200] [Batch 22/44] [D loss: 0.006312] [G loss: -0.010606]\n",
      "[Epoch 2/200] [Batch 24/44] [D loss: 0.005499] [G loss: -0.010599]\n",
      "[Epoch 2/200] [Batch 26/44] [D loss: 0.005162] [G loss: -0.010628]\n",
      "[Epoch 2/200] [Batch 28/44] [D loss: 0.006860] [G loss: -0.010617]\n",
      "[Epoch 2/200] [Batch 30/44] [D loss: 0.004629] [G loss: -0.010616]\n",
      "[Epoch 2/200] [Batch 32/44] [D loss: 0.004405] [G loss: -0.010610]\n",
      "[Epoch 2/200] [Batch 34/44] [D loss: 0.007583] [G loss: -0.010595]\n",
      "[Epoch 2/200] [Batch 36/44] [D loss: 0.005119] [G loss: -0.010607]\n",
      "[Epoch 2/200] [Batch 38/44] [D loss: 0.007910] [G loss: -0.010604]\n",
      "[Epoch 2/200] [Batch 40/44] [D loss: 0.006657] [G loss: -0.010613]\n",
      "[Epoch 2/200] [Batch 42/44] [D loss: 0.005435] [G loss: -0.010611]\n",
      "[Epoch 3/200] [Batch 0/44] [D loss: 0.005099] [G loss: -0.010611]\n",
      "[Epoch 3/200] [Batch 2/44] [D loss: 0.004498] [G loss: -0.010606]\n",
      "[Epoch 3/200] [Batch 4/44] [D loss: 0.004057] [G loss: -0.010620]\n",
      "[Epoch 3/200] [Batch 6/44] [D loss: 0.006801] [G loss: -0.010611]\n",
      "[Epoch 3/200] [Batch 8/44] [D loss: 0.005459] [G loss: -0.010575]\n",
      "[Epoch 3/200] [Batch 10/44] [D loss: 0.005260] [G loss: -0.010629]\n",
      "[Epoch 3/200] [Batch 12/44] [D loss: 0.004613] [G loss: -0.010623]\n",
      "[Epoch 3/200] [Batch 14/44] [D loss: 0.003993] [G loss: -0.010630]\n",
      "[Epoch 3/200] [Batch 16/44] [D loss: 0.007145] [G loss: -0.010626]\n",
      "[Epoch 3/200] [Batch 18/44] [D loss: 0.006492] [G loss: -0.010625]\n",
      "[Epoch 3/200] [Batch 20/44] [D loss: 0.005901] [G loss: -0.010619]\n",
      "[Epoch 3/200] [Batch 22/44] [D loss: 0.006607] [G loss: -0.010632]\n",
      "[Epoch 3/200] [Batch 24/44] [D loss: 0.005048] [G loss: -0.010631]\n",
      "[Epoch 3/200] [Batch 26/44] [D loss: 0.005681] [G loss: -0.010601]\n",
      "[Epoch 3/200] [Batch 28/44] [D loss: 0.005017] [G loss: -0.010635]\n",
      "[Epoch 3/200] [Batch 30/44] [D loss: 0.006305] [G loss: -0.010629]\n",
      "[Epoch 3/200] [Batch 32/44] [D loss: 0.004267] [G loss: -0.010607]\n",
      "[Epoch 3/200] [Batch 34/44] [D loss: 0.004836] [G loss: -0.010605]\n",
      "[Epoch 3/200] [Batch 36/44] [D loss: 0.007912] [G loss: -0.010618]\n",
      "[Epoch 3/200] [Batch 38/44] [D loss: 0.007150] [G loss: -0.010573]\n",
      "[Epoch 3/200] [Batch 40/44] [D loss: 0.006780] [G loss: -0.010622]\n",
      "[Epoch 3/200] [Batch 42/44] [D loss: 0.005012] [G loss: -0.010598]\n",
      "[Epoch 4/200] [Batch 0/44] [D loss: 0.004895] [G loss: -0.010605]\n",
      "[Epoch 4/200] [Batch 2/44] [D loss: 0.005772] [G loss: -0.010643]\n",
      "[Epoch 4/200] [Batch 4/44] [D loss: 0.007430] [G loss: -0.010634]\n",
      "[Epoch 4/200] [Batch 6/44] [D loss: 0.004901] [G loss: -0.010625]\n",
      "[Epoch 4/200] [Batch 8/44] [D loss: 0.006299] [G loss: -0.010613]\n",
      "[Epoch 4/200] [Batch 10/44] [D loss: 0.005905] [G loss: -0.010616]\n",
      "[Epoch 4/200] [Batch 12/44] [D loss: 0.005828] [G loss: -0.010610]\n",
      "[Epoch 4/200] [Batch 14/44] [D loss: 0.004726] [G loss: -0.010632]\n",
      "[Epoch 4/200] [Batch 16/44] [D loss: 0.006282] [G loss: -0.010615]\n",
      "[Epoch 4/200] [Batch 18/44] [D loss: 0.003118] [G loss: -0.010635]\n",
      "[Epoch 4/200] [Batch 20/44] [D loss: 0.004064] [G loss: -0.010628]\n",
      "[Epoch 4/200] [Batch 22/44] [D loss: 0.006385] [G loss: -0.010616]\n",
      "[Epoch 4/200] [Batch 24/44] [D loss: 0.006439] [G loss: -0.010618]\n",
      "[Epoch 4/200] [Batch 26/44] [D loss: 0.006053] [G loss: -0.010607]\n",
      "[Epoch 4/200] [Batch 28/44] [D loss: 0.005529] [G loss: -0.010612]\n",
      "[Epoch 4/200] [Batch 30/44] [D loss: 0.008250] [G loss: -0.010607]\n",
      "[Epoch 4/200] [Batch 32/44] [D loss: 0.004234] [G loss: -0.010622]\n",
      "[Epoch 4/200] [Batch 34/44] [D loss: 0.006423] [G loss: -0.010618]\n",
      "[Epoch 4/200] [Batch 36/44] [D loss: 0.004170] [G loss: -0.010603]\n",
      "[Epoch 4/200] [Batch 38/44] [D loss: 0.004773] [G loss: -0.010601]\n",
      "[Epoch 4/200] [Batch 40/44] [D loss: 0.005313] [G loss: -0.010609]\n",
      "[Epoch 4/200] [Batch 42/44] [D loss: 0.005452] [G loss: -0.010618]\n",
      "[Epoch 5/200] [Batch 0/44] [D loss: 0.007028] [G loss: -0.010630]\n",
      "[Epoch 5/200] [Batch 2/44] [D loss: 0.005026] [G loss: -0.010635]\n",
      "[Epoch 5/200] [Batch 4/44] [D loss: 0.005016] [G loss: -0.010620]\n",
      "[Epoch 5/200] [Batch 6/44] [D loss: 0.005054] [G loss: -0.010618]\n",
      "[Epoch 5/200] [Batch 8/44] [D loss: 0.004726] [G loss: -0.010632]\n",
      "[Epoch 5/200] [Batch 10/44] [D loss: 0.006529] [G loss: -0.010627]\n",
      "[Epoch 5/200] [Batch 12/44] [D loss: 0.005294] [G loss: -0.010614]\n",
      "[Epoch 5/200] [Batch 14/44] [D loss: 0.003994] [G loss: -0.010624]\n",
      "[Epoch 5/200] [Batch 16/44] [D loss: 0.005470] [G loss: -0.010635]\n",
      "[Epoch 5/200] [Batch 18/44] [D loss: 0.005878] [G loss: -0.010624]\n",
      "[Epoch 5/200] [Batch 20/44] [D loss: 0.006340] [G loss: -0.010616]\n",
      "[Epoch 5/200] [Batch 22/44] [D loss: 0.005103] [G loss: -0.010605]\n",
      "[Epoch 5/200] [Batch 24/44] [D loss: 0.004523] [G loss: -0.010628]\n",
      "[Epoch 5/200] [Batch 26/44] [D loss: 0.005703] [G loss: -0.010640]\n",
      "[Epoch 5/200] [Batch 28/44] [D loss: 0.006032] [G loss: -0.010621]\n",
      "[Epoch 5/200] [Batch 30/44] [D loss: 0.006860] [G loss: -0.010626]\n",
      "[Epoch 5/200] [Batch 32/44] [D loss: 0.007317] [G loss: -0.010599]\n",
      "[Epoch 5/200] [Batch 34/44] [D loss: 0.004689] [G loss: -0.010601]\n",
      "[Epoch 5/200] [Batch 36/44] [D loss: 0.005988] [G loss: -0.010630]\n",
      "[Epoch 5/200] [Batch 38/44] [D loss: 0.006360] [G loss: -0.010625]\n",
      "[Epoch 5/200] [Batch 40/44] [D loss: 0.005898] [G loss: -0.010616]\n",
      "[Epoch 5/200] [Batch 42/44] [D loss: 0.005030] [G loss: -0.010629]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 6/200] [Batch 0/44] [D loss: 0.005604] [G loss: -0.010607]\n",
      "[Epoch 6/200] [Batch 2/44] [D loss: 0.006089] [G loss: -0.010610]\n",
      "[Epoch 6/200] [Batch 4/44] [D loss: 0.005433] [G loss: -0.010611]\n",
      "[Epoch 6/200] [Batch 6/44] [D loss: 0.007245] [G loss: -0.010622]\n",
      "[Epoch 6/200] [Batch 8/44] [D loss: 0.005840] [G loss: -0.010610]\n",
      "[Epoch 6/200] [Batch 10/44] [D loss: 0.005014] [G loss: -0.010588]\n",
      "[Epoch 6/200] [Batch 12/44] [D loss: 0.007845] [G loss: -0.010618]\n",
      "[Epoch 6/200] [Batch 14/44] [D loss: 0.004329] [G loss: -0.010608]\n",
      "[Epoch 6/200] [Batch 16/44] [D loss: 0.005105] [G loss: -0.010629]\n",
      "[Epoch 6/200] [Batch 18/44] [D loss: 0.001555] [G loss: -0.010642]\n",
      "[Epoch 6/200] [Batch 20/44] [D loss: 0.005170] [G loss: -0.010615]\n",
      "[Epoch 6/200] [Batch 22/44] [D loss: 0.007566] [G loss: -0.010602]\n",
      "[Epoch 6/200] [Batch 24/44] [D loss: 0.005506] [G loss: -0.010623]\n",
      "[Epoch 6/200] [Batch 26/44] [D loss: 0.006543] [G loss: -0.010632]\n",
      "[Epoch 6/200] [Batch 28/44] [D loss: 0.005860] [G loss: -0.010600]\n",
      "[Epoch 6/200] [Batch 30/44] [D loss: 0.006425] [G loss: -0.010602]\n",
      "[Epoch 6/200] [Batch 32/44] [D loss: 0.005167] [G loss: -0.010631]\n",
      "[Epoch 6/200] [Batch 34/44] [D loss: 0.004894] [G loss: -0.010628]\n",
      "[Epoch 6/200] [Batch 36/44] [D loss: 0.005008] [G loss: -0.010628]\n",
      "[Epoch 6/200] [Batch 38/44] [D loss: 0.004590] [G loss: -0.010626]\n",
      "[Epoch 6/200] [Batch 40/44] [D loss: 0.005795] [G loss: -0.010628]\n",
      "[Epoch 6/200] [Batch 42/44] [D loss: 0.004075] [G loss: -0.010604]\n",
      "[Epoch 7/200] [Batch 0/44] [D loss: 0.006210] [G loss: -0.010617]\n",
      "[Epoch 7/200] [Batch 2/44] [D loss: 0.003707] [G loss: -0.010613]\n",
      "[Epoch 7/200] [Batch 4/44] [D loss: 0.004868] [G loss: -0.010616]\n",
      "[Epoch 7/200] [Batch 6/44] [D loss: 0.004429] [G loss: -0.010612]\n",
      "[Epoch 7/200] [Batch 8/44] [D loss: 0.005989] [G loss: -0.010608]\n",
      "[Epoch 7/200] [Batch 10/44] [D loss: 0.004257] [G loss: -0.010618]\n",
      "[Epoch 7/200] [Batch 12/44] [D loss: 0.005242] [G loss: -0.010609]\n",
      "[Epoch 7/200] [Batch 14/44] [D loss: 0.004173] [G loss: -0.010622]\n",
      "[Epoch 7/200] [Batch 16/44] [D loss: 0.005770] [G loss: -0.010617]\n",
      "[Epoch 7/200] [Batch 18/44] [D loss: 0.004817] [G loss: -0.010608]\n",
      "[Epoch 7/200] [Batch 20/44] [D loss: 0.005043] [G loss: -0.010611]\n",
      "[Epoch 7/200] [Batch 22/44] [D loss: 0.005126] [G loss: -0.010626]\n",
      "[Epoch 7/200] [Batch 24/44] [D loss: 0.007135] [G loss: -0.010613]\n",
      "[Epoch 7/200] [Batch 26/44] [D loss: 0.005317] [G loss: -0.010600]\n",
      "[Epoch 7/200] [Batch 28/44] [D loss: 0.005464] [G loss: -0.010621]\n",
      "[Epoch 7/200] [Batch 30/44] [D loss: 0.005929] [G loss: -0.010631]\n",
      "[Epoch 7/200] [Batch 32/44] [D loss: 0.005997] [G loss: -0.010624]\n",
      "[Epoch 7/200] [Batch 34/44] [D loss: 0.005529] [G loss: -0.010625]\n",
      "[Epoch 7/200] [Batch 36/44] [D loss: 0.006315] [G loss: -0.010610]\n",
      "[Epoch 7/200] [Batch 38/44] [D loss: 0.006355] [G loss: -0.010612]\n",
      "[Epoch 7/200] [Batch 40/44] [D loss: 0.006232] [G loss: -0.010611]\n",
      "[Epoch 7/200] [Batch 42/44] [D loss: 0.006387] [G loss: -0.010626]\n",
      "[Epoch 8/200] [Batch 0/44] [D loss: 0.006287] [G loss: -0.010612]\n",
      "[Epoch 8/200] [Batch 2/44] [D loss: 0.005405] [G loss: -0.010628]\n",
      "[Epoch 8/200] [Batch 4/44] [D loss: 0.007985] [G loss: -0.010621]\n",
      "[Epoch 8/200] [Batch 6/44] [D loss: 0.005680] [G loss: -0.010626]\n",
      "[Epoch 8/200] [Batch 8/44] [D loss: 0.006018] [G loss: -0.010604]\n",
      "[Epoch 8/200] [Batch 10/44] [D loss: 0.003546] [G loss: -0.010610]\n",
      "[Epoch 8/200] [Batch 12/44] [D loss: 0.002571] [G loss: -0.010611]\n",
      "[Epoch 8/200] [Batch 14/44] [D loss: 0.005715] [G loss: -0.010618]\n",
      "[Epoch 8/200] [Batch 16/44] [D loss: 0.006216] [G loss: -0.010592]\n",
      "[Epoch 8/200] [Batch 18/44] [D loss: 0.003720] [G loss: -0.010604]\n",
      "[Epoch 8/200] [Batch 20/44] [D loss: 0.006409] [G loss: -0.010613]\n",
      "[Epoch 8/200] [Batch 22/44] [D loss: 0.006085] [G loss: -0.010636]\n",
      "[Epoch 8/200] [Batch 24/44] [D loss: 0.006033] [G loss: -0.010622]\n",
      "[Epoch 8/200] [Batch 26/44] [D loss: 0.006413] [G loss: -0.010621]\n",
      "[Epoch 8/200] [Batch 28/44] [D loss: 0.004311] [G loss: -0.010619]\n",
      "[Epoch 8/200] [Batch 30/44] [D loss: 0.005867] [G loss: -0.010602]\n",
      "[Epoch 8/200] [Batch 32/44] [D loss: 0.005336] [G loss: -0.010621]\n",
      "[Epoch 8/200] [Batch 34/44] [D loss: 0.007055] [G loss: -0.010621]\n",
      "[Epoch 8/200] [Batch 36/44] [D loss: 0.004719] [G loss: -0.010618]\n",
      "[Epoch 8/200] [Batch 38/44] [D loss: 0.004734] [G loss: -0.010609]\n",
      "[Epoch 8/200] [Batch 40/44] [D loss: 0.005791] [G loss: -0.010625]\n",
      "[Epoch 8/200] [Batch 42/44] [D loss: 0.006891] [G loss: -0.010606]\n",
      "[Epoch 9/200] [Batch 0/44] [D loss: 0.006788] [G loss: -0.010623]\n",
      "[Epoch 9/200] [Batch 2/44] [D loss: 0.006042] [G loss: -0.010612]\n",
      "[Epoch 9/200] [Batch 4/44] [D loss: 0.008296] [G loss: -0.010612]\n",
      "[Epoch 9/200] [Batch 6/44] [D loss: 0.006363] [G loss: -0.010605]\n",
      "[Epoch 9/200] [Batch 8/44] [D loss: 0.006064] [G loss: -0.010613]\n",
      "[Epoch 9/200] [Batch 10/44] [D loss: 0.006133] [G loss: -0.010613]\n",
      "[Epoch 9/200] [Batch 12/44] [D loss: 0.004997] [G loss: -0.010644]\n",
      "[Epoch 9/200] [Batch 14/44] [D loss: 0.006180] [G loss: -0.010610]\n",
      "[Epoch 9/200] [Batch 16/44] [D loss: 0.006544] [G loss: -0.010608]\n",
      "[Epoch 9/200] [Batch 18/44] [D loss: 0.004866] [G loss: -0.010612]\n",
      "[Epoch 9/200] [Batch 20/44] [D loss: 0.005045] [G loss: -0.010606]\n",
      "[Epoch 9/200] [Batch 22/44] [D loss: 0.004444] [G loss: -0.010614]\n",
      "[Epoch 9/200] [Batch 24/44] [D loss: 0.003014] [G loss: -0.010593]\n",
      "[Epoch 9/200] [Batch 26/44] [D loss: 0.006183] [G loss: -0.010634]\n",
      "[Epoch 9/200] [Batch 28/44] [D loss: 0.007391] [G loss: -0.010598]\n",
      "[Epoch 9/200] [Batch 30/44] [D loss: 0.005264] [G loss: -0.010580]\n",
      "[Epoch 9/200] [Batch 32/44] [D loss: 0.005318] [G loss: -0.010626]\n",
      "[Epoch 9/200] [Batch 34/44] [D loss: 0.007555] [G loss: -0.010606]\n",
      "[Epoch 9/200] [Batch 36/44] [D loss: 0.006704] [G loss: -0.010631]\n",
      "[Epoch 9/200] [Batch 38/44] [D loss: 0.006834] [G loss: -0.010608]\n",
      "[Epoch 9/200] [Batch 40/44] [D loss: 0.005381] [G loss: -0.010607]\n",
      "[Epoch 9/200] [Batch 42/44] [D loss: 0.004596] [G loss: -0.010625]\n",
      "[Epoch 10/200] [Batch 0/44] [D loss: 0.003916] [G loss: -0.010598]\n",
      "[Epoch 10/200] [Batch 2/44] [D loss: 0.004084] [G loss: -0.010613]\n",
      "[Epoch 10/200] [Batch 4/44] [D loss: 0.004383] [G loss: -0.010601]\n",
      "[Epoch 10/200] [Batch 6/44] [D loss: 0.006721] [G loss: -0.010597]\n",
      "[Epoch 10/200] [Batch 8/44] [D loss: 0.006143] [G loss: -0.010622]\n",
      "[Epoch 10/200] [Batch 10/44] [D loss: 0.006807] [G loss: -0.010632]\n",
      "[Epoch 10/200] [Batch 12/44] [D loss: 0.005505] [G loss: -0.010600]\n",
      "[Epoch 10/200] [Batch 14/44] [D loss: 0.007027] [G loss: -0.010613]\n",
      "[Epoch 10/200] [Batch 16/44] [D loss: 0.005714] [G loss: -0.010625]\n",
      "[Epoch 10/200] [Batch 18/44] [D loss: 0.006113] [G loss: -0.010616]\n",
      "[Epoch 10/200] [Batch 20/44] [D loss: 0.007375] [G loss: -0.010628]\n",
      "[Epoch 10/200] [Batch 22/44] [D loss: 0.005271] [G loss: -0.010624]\n",
      "[Epoch 10/200] [Batch 24/44] [D loss: 0.005951] [G loss: -0.010644]\n",
      "[Epoch 10/200] [Batch 26/44] [D loss: 0.005436] [G loss: -0.010597]\n",
      "[Epoch 10/200] [Batch 28/44] [D loss: 0.004413] [G loss: -0.010609]\n",
      "[Epoch 10/200] [Batch 30/44] [D loss: 0.005782] [G loss: -0.010623]\n",
      "[Epoch 10/200] [Batch 32/44] [D loss: 0.004486] [G loss: -0.010605]\n",
      "[Epoch 10/200] [Batch 34/44] [D loss: 0.005281] [G loss: -0.010634]\n",
      "[Epoch 10/200] [Batch 36/44] [D loss: 0.005820] [G loss: -0.010614]\n",
      "[Epoch 10/200] [Batch 38/44] [D loss: 0.005869] [G loss: -0.010620]\n",
      "[Epoch 10/200] [Batch 40/44] [D loss: 0.006119] [G loss: -0.010617]\n",
      "[Epoch 10/200] [Batch 42/44] [D loss: 0.006308] [G loss: -0.010605]\n",
      "[Epoch 11/200] [Batch 0/44] [D loss: 0.005300] [G loss: -0.010625]\n",
      "[Epoch 11/200] [Batch 2/44] [D loss: 0.006133] [G loss: -0.010633]\n",
      "[Epoch 11/200] [Batch 4/44] [D loss: 0.006621] [G loss: -0.010624]\n",
      "[Epoch 11/200] [Batch 6/44] [D loss: 0.008118] [G loss: -0.010627]\n",
      "[Epoch 11/200] [Batch 8/44] [D loss: 0.005137] [G loss: -0.010624]\n",
      "[Epoch 11/200] [Batch 10/44] [D loss: 0.006489] [G loss: -0.010596]\n",
      "[Epoch 11/200] [Batch 12/44] [D loss: 0.004757] [G loss: -0.010609]\n",
      "[Epoch 11/200] [Batch 14/44] [D loss: 0.004692] [G loss: -0.010618]\n",
      "[Epoch 11/200] [Batch 16/44] [D loss: 0.005345] [G loss: -0.010590]\n",
      "[Epoch 11/200] [Batch 18/44] [D loss: 0.006122] [G loss: -0.010623]\n",
      "[Epoch 11/200] [Batch 20/44] [D loss: 0.006388] [G loss: -0.010605]\n",
      "[Epoch 11/200] [Batch 22/44] [D loss: 0.003908] [G loss: -0.010627]\n",
      "[Epoch 11/200] [Batch 24/44] [D loss: 0.006522] [G loss: -0.010609]\n",
      "[Epoch 11/200] [Batch 26/44] [D loss: 0.005301] [G loss: -0.010623]\n",
      "[Epoch 11/200] [Batch 28/44] [D loss: 0.005111] [G loss: -0.010605]\n",
      "[Epoch 11/200] [Batch 30/44] [D loss: 0.005354] [G loss: -0.010637]\n",
      "[Epoch 11/200] [Batch 32/44] [D loss: 0.006289] [G loss: -0.010623]\n",
      "[Epoch 11/200] [Batch 34/44] [D loss: 0.006043] [G loss: -0.010610]\n",
      "[Epoch 11/200] [Batch 36/44] [D loss: 0.007012] [G loss: -0.010613]\n",
      "[Epoch 11/200] [Batch 38/44] [D loss: 0.007117] [G loss: -0.010604]\n",
      "[Epoch 11/200] [Batch 40/44] [D loss: 0.004613] [G loss: -0.010628]\n",
      "[Epoch 11/200] [Batch 42/44] [D loss: 0.003814] [G loss: -0.010606]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12/200] [Batch 0/44] [D loss: 0.005043] [G loss: -0.010614]\n",
      "[Epoch 12/200] [Batch 2/44] [D loss: 0.007062] [G loss: -0.010619]\n",
      "[Epoch 12/200] [Batch 4/44] [D loss: 0.006681] [G loss: -0.010643]\n",
      "[Epoch 12/200] [Batch 6/44] [D loss: 0.003919] [G loss: -0.010614]\n",
      "[Epoch 12/200] [Batch 8/44] [D loss: 0.006501] [G loss: -0.010617]\n",
      "[Epoch 12/200] [Batch 10/44] [D loss: 0.006080] [G loss: -0.010604]\n",
      "[Epoch 12/200] [Batch 12/44] [D loss: 0.005281] [G loss: -0.010624]\n",
      "[Epoch 12/200] [Batch 14/44] [D loss: 0.007167] [G loss: -0.010627]\n",
      "[Epoch 12/200] [Batch 16/44] [D loss: 0.007563] [G loss: -0.010637]\n",
      "[Epoch 12/200] [Batch 18/44] [D loss: 0.004197] [G loss: -0.010631]\n",
      "[Epoch 12/200] [Batch 20/44] [D loss: 0.006491] [G loss: -0.010626]\n",
      "[Epoch 12/200] [Batch 22/44] [D loss: 0.006018] [G loss: -0.010607]\n",
      "[Epoch 12/200] [Batch 24/44] [D loss: 0.006302] [G loss: -0.010621]\n",
      "[Epoch 12/200] [Batch 26/44] [D loss: 0.004722] [G loss: -0.010588]\n",
      "[Epoch 12/200] [Batch 28/44] [D loss: 0.007040] [G loss: -0.010619]\n",
      "[Epoch 12/200] [Batch 30/44] [D loss: 0.006050] [G loss: -0.010630]\n",
      "[Epoch 12/200] [Batch 32/44] [D loss: 0.006493] [G loss: -0.010601]\n",
      "[Epoch 12/200] [Batch 34/44] [D loss: 0.005614] [G loss: -0.010630]\n",
      "[Epoch 12/200] [Batch 36/44] [D loss: 0.005874] [G loss: -0.010606]\n",
      "[Epoch 12/200] [Batch 38/44] [D loss: 0.006560] [G loss: -0.010618]\n",
      "[Epoch 12/200] [Batch 40/44] [D loss: 0.007251] [G loss: -0.010607]\n",
      "[Epoch 12/200] [Batch 42/44] [D loss: 0.007180] [G loss: -0.010628]\n",
      "[Epoch 13/200] [Batch 0/44] [D loss: 0.006293] [G loss: -0.010614]\n",
      "[Epoch 13/200] [Batch 2/44] [D loss: 0.007751] [G loss: -0.010613]\n",
      "[Epoch 13/200] [Batch 4/44] [D loss: 0.005738] [G loss: -0.010614]\n",
      "[Epoch 13/200] [Batch 6/44] [D loss: 0.003568] [G loss: -0.010622]\n",
      "[Epoch 13/200] [Batch 8/44] [D loss: 0.005953] [G loss: -0.010605]\n",
      "[Epoch 13/200] [Batch 10/44] [D loss: 0.005537] [G loss: -0.010618]\n",
      "[Epoch 13/200] [Batch 12/44] [D loss: 0.006503] [G loss: -0.010633]\n",
      "[Epoch 13/200] [Batch 14/44] [D loss: 0.006877] [G loss: -0.010605]\n",
      "[Epoch 13/200] [Batch 16/44] [D loss: 0.004572] [G loss: -0.010618]\n",
      "[Epoch 13/200] [Batch 18/44] [D loss: 0.004116] [G loss: -0.010606]\n",
      "[Epoch 13/200] [Batch 20/44] [D loss: 0.007519] [G loss: -0.010639]\n",
      "[Epoch 13/200] [Batch 22/44] [D loss: 0.007012] [G loss: -0.010621]\n",
      "[Epoch 13/200] [Batch 24/44] [D loss: 0.004810] [G loss: -0.010630]\n",
      "[Epoch 13/200] [Batch 26/44] [D loss: 0.006039] [G loss: -0.010599]\n",
      "[Epoch 13/200] [Batch 28/44] [D loss: 0.006566] [G loss: -0.010621]\n",
      "[Epoch 13/200] [Batch 30/44] [D loss: 0.005265] [G loss: -0.010625]\n",
      "[Epoch 13/200] [Batch 32/44] [D loss: 0.007123] [G loss: -0.010617]\n",
      "[Epoch 13/200] [Batch 34/44] [D loss: 0.003681] [G loss: -0.010622]\n",
      "[Epoch 13/200] [Batch 36/44] [D loss: 0.007037] [G loss: -0.010608]\n",
      "[Epoch 13/200] [Batch 38/44] [D loss: 0.005095] [G loss: -0.010626]\n",
      "[Epoch 13/200] [Batch 40/44] [D loss: 0.004589] [G loss: -0.010638]\n",
      "[Epoch 13/200] [Batch 42/44] [D loss: 0.006444] [G loss: -0.010626]\n",
      "[Epoch 14/200] [Batch 0/44] [D loss: 0.005133] [G loss: -0.010622]\n",
      "[Epoch 14/200] [Batch 2/44] [D loss: 0.003977] [G loss: -0.010625]\n",
      "[Epoch 14/200] [Batch 4/44] [D loss: 0.005144] [G loss: -0.010602]\n",
      "[Epoch 14/200] [Batch 6/44] [D loss: 0.002954] [G loss: -0.010625]\n",
      "[Epoch 14/200] [Batch 8/44] [D loss: 0.005237] [G loss: -0.010610]\n",
      "[Epoch 14/200] [Batch 10/44] [D loss: 0.005939] [G loss: -0.010610]\n",
      "[Epoch 14/200] [Batch 12/44] [D loss: 0.006520] [G loss: -0.010628]\n",
      "[Epoch 14/200] [Batch 14/44] [D loss: 0.005923] [G loss: -0.010633]\n",
      "[Epoch 14/200] [Batch 16/44] [D loss: 0.005621] [G loss: -0.010624]\n",
      "[Epoch 14/200] [Batch 18/44] [D loss: 0.006422] [G loss: -0.010634]\n",
      "[Epoch 14/200] [Batch 20/44] [D loss: 0.007606] [G loss: -0.010621]\n",
      "[Epoch 14/200] [Batch 22/44] [D loss: 0.006662] [G loss: -0.010620]\n",
      "[Epoch 14/200] [Batch 24/44] [D loss: 0.005258] [G loss: -0.010640]\n",
      "[Epoch 14/200] [Batch 26/44] [D loss: 0.004883] [G loss: -0.010608]\n",
      "[Epoch 14/200] [Batch 28/44] [D loss: 0.006447] [G loss: -0.010603]\n",
      "[Epoch 14/200] [Batch 30/44] [D loss: 0.004813] [G loss: -0.010607]\n",
      "[Epoch 14/200] [Batch 32/44] [D loss: 0.006286] [G loss: -0.010634]\n",
      "[Epoch 14/200] [Batch 34/44] [D loss: 0.005950] [G loss: -0.010622]\n",
      "[Epoch 14/200] [Batch 36/44] [D loss: 0.004882] [G loss: -0.010632]\n",
      "[Epoch 14/200] [Batch 38/44] [D loss: 0.003846] [G loss: -0.010613]\n",
      "[Epoch 14/200] [Batch 40/44] [D loss: 0.006048] [G loss: -0.010601]\n",
      "[Epoch 14/200] [Batch 42/44] [D loss: 0.005326] [G loss: -0.010617]\n",
      "[Epoch 15/200] [Batch 0/44] [D loss: 0.006732] [G loss: -0.010627]\n",
      "[Epoch 15/200] [Batch 2/44] [D loss: 0.005683] [G loss: -0.010613]\n",
      "[Epoch 15/200] [Batch 4/44] [D loss: 0.004935] [G loss: -0.010621]\n",
      "[Epoch 15/200] [Batch 6/44] [D loss: 0.004276] [G loss: -0.010610]\n",
      "[Epoch 15/200] [Batch 8/44] [D loss: 0.007253] [G loss: -0.010609]\n",
      "[Epoch 15/200] [Batch 10/44] [D loss: 0.006231] [G loss: -0.010629]\n",
      "[Epoch 15/200] [Batch 12/44] [D loss: 0.004328] [G loss: -0.010598]\n",
      "[Epoch 15/200] [Batch 14/44] [D loss: 0.006949] [G loss: -0.010609]\n",
      "[Epoch 15/200] [Batch 16/44] [D loss: 0.006798] [G loss: -0.010645]\n",
      "[Epoch 15/200] [Batch 18/44] [D loss: 0.004746] [G loss: -0.010614]\n",
      "[Epoch 15/200] [Batch 20/44] [D loss: 0.003851] [G loss: -0.010614]\n",
      "[Epoch 15/200] [Batch 22/44] [D loss: 0.006368] [G loss: -0.010622]\n",
      "[Epoch 15/200] [Batch 24/44] [D loss: 0.004081] [G loss: -0.010609]\n",
      "[Epoch 15/200] [Batch 26/44] [D loss: 0.008389] [G loss: -0.010595]\n",
      "[Epoch 15/200] [Batch 28/44] [D loss: 0.005253] [G loss: -0.010638]\n",
      "[Epoch 15/200] [Batch 30/44] [D loss: 0.006439] [G loss: -0.010624]\n",
      "[Epoch 15/200] [Batch 32/44] [D loss: 0.005482] [G loss: -0.010612]\n",
      "[Epoch 15/200] [Batch 34/44] [D loss: 0.004322] [G loss: -0.010608]\n",
      "[Epoch 15/200] [Batch 36/44] [D loss: 0.006683] [G loss: -0.010630]\n",
      "[Epoch 15/200] [Batch 38/44] [D loss: 0.006369] [G loss: -0.010624]\n",
      "[Epoch 15/200] [Batch 40/44] [D loss: 0.005762] [G loss: -0.010601]\n",
      "[Epoch 15/200] [Batch 42/44] [D loss: 0.005158] [G loss: -0.010629]\n",
      "[Epoch 16/200] [Batch 0/44] [D loss: 0.005039] [G loss: -0.010616]\n",
      "[Epoch 16/200] [Batch 2/44] [D loss: 0.006280] [G loss: -0.010617]\n",
      "[Epoch 16/200] [Batch 4/44] [D loss: 0.005265] [G loss: -0.010628]\n",
      "[Epoch 16/200] [Batch 6/44] [D loss: 0.005942] [G loss: -0.010617]\n",
      "[Epoch 16/200] [Batch 8/44] [D loss: 0.004197] [G loss: -0.010633]\n",
      "[Epoch 16/200] [Batch 10/44] [D loss: 0.004913] [G loss: -0.010627]\n",
      "[Epoch 16/200] [Batch 12/44] [D loss: 0.004291] [G loss: -0.010605]\n",
      "[Epoch 16/200] [Batch 14/44] [D loss: 0.007125] [G loss: -0.010634]\n",
      "[Epoch 16/200] [Batch 16/44] [D loss: 0.006253] [G loss: -0.010613]\n",
      "[Epoch 16/200] [Batch 18/44] [D loss: 0.005793] [G loss: -0.010611]\n",
      "[Epoch 16/200] [Batch 20/44] [D loss: 0.004082] [G loss: -0.010597]\n",
      "[Epoch 16/200] [Batch 22/44] [D loss: 0.005217] [G loss: -0.010614]\n",
      "[Epoch 16/200] [Batch 24/44] [D loss: 0.004717] [G loss: -0.010592]\n",
      "[Epoch 16/200] [Batch 26/44] [D loss: 0.005166] [G loss: -0.010603]\n",
      "[Epoch 16/200] [Batch 28/44] [D loss: 0.007215] [G loss: -0.010625]\n",
      "[Epoch 16/200] [Batch 30/44] [D loss: 0.004418] [G loss: -0.010625]\n",
      "[Epoch 16/200] [Batch 32/44] [D loss: 0.006869] [G loss: -0.010610]\n",
      "[Epoch 16/200] [Batch 34/44] [D loss: 0.004994] [G loss: -0.010618]\n",
      "[Epoch 16/200] [Batch 36/44] [D loss: 0.005206] [G loss: -0.010611]\n",
      "[Epoch 16/200] [Batch 38/44] [D loss: 0.005274] [G loss: -0.010627]\n",
      "[Epoch 16/200] [Batch 40/44] [D loss: 0.004786] [G loss: -0.010626]\n",
      "[Epoch 16/200] [Batch 42/44] [D loss: 0.005004] [G loss: -0.010626]\n",
      "[Epoch 17/200] [Batch 0/44] [D loss: 0.004691] [G loss: -0.010608]\n",
      "[Epoch 17/200] [Batch 2/44] [D loss: 0.006636] [G loss: -0.010630]\n",
      "[Epoch 17/200] [Batch 4/44] [D loss: 0.005830] [G loss: -0.010613]\n",
      "[Epoch 17/200] [Batch 6/44] [D loss: 0.006472] [G loss: -0.010590]\n",
      "[Epoch 17/200] [Batch 8/44] [D loss: 0.006040] [G loss: -0.010622]\n",
      "[Epoch 17/200] [Batch 10/44] [D loss: 0.007189] [G loss: -0.010628]\n",
      "[Epoch 17/200] [Batch 12/44] [D loss: 0.005784] [G loss: -0.010625]\n",
      "[Epoch 17/200] [Batch 14/44] [D loss: 0.005363] [G loss: -0.010624]\n",
      "[Epoch 17/200] [Batch 16/44] [D loss: 0.005129] [G loss: -0.010599]\n",
      "[Epoch 17/200] [Batch 18/44] [D loss: 0.005510] [G loss: -0.010596]\n",
      "[Epoch 17/200] [Batch 20/44] [D loss: 0.005540] [G loss: -0.010600]\n",
      "[Epoch 17/200] [Batch 22/44] [D loss: 0.006611] [G loss: -0.010634]\n",
      "[Epoch 17/200] [Batch 24/44] [D loss: 0.005633] [G loss: -0.010607]\n",
      "[Epoch 17/200] [Batch 26/44] [D loss: 0.005760] [G loss: -0.010622]\n",
      "[Epoch 17/200] [Batch 28/44] [D loss: 0.005790] [G loss: -0.010626]\n",
      "[Epoch 17/200] [Batch 30/44] [D loss: 0.006260] [G loss: -0.010631]\n",
      "[Epoch 17/200] [Batch 32/44] [D loss: 0.005053] [G loss: -0.010627]\n",
      "[Epoch 17/200] [Batch 34/44] [D loss: 0.003716] [G loss: -0.010616]\n",
      "[Epoch 17/200] [Batch 36/44] [D loss: 0.007854] [G loss: -0.010614]\n",
      "[Epoch 17/200] [Batch 38/44] [D loss: 0.005225] [G loss: -0.010606]\n",
      "[Epoch 17/200] [Batch 40/44] [D loss: 0.006504] [G loss: -0.010613]\n",
      "[Epoch 17/200] [Batch 42/44] [D loss: 0.004099] [G loss: -0.010615]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 18/200] [Batch 0/44] [D loss: 0.003780] [G loss: -0.010611]\n",
      "[Epoch 18/200] [Batch 2/44] [D loss: 0.004973] [G loss: -0.010607]\n",
      "[Epoch 18/200] [Batch 4/44] [D loss: 0.004803] [G loss: -0.010612]\n",
      "[Epoch 18/200] [Batch 6/44] [D loss: 0.006407] [G loss: -0.010627]\n",
      "[Epoch 18/200] [Batch 8/44] [D loss: 0.005681] [G loss: -0.010616]\n",
      "[Epoch 18/200] [Batch 10/44] [D loss: 0.006252] [G loss: -0.010626]\n",
      "[Epoch 18/200] [Batch 12/44] [D loss: 0.006251] [G loss: -0.010629]\n",
      "[Epoch 18/200] [Batch 14/44] [D loss: 0.005141] [G loss: -0.010602]\n",
      "[Epoch 18/200] [Batch 16/44] [D loss: 0.008099] [G loss: -0.010606]\n",
      "[Epoch 18/200] [Batch 18/44] [D loss: 0.005457] [G loss: -0.010609]\n",
      "[Epoch 18/200] [Batch 20/44] [D loss: 0.007361] [G loss: -0.010609]\n",
      "[Epoch 18/200] [Batch 22/44] [D loss: 0.005565] [G loss: -0.010641]\n",
      "[Epoch 18/200] [Batch 24/44] [D loss: 0.005687] [G loss: -0.010619]\n",
      "[Epoch 18/200] [Batch 26/44] [D loss: 0.008268] [G loss: -0.010625]\n",
      "[Epoch 18/200] [Batch 28/44] [D loss: 0.004847] [G loss: -0.010618]\n",
      "[Epoch 18/200] [Batch 30/44] [D loss: 0.006216] [G loss: -0.010615]\n",
      "[Epoch 18/200] [Batch 32/44] [D loss: 0.006607] [G loss: -0.010639]\n",
      "[Epoch 18/200] [Batch 34/44] [D loss: 0.003524] [G loss: -0.010613]\n",
      "[Epoch 18/200] [Batch 36/44] [D loss: 0.005418] [G loss: -0.010605]\n",
      "[Epoch 18/200] [Batch 38/44] [D loss: 0.004026] [G loss: -0.010625]\n",
      "[Epoch 18/200] [Batch 40/44] [D loss: 0.005131] [G loss: -0.010613]\n",
      "[Epoch 18/200] [Batch 42/44] [D loss: 0.004505] [G loss: -0.010618]\n",
      "[Epoch 19/200] [Batch 0/44] [D loss: 0.006227] [G loss: -0.010606]\n",
      "[Epoch 19/200] [Batch 2/44] [D loss: 0.006653] [G loss: -0.010624]\n",
      "[Epoch 19/200] [Batch 4/44] [D loss: 0.006911] [G loss: -0.010631]\n",
      "[Epoch 19/200] [Batch 6/44] [D loss: 0.006442] [G loss: -0.010610]\n",
      "[Epoch 19/200] [Batch 8/44] [D loss: 0.006554] [G loss: -0.010622]\n",
      "[Epoch 19/200] [Batch 10/44] [D loss: 0.005737] [G loss: -0.010622]\n",
      "[Epoch 19/200] [Batch 12/44] [D loss: 0.005473] [G loss: -0.010611]\n",
      "[Epoch 19/200] [Batch 14/44] [D loss: 0.004623] [G loss: -0.010600]\n",
      "[Epoch 19/200] [Batch 16/44] [D loss: 0.006198] [G loss: -0.010620]\n",
      "[Epoch 19/200] [Batch 18/44] [D loss: 0.004309] [G loss: -0.010624]\n",
      "[Epoch 19/200] [Batch 20/44] [D loss: 0.003886] [G loss: -0.010628]\n",
      "[Epoch 19/200] [Batch 22/44] [D loss: 0.004785] [G loss: -0.010603]\n",
      "[Epoch 19/200] [Batch 24/44] [D loss: 0.004867] [G loss: -0.010628]\n",
      "[Epoch 19/200] [Batch 26/44] [D loss: 0.008813] [G loss: -0.010599]\n",
      "[Epoch 19/200] [Batch 28/44] [D loss: 0.004811] [G loss: -0.010615]\n",
      "[Epoch 19/200] [Batch 30/44] [D loss: 0.004786] [G loss: -0.010623]\n",
      "[Epoch 19/200] [Batch 32/44] [D loss: 0.002836] [G loss: -0.010641]\n",
      "[Epoch 19/200] [Batch 34/44] [D loss: 0.006932] [G loss: -0.010623]\n",
      "[Epoch 19/200] [Batch 36/44] [D loss: 0.006989] [G loss: -0.010625]\n",
      "[Epoch 19/200] [Batch 38/44] [D loss: 0.005336] [G loss: -0.010617]\n",
      "[Epoch 19/200] [Batch 40/44] [D loss: 0.005156] [G loss: -0.010653]\n",
      "[Epoch 19/200] [Batch 42/44] [D loss: 0.005271] [G loss: -0.010607]\n",
      "[Epoch 20/200] [Batch 0/44] [D loss: 0.005141] [G loss: -0.010610]\n",
      "[Epoch 20/200] [Batch 2/44] [D loss: 0.006557] [G loss: -0.010614]\n",
      "[Epoch 20/200] [Batch 4/44] [D loss: 0.007738] [G loss: -0.010648]\n",
      "[Epoch 20/200] [Batch 6/44] [D loss: 0.007274] [G loss: -0.010626]\n",
      "[Epoch 20/200] [Batch 8/44] [D loss: 0.006263] [G loss: -0.010584]\n",
      "[Epoch 20/200] [Batch 10/44] [D loss: 0.003839] [G loss: -0.010633]\n",
      "[Epoch 20/200] [Batch 12/44] [D loss: 0.005337] [G loss: -0.010581]\n",
      "[Epoch 20/200] [Batch 14/44] [D loss: 0.007068] [G loss: -0.010617]\n",
      "[Epoch 20/200] [Batch 16/44] [D loss: 0.006515] [G loss: -0.010625]\n",
      "[Epoch 20/200] [Batch 18/44] [D loss: 0.004246] [G loss: -0.010591]\n",
      "[Epoch 20/200] [Batch 20/44] [D loss: 0.007184] [G loss: -0.010632]\n",
      "[Epoch 20/200] [Batch 22/44] [D loss: 0.005627] [G loss: -0.010623]\n",
      "[Epoch 20/200] [Batch 24/44] [D loss: 0.004049] [G loss: -0.010618]\n",
      "[Epoch 20/200] [Batch 26/44] [D loss: 0.004884] [G loss: -0.010606]\n",
      "[Epoch 20/200] [Batch 28/44] [D loss: 0.003700] [G loss: -0.010625]\n",
      "[Epoch 20/200] [Batch 30/44] [D loss: 0.007355] [G loss: -0.010605]\n",
      "[Epoch 20/200] [Batch 32/44] [D loss: 0.004669] [G loss: -0.010640]\n",
      "[Epoch 20/200] [Batch 34/44] [D loss: 0.005223] [G loss: -0.010615]\n",
      "[Epoch 20/200] [Batch 36/44] [D loss: 0.005256] [G loss: -0.010588]\n",
      "[Epoch 20/200] [Batch 38/44] [D loss: 0.004125] [G loss: -0.010613]\n",
      "[Epoch 20/200] [Batch 40/44] [D loss: 0.005075] [G loss: -0.010596]\n",
      "[Epoch 20/200] [Batch 42/44] [D loss: 0.003089] [G loss: -0.010604]\n",
      "[Epoch 21/200] [Batch 0/44] [D loss: 0.004257] [G loss: -0.010612]\n",
      "[Epoch 21/200] [Batch 2/44] [D loss: 0.004751] [G loss: -0.010597]\n",
      "[Epoch 21/200] [Batch 4/44] [D loss: 0.005567] [G loss: -0.010597]\n",
      "[Epoch 21/200] [Batch 6/44] [D loss: 0.006185] [G loss: -0.010626]\n",
      "[Epoch 21/200] [Batch 8/44] [D loss: 0.006749] [G loss: -0.010602]\n",
      "[Epoch 21/200] [Batch 10/44] [D loss: 0.006511] [G loss: -0.010601]\n",
      "[Epoch 21/200] [Batch 12/44] [D loss: 0.005674] [G loss: -0.010607]\n",
      "[Epoch 21/200] [Batch 14/44] [D loss: 0.004665] [G loss: -0.010602]\n",
      "[Epoch 21/200] [Batch 16/44] [D loss: 0.006247] [G loss: -0.010613]\n",
      "[Epoch 21/200] [Batch 18/44] [D loss: 0.005410] [G loss: -0.010632]\n",
      "[Epoch 21/200] [Batch 20/44] [D loss: 0.006607] [G loss: -0.010602]\n",
      "[Epoch 21/200] [Batch 22/44] [D loss: 0.004126] [G loss: -0.010611]\n",
      "[Epoch 21/200] [Batch 24/44] [D loss: 0.005656] [G loss: -0.010629]\n",
      "[Epoch 21/200] [Batch 26/44] [D loss: 0.003408] [G loss: -0.010629]\n",
      "[Epoch 21/200] [Batch 28/44] [D loss: 0.006221] [G loss: -0.010627]\n",
      "[Epoch 21/200] [Batch 30/44] [D loss: 0.003833] [G loss: -0.010632]\n",
      "[Epoch 21/200] [Batch 32/44] [D loss: 0.005127] [G loss: -0.010614]\n",
      "[Epoch 21/200] [Batch 34/44] [D loss: 0.007731] [G loss: -0.010602]\n",
      "[Epoch 21/200] [Batch 36/44] [D loss: 0.005334] [G loss: -0.010619]\n",
      "[Epoch 21/200] [Batch 38/44] [D loss: 0.004407] [G loss: -0.010594]\n",
      "[Epoch 21/200] [Batch 40/44] [D loss: 0.004887] [G loss: -0.010621]\n",
      "[Epoch 21/200] [Batch 42/44] [D loss: 0.005113] [G loss: -0.010628]\n",
      "[Epoch 22/200] [Batch 0/44] [D loss: 0.008494] [G loss: -0.010618]\n",
      "[Epoch 22/200] [Batch 2/44] [D loss: 0.005650] [G loss: -0.010629]\n",
      "[Epoch 22/200] [Batch 4/44] [D loss: 0.005071] [G loss: -0.010609]\n",
      "[Epoch 22/200] [Batch 6/44] [D loss: 0.004778] [G loss: -0.010619]\n",
      "[Epoch 22/200] [Batch 8/44] [D loss: 0.004713] [G loss: -0.010608]\n",
      "[Epoch 22/200] [Batch 10/44] [D loss: 0.005911] [G loss: -0.010614]\n",
      "[Epoch 22/200] [Batch 12/44] [D loss: 0.006684] [G loss: -0.010624]\n",
      "[Epoch 22/200] [Batch 14/44] [D loss: 0.002325] [G loss: -0.010634]\n",
      "[Epoch 22/200] [Batch 16/44] [D loss: 0.005933] [G loss: -0.010605]\n",
      "[Epoch 22/200] [Batch 18/44] [D loss: 0.006023] [G loss: -0.010624]\n",
      "[Epoch 22/200] [Batch 20/44] [D loss: 0.003507] [G loss: -0.010601]\n",
      "[Epoch 22/200] [Batch 22/44] [D loss: 0.006290] [G loss: -0.010618]\n",
      "[Epoch 22/200] [Batch 24/44] [D loss: 0.005810] [G loss: -0.010592]\n",
      "[Epoch 22/200] [Batch 26/44] [D loss: 0.005988] [G loss: -0.010600]\n",
      "[Epoch 22/200] [Batch 28/44] [D loss: 0.006910] [G loss: -0.010622]\n",
      "[Epoch 22/200] [Batch 30/44] [D loss: 0.004598] [G loss: -0.010626]\n",
      "[Epoch 22/200] [Batch 32/44] [D loss: 0.004625] [G loss: -0.010614]\n",
      "[Epoch 22/200] [Batch 34/44] [D loss: 0.003830] [G loss: -0.010624]\n",
      "[Epoch 22/200] [Batch 36/44] [D loss: 0.007174] [G loss: -0.010638]\n",
      "[Epoch 22/200] [Batch 38/44] [D loss: 0.007481] [G loss: -0.010610]\n",
      "[Epoch 22/200] [Batch 40/44] [D loss: 0.005486] [G loss: -0.010625]\n",
      "[Epoch 22/200] [Batch 42/44] [D loss: 0.005736] [G loss: -0.010615]\n",
      "[Epoch 23/200] [Batch 0/44] [D loss: 0.005230] [G loss: -0.010603]\n",
      "[Epoch 23/200] [Batch 2/44] [D loss: 0.007820] [G loss: -0.010594]\n",
      "[Epoch 23/200] [Batch 4/44] [D loss: 0.003707] [G loss: -0.010620]\n",
      "[Epoch 23/200] [Batch 6/44] [D loss: 0.006695] [G loss: -0.010630]\n",
      "[Epoch 23/200] [Batch 8/44] [D loss: 0.006654] [G loss: -0.010622]\n",
      "[Epoch 23/200] [Batch 10/44] [D loss: 0.005988] [G loss: -0.010602]\n",
      "[Epoch 23/200] [Batch 12/44] [D loss: 0.006054] [G loss: -0.010618]\n",
      "[Epoch 23/200] [Batch 14/44] [D loss: 0.005478] [G loss: -0.010624]\n",
      "[Epoch 23/200] [Batch 16/44] [D loss: 0.005386] [G loss: -0.010616]\n",
      "[Epoch 23/200] [Batch 18/44] [D loss: 0.003865] [G loss: -0.010614]\n",
      "[Epoch 23/200] [Batch 20/44] [D loss: 0.005137] [G loss: -0.010615]\n",
      "[Epoch 23/200] [Batch 22/44] [D loss: 0.004042] [G loss: -0.010640]\n",
      "[Epoch 23/200] [Batch 24/44] [D loss: 0.005727] [G loss: -0.010617]\n",
      "[Epoch 23/200] [Batch 26/44] [D loss: 0.007198] [G loss: -0.010616]\n",
      "[Epoch 23/200] [Batch 28/44] [D loss: 0.005039] [G loss: -0.010627]\n",
      "[Epoch 23/200] [Batch 30/44] [D loss: 0.005606] [G loss: -0.010623]\n",
      "[Epoch 23/200] [Batch 32/44] [D loss: 0.005420] [G loss: -0.010603]\n",
      "[Epoch 23/200] [Batch 34/44] [D loss: 0.005618] [G loss: -0.010599]\n",
      "[Epoch 23/200] [Batch 36/44] [D loss: 0.006192] [G loss: -0.010630]\n",
      "[Epoch 23/200] [Batch 38/44] [D loss: 0.005046] [G loss: -0.010614]\n",
      "[Epoch 23/200] [Batch 40/44] [D loss: 0.004986] [G loss: -0.010626]\n",
      "[Epoch 23/200] [Batch 42/44] [D loss: 0.005451] [G loss: -0.010609]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 24/200] [Batch 0/44] [D loss: 0.004222] [G loss: -0.010628]\n",
      "[Epoch 24/200] [Batch 2/44] [D loss: 0.005875] [G loss: -0.010607]\n",
      "[Epoch 24/200] [Batch 4/44] [D loss: 0.004574] [G loss: -0.010613]\n",
      "[Epoch 24/200] [Batch 6/44] [D loss: 0.004548] [G loss: -0.010605]\n",
      "[Epoch 24/200] [Batch 8/44] [D loss: 0.007300] [G loss: -0.010618]\n",
      "[Epoch 24/200] [Batch 10/44] [D loss: 0.005761] [G loss: -0.010609]\n",
      "[Epoch 24/200] [Batch 12/44] [D loss: 0.005164] [G loss: -0.010617]\n",
      "[Epoch 24/200] [Batch 14/44] [D loss: 0.004592] [G loss: -0.010597]\n",
      "[Epoch 24/200] [Batch 16/44] [D loss: 0.006040] [G loss: -0.010626]\n",
      "[Epoch 24/200] [Batch 18/44] [D loss: 0.006689] [G loss: -0.010619]\n",
      "[Epoch 24/200] [Batch 20/44] [D loss: 0.006769] [G loss: -0.010635]\n",
      "[Epoch 24/200] [Batch 22/44] [D loss: 0.004482] [G loss: -0.010607]\n",
      "[Epoch 24/200] [Batch 24/44] [D loss: 0.005315] [G loss: -0.010622]\n",
      "[Epoch 24/200] [Batch 26/44] [D loss: 0.005651] [G loss: -0.010586]\n",
      "[Epoch 24/200] [Batch 28/44] [D loss: 0.003865] [G loss: -0.010619]\n",
      "[Epoch 24/200] [Batch 30/44] [D loss: 0.005308] [G loss: -0.010621]\n",
      "[Epoch 24/200] [Batch 32/44] [D loss: 0.006375] [G loss: -0.010629]\n",
      "[Epoch 24/200] [Batch 34/44] [D loss: 0.005674] [G loss: -0.010634]\n",
      "[Epoch 24/200] [Batch 36/44] [D loss: 0.006046] [G loss: -0.010605]\n",
      "[Epoch 24/200] [Batch 38/44] [D loss: 0.006134] [G loss: -0.010636]\n",
      "[Epoch 24/200] [Batch 40/44] [D loss: 0.006730] [G loss: -0.010605]\n",
      "[Epoch 24/200] [Batch 42/44] [D loss: 0.003015] [G loss: -0.010612]\n",
      "[Epoch 25/200] [Batch 0/44] [D loss: 0.007140] [G loss: -0.010607]\n",
      "[Epoch 25/200] [Batch 2/44] [D loss: 0.006618] [G loss: -0.010619]\n",
      "[Epoch 25/200] [Batch 4/44] [D loss: 0.006862] [G loss: -0.010590]\n",
      "[Epoch 25/200] [Batch 6/44] [D loss: 0.005155] [G loss: -0.010628]\n",
      "[Epoch 25/200] [Batch 8/44] [D loss: 0.006632] [G loss: -0.010639]\n",
      "[Epoch 25/200] [Batch 10/44] [D loss: 0.004775] [G loss: -0.010620]\n",
      "[Epoch 25/200] [Batch 12/44] [D loss: 0.007047] [G loss: -0.010617]\n",
      "[Epoch 25/200] [Batch 14/44] [D loss: 0.004996] [G loss: -0.010620]\n",
      "[Epoch 25/200] [Batch 16/44] [D loss: 0.005704] [G loss: -0.010623]\n",
      "[Epoch 25/200] [Batch 18/44] [D loss: 0.005361] [G loss: -0.010634]\n",
      "[Epoch 25/200] [Batch 20/44] [D loss: 0.003558] [G loss: -0.010623]\n",
      "[Epoch 25/200] [Batch 22/44] [D loss: 0.004439] [G loss: -0.010634]\n",
      "[Epoch 25/200] [Batch 24/44] [D loss: 0.004885] [G loss: -0.010615]\n",
      "[Epoch 25/200] [Batch 26/44] [D loss: 0.004924] [G loss: -0.010634]\n",
      "[Epoch 25/200] [Batch 28/44] [D loss: 0.006046] [G loss: -0.010615]\n",
      "[Epoch 25/200] [Batch 30/44] [D loss: 0.006287] [G loss: -0.010644]\n",
      "[Epoch 25/200] [Batch 32/44] [D loss: 0.003331] [G loss: -0.010639]\n",
      "[Epoch 25/200] [Batch 34/44] [D loss: 0.003429] [G loss: -0.010617]\n",
      "[Epoch 25/200] [Batch 36/44] [D loss: 0.004736] [G loss: -0.010609]\n",
      "[Epoch 25/200] [Batch 38/44] [D loss: 0.005835] [G loss: -0.010602]\n",
      "[Epoch 25/200] [Batch 40/44] [D loss: 0.004601] [G loss: -0.010624]\n",
      "[Epoch 25/200] [Batch 42/44] [D loss: 0.006454] [G loss: -0.010610]\n",
      "[Epoch 26/200] [Batch 0/44] [D loss: 0.004727] [G loss: -0.010631]\n",
      "[Epoch 26/200] [Batch 2/44] [D loss: 0.005352] [G loss: -0.010612]\n",
      "[Epoch 26/200] [Batch 4/44] [D loss: 0.004767] [G loss: -0.010604]\n",
      "[Epoch 26/200] [Batch 6/44] [D loss: 0.005874] [G loss: -0.010620]\n",
      "[Epoch 26/200] [Batch 8/44] [D loss: 0.004462] [G loss: -0.010603]\n",
      "[Epoch 26/200] [Batch 10/44] [D loss: 0.006523] [G loss: -0.010618]\n",
      "[Epoch 26/200] [Batch 12/44] [D loss: 0.005294] [G loss: -0.010609]\n",
      "[Epoch 26/200] [Batch 14/44] [D loss: 0.005977] [G loss: -0.010620]\n",
      "[Epoch 26/200] [Batch 16/44] [D loss: 0.005521] [G loss: -0.010626]\n",
      "[Epoch 26/200] [Batch 18/44] [D loss: 0.006626] [G loss: -0.010618]\n",
      "[Epoch 26/200] [Batch 20/44] [D loss: 0.006150] [G loss: -0.010618]\n",
      "[Epoch 26/200] [Batch 22/44] [D loss: 0.005801] [G loss: -0.010629]\n",
      "[Epoch 26/200] [Batch 24/44] [D loss: 0.007994] [G loss: -0.010597]\n",
      "[Epoch 26/200] [Batch 26/44] [D loss: 0.006134] [G loss: -0.010622]\n",
      "[Epoch 26/200] [Batch 28/44] [D loss: 0.005468] [G loss: -0.010621]\n",
      "[Epoch 26/200] [Batch 30/44] [D loss: 0.004006] [G loss: -0.010598]\n",
      "[Epoch 26/200] [Batch 32/44] [D loss: 0.005539] [G loss: -0.010605]\n",
      "[Epoch 26/200] [Batch 34/44] [D loss: 0.005349] [G loss: -0.010607]\n",
      "[Epoch 26/200] [Batch 36/44] [D loss: 0.006451] [G loss: -0.010599]\n",
      "[Epoch 26/200] [Batch 38/44] [D loss: 0.006614] [G loss: -0.010625]\n",
      "[Epoch 26/200] [Batch 40/44] [D loss: 0.003826] [G loss: -0.010601]\n",
      "[Epoch 26/200] [Batch 42/44] [D loss: 0.004396] [G loss: -0.010619]\n",
      "[Epoch 27/200] [Batch 0/44] [D loss: 0.006117] [G loss: -0.010620]\n",
      "[Epoch 27/200] [Batch 2/44] [D loss: 0.005490] [G loss: -0.010641]\n",
      "[Epoch 27/200] [Batch 4/44] [D loss: 0.004147] [G loss: -0.010627]\n",
      "[Epoch 27/200] [Batch 6/44] [D loss: 0.006443] [G loss: -0.010613]\n",
      "[Epoch 27/200] [Batch 8/44] [D loss: 0.004384] [G loss: -0.010619]\n",
      "[Epoch 27/200] [Batch 10/44] [D loss: 0.005449] [G loss: -0.010618]\n",
      "[Epoch 27/200] [Batch 12/44] [D loss: 0.006937] [G loss: -0.010604]\n",
      "[Epoch 27/200] [Batch 14/44] [D loss: 0.005777] [G loss: -0.010630]\n",
      "[Epoch 27/200] [Batch 16/44] [D loss: 0.006612] [G loss: -0.010620]\n",
      "[Epoch 27/200] [Batch 18/44] [D loss: 0.004638] [G loss: -0.010632]\n",
      "[Epoch 27/200] [Batch 20/44] [D loss: 0.005204] [G loss: -0.010623]\n",
      "[Epoch 27/200] [Batch 22/44] [D loss: 0.005864] [G loss: -0.010622]\n",
      "[Epoch 27/200] [Batch 24/44] [D loss: 0.005782] [G loss: -0.010612]\n",
      "[Epoch 27/200] [Batch 26/44] [D loss: 0.003525] [G loss: -0.010612]\n",
      "[Epoch 27/200] [Batch 28/44] [D loss: 0.006999] [G loss: -0.010587]\n",
      "[Epoch 27/200] [Batch 30/44] [D loss: 0.007540] [G loss: -0.010629]\n",
      "[Epoch 27/200] [Batch 32/44] [D loss: 0.005403] [G loss: -0.010613]\n",
      "[Epoch 27/200] [Batch 34/44] [D loss: 0.006490] [G loss: -0.010619]\n",
      "[Epoch 27/200] [Batch 36/44] [D loss: 0.005370] [G loss: -0.010618]\n",
      "[Epoch 27/200] [Batch 38/44] [D loss: 0.006845] [G loss: -0.010586]\n",
      "[Epoch 27/200] [Batch 40/44] [D loss: 0.004867] [G loss: -0.010614]\n",
      "[Epoch 27/200] [Batch 42/44] [D loss: 0.005357] [G loss: -0.010634]\n",
      "[Epoch 28/200] [Batch 0/44] [D loss: 0.004843] [G loss: -0.010613]\n",
      "[Epoch 28/200] [Batch 2/44] [D loss: 0.006336] [G loss: -0.010638]\n",
      "[Epoch 28/200] [Batch 4/44] [D loss: 0.004285] [G loss: -0.010601]\n",
      "[Epoch 28/200] [Batch 6/44] [D loss: 0.003949] [G loss: -0.010603]\n",
      "[Epoch 28/200] [Batch 8/44] [D loss: 0.005295] [G loss: -0.010610]\n",
      "[Epoch 28/200] [Batch 10/44] [D loss: 0.006916] [G loss: -0.010634]\n",
      "[Epoch 28/200] [Batch 12/44] [D loss: 0.005892] [G loss: -0.010593]\n",
      "[Epoch 28/200] [Batch 14/44] [D loss: 0.005500] [G loss: -0.010606]\n",
      "[Epoch 28/200] [Batch 16/44] [D loss: 0.006139] [G loss: -0.010624]\n",
      "[Epoch 28/200] [Batch 18/44] [D loss: 0.006884] [G loss: -0.010600]\n",
      "[Epoch 28/200] [Batch 20/44] [D loss: 0.006072] [G loss: -0.010628]\n",
      "[Epoch 28/200] [Batch 22/44] [D loss: 0.004257] [G loss: -0.010608]\n",
      "[Epoch 28/200] [Batch 24/44] [D loss: 0.005471] [G loss: -0.010606]\n",
      "[Epoch 28/200] [Batch 26/44] [D loss: 0.004804] [G loss: -0.010605]\n",
      "[Epoch 28/200] [Batch 28/44] [D loss: 0.005496] [G loss: -0.010614]\n",
      "[Epoch 28/200] [Batch 30/44] [D loss: 0.006233] [G loss: -0.010635]\n",
      "[Epoch 28/200] [Batch 32/44] [D loss: 0.005079] [G loss: -0.010622]\n",
      "[Epoch 28/200] [Batch 34/44] [D loss: 0.004279] [G loss: -0.010622]\n",
      "[Epoch 28/200] [Batch 36/44] [D loss: 0.004941] [G loss: -0.010620]\n",
      "[Epoch 28/200] [Batch 38/44] [D loss: 0.006517] [G loss: -0.010619]\n",
      "[Epoch 28/200] [Batch 40/44] [D loss: 0.004787] [G loss: -0.010622]\n",
      "[Epoch 28/200] [Batch 42/44] [D loss: 0.006336] [G loss: -0.010625]\n",
      "[Epoch 29/200] [Batch 0/44] [D loss: 0.004615] [G loss: -0.010608]\n",
      "[Epoch 29/200] [Batch 2/44] [D loss: 0.005345] [G loss: -0.010640]\n",
      "[Epoch 29/200] [Batch 4/44] [D loss: 0.004930] [G loss: -0.010606]\n",
      "[Epoch 29/200] [Batch 6/44] [D loss: 0.004845] [G loss: -0.010629]\n",
      "[Epoch 29/200] [Batch 8/44] [D loss: 0.005477] [G loss: -0.010603]\n",
      "[Epoch 29/200] [Batch 10/44] [D loss: 0.005519] [G loss: -0.010611]\n",
      "[Epoch 29/200] [Batch 12/44] [D loss: 0.005627] [G loss: -0.010610]\n",
      "[Epoch 29/200] [Batch 14/44] [D loss: 0.005402] [G loss: -0.010635]\n",
      "[Epoch 29/200] [Batch 16/44] [D loss: 0.006585] [G loss: -0.010606]\n",
      "[Epoch 29/200] [Batch 18/44] [D loss: 0.008505] [G loss: -0.010627]\n",
      "[Epoch 29/200] [Batch 20/44] [D loss: 0.005904] [G loss: -0.010627]\n",
      "[Epoch 29/200] [Batch 22/44] [D loss: 0.003969] [G loss: -0.010621]\n",
      "[Epoch 29/200] [Batch 24/44] [D loss: 0.007434] [G loss: -0.010608]\n",
      "[Epoch 29/200] [Batch 26/44] [D loss: 0.004441] [G loss: -0.010611]\n",
      "[Epoch 29/200] [Batch 28/44] [D loss: 0.005534] [G loss: -0.010614]\n",
      "[Epoch 29/200] [Batch 30/44] [D loss: 0.005516] [G loss: -0.010606]\n",
      "[Epoch 29/200] [Batch 32/44] [D loss: 0.006963] [G loss: -0.010632]\n",
      "[Epoch 29/200] [Batch 34/44] [D loss: 0.005792] [G loss: -0.010633]\n",
      "[Epoch 29/200] [Batch 36/44] [D loss: 0.003203] [G loss: -0.010601]\n",
      "[Epoch 29/200] [Batch 38/44] [D loss: 0.003839] [G loss: -0.010617]\n",
      "[Epoch 29/200] [Batch 40/44] [D loss: 0.007335] [G loss: -0.010625]\n",
      "[Epoch 29/200] [Batch 42/44] [D loss: 0.007876] [G loss: -0.010592]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 30/200] [Batch 0/44] [D loss: 0.005468] [G loss: -0.010599]\n",
      "[Epoch 30/200] [Batch 2/44] [D loss: 0.003655] [G loss: -0.010623]\n",
      "[Epoch 30/200] [Batch 4/44] [D loss: 0.005102] [G loss: -0.010610]\n",
      "[Epoch 30/200] [Batch 6/44] [D loss: 0.005902] [G loss: -0.010640]\n",
      "[Epoch 30/200] [Batch 8/44] [D loss: 0.005038] [G loss: -0.010603]\n",
      "[Epoch 30/200] [Batch 10/44] [D loss: 0.007301] [G loss: -0.010618]\n",
      "[Epoch 30/200] [Batch 12/44] [D loss: 0.004813] [G loss: -0.010610]\n",
      "[Epoch 30/200] [Batch 14/44] [D loss: 0.005519] [G loss: -0.010614]\n",
      "[Epoch 30/200] [Batch 16/44] [D loss: 0.008127] [G loss: -0.010608]\n",
      "[Epoch 30/200] [Batch 18/44] [D loss: 0.005027] [G loss: -0.010631]\n",
      "[Epoch 30/200] [Batch 20/44] [D loss: 0.003761] [G loss: -0.010614]\n",
      "[Epoch 30/200] [Batch 22/44] [D loss: 0.007268] [G loss: -0.010630]\n",
      "[Epoch 30/200] [Batch 24/44] [D loss: 0.007916] [G loss: -0.010630]\n",
      "[Epoch 30/200] [Batch 26/44] [D loss: 0.005417] [G loss: -0.010633]\n",
      "[Epoch 30/200] [Batch 28/44] [D loss: 0.003795] [G loss: -0.010620]\n",
      "[Epoch 30/200] [Batch 30/44] [D loss: 0.003162] [G loss: -0.010624]\n",
      "[Epoch 30/200] [Batch 32/44] [D loss: 0.006897] [G loss: -0.010620]\n",
      "[Epoch 30/200] [Batch 34/44] [D loss: 0.003655] [G loss: -0.010605]\n",
      "[Epoch 30/200] [Batch 36/44] [D loss: 0.005761] [G loss: -0.010602]\n",
      "[Epoch 30/200] [Batch 38/44] [D loss: 0.007527] [G loss: -0.010588]\n",
      "[Epoch 30/200] [Batch 40/44] [D loss: 0.006598] [G loss: -0.010616]\n",
      "[Epoch 30/200] [Batch 42/44] [D loss: 0.005164] [G loss: -0.010614]\n",
      "[Epoch 31/200] [Batch 0/44] [D loss: 0.005816] [G loss: -0.010623]\n",
      "[Epoch 31/200] [Batch 2/44] [D loss: 0.006379] [G loss: -0.010613]\n",
      "[Epoch 31/200] [Batch 4/44] [D loss: 0.004308] [G loss: -0.010613]\n",
      "[Epoch 31/200] [Batch 6/44] [D loss: 0.005770] [G loss: -0.010607]\n",
      "[Epoch 31/200] [Batch 8/44] [D loss: 0.005224] [G loss: -0.010634]\n",
      "[Epoch 31/200] [Batch 10/44] [D loss: 0.005348] [G loss: -0.010620]\n",
      "[Epoch 31/200] [Batch 12/44] [D loss: 0.004427] [G loss: -0.010622]\n",
      "[Epoch 31/200] [Batch 14/44] [D loss: 0.004389] [G loss: -0.010627]\n",
      "[Epoch 31/200] [Batch 16/44] [D loss: 0.005891] [G loss: -0.010638]\n",
      "[Epoch 31/200] [Batch 18/44] [D loss: 0.006883] [G loss: -0.010647]\n",
      "[Epoch 31/200] [Batch 20/44] [D loss: 0.004947] [G loss: -0.010621]\n",
      "[Epoch 31/200] [Batch 22/44] [D loss: 0.007615] [G loss: -0.010640]\n",
      "[Epoch 31/200] [Batch 24/44] [D loss: 0.006344] [G loss: -0.010639]\n",
      "[Epoch 31/200] [Batch 26/44] [D loss: 0.007443] [G loss: -0.010612]\n",
      "[Epoch 31/200] [Batch 28/44] [D loss: 0.005632] [G loss: -0.010627]\n",
      "[Epoch 31/200] [Batch 30/44] [D loss: 0.003471] [G loss: -0.010620]\n",
      "[Epoch 31/200] [Batch 32/44] [D loss: 0.007928] [G loss: -0.010623]\n",
      "[Epoch 31/200] [Batch 34/44] [D loss: 0.005772] [G loss: -0.010627]\n",
      "[Epoch 31/200] [Batch 36/44] [D loss: 0.005458] [G loss: -0.010613]\n",
      "[Epoch 31/200] [Batch 38/44] [D loss: 0.005824] [G loss: -0.010608]\n",
      "[Epoch 31/200] [Batch 40/44] [D loss: 0.004561] [G loss: -0.010620]\n",
      "[Epoch 31/200] [Batch 42/44] [D loss: 0.003215] [G loss: -0.010590]\n",
      "[Epoch 32/200] [Batch 0/44] [D loss: 0.005175] [G loss: -0.010604]\n",
      "[Epoch 32/200] [Batch 2/44] [D loss: 0.006082] [G loss: -0.010626]\n",
      "[Epoch 32/200] [Batch 4/44] [D loss: 0.005128] [G loss: -0.010606]\n",
      "[Epoch 32/200] [Batch 6/44] [D loss: 0.004725] [G loss: -0.010614]\n",
      "[Epoch 32/200] [Batch 8/44] [D loss: 0.006052] [G loss: -0.010620]\n",
      "[Epoch 32/200] [Batch 10/44] [D loss: 0.006371] [G loss: -0.010601]\n",
      "[Epoch 32/200] [Batch 12/44] [D loss: 0.004646] [G loss: -0.010609]\n",
      "[Epoch 32/200] [Batch 14/44] [D loss: 0.005647] [G loss: -0.010634]\n",
      "[Epoch 32/200] [Batch 16/44] [D loss: 0.002684] [G loss: -0.010609]\n",
      "[Epoch 32/200] [Batch 18/44] [D loss: 0.004186] [G loss: -0.010614]\n",
      "[Epoch 32/200] [Batch 20/44] [D loss: 0.006670] [G loss: -0.010631]\n",
      "[Epoch 32/200] [Batch 22/44] [D loss: 0.006758] [G loss: -0.010612]\n",
      "[Epoch 32/200] [Batch 24/44] [D loss: 0.003898] [G loss: -0.010625]\n",
      "[Epoch 32/200] [Batch 26/44] [D loss: 0.006065] [G loss: -0.010612]\n",
      "[Epoch 32/200] [Batch 28/44] [D loss: 0.006555] [G loss: -0.010620]\n",
      "[Epoch 32/200] [Batch 30/44] [D loss: 0.004861] [G loss: -0.010615]\n",
      "[Epoch 32/200] [Batch 32/44] [D loss: 0.005586] [G loss: -0.010622]\n",
      "[Epoch 32/200] [Batch 34/44] [D loss: 0.005568] [G loss: -0.010619]\n",
      "[Epoch 32/200] [Batch 36/44] [D loss: 0.004855] [G loss: -0.010631]\n",
      "[Epoch 32/200] [Batch 38/44] [D loss: 0.004426] [G loss: -0.010596]\n",
      "[Epoch 32/200] [Batch 40/44] [D loss: 0.007578] [G loss: -0.010607]\n",
      "[Epoch 32/200] [Batch 42/44] [D loss: 0.005902] [G loss: -0.010648]\n",
      "[Epoch 33/200] [Batch 0/44] [D loss: 0.005261] [G loss: -0.010622]\n",
      "[Epoch 33/200] [Batch 2/44] [D loss: 0.006843] [G loss: -0.010615]\n",
      "[Epoch 33/200] [Batch 4/44] [D loss: 0.006849] [G loss: -0.010619]\n",
      "[Epoch 33/200] [Batch 6/44] [D loss: 0.006959] [G loss: -0.010614]\n",
      "[Epoch 33/200] [Batch 8/44] [D loss: 0.003691] [G loss: -0.010594]\n",
      "[Epoch 33/200] [Batch 10/44] [D loss: 0.004924] [G loss: -0.010620]\n",
      "[Epoch 33/200] [Batch 12/44] [D loss: 0.004429] [G loss: -0.010612]\n",
      "[Epoch 33/200] [Batch 14/44] [D loss: 0.006985] [G loss: -0.010618]\n",
      "[Epoch 33/200] [Batch 16/44] [D loss: 0.005496] [G loss: -0.010609]\n",
      "[Epoch 33/200] [Batch 18/44] [D loss: 0.005927] [G loss: -0.010598]\n",
      "[Epoch 33/200] [Batch 20/44] [D loss: 0.005638] [G loss: -0.010621]\n",
      "[Epoch 33/200] [Batch 22/44] [D loss: 0.005987] [G loss: -0.010621]\n",
      "[Epoch 33/200] [Batch 24/44] [D loss: 0.006249] [G loss: -0.010640]\n",
      "[Epoch 33/200] [Batch 26/44] [D loss: 0.005565] [G loss: -0.010617]\n",
      "[Epoch 33/200] [Batch 28/44] [D loss: 0.004962] [G loss: -0.010615]\n",
      "[Epoch 33/200] [Batch 30/44] [D loss: 0.004555] [G loss: -0.010600]\n",
      "[Epoch 33/200] [Batch 32/44] [D loss: 0.006690] [G loss: -0.010606]\n",
      "[Epoch 33/200] [Batch 34/44] [D loss: 0.004806] [G loss: -0.010613]\n",
      "[Epoch 33/200] [Batch 36/44] [D loss: 0.005486] [G loss: -0.010622]\n",
      "[Epoch 33/200] [Batch 38/44] [D loss: 0.005735] [G loss: -0.010607]\n",
      "[Epoch 33/200] [Batch 40/44] [D loss: 0.006913] [G loss: -0.010610]\n",
      "[Epoch 33/200] [Batch 42/44] [D loss: 0.003869] [G loss: -0.010625]\n",
      "[Epoch 34/200] [Batch 0/44] [D loss: 0.003585] [G loss: -0.010625]\n",
      "[Epoch 34/200] [Batch 2/44] [D loss: 0.003098] [G loss: -0.010626]\n",
      "[Epoch 34/200] [Batch 4/44] [D loss: 0.004566] [G loss: -0.010635]\n",
      "[Epoch 34/200] [Batch 6/44] [D loss: 0.007937] [G loss: -0.010623]\n",
      "[Epoch 34/200] [Batch 8/44] [D loss: 0.005305] [G loss: -0.010601]\n",
      "[Epoch 34/200] [Batch 10/44] [D loss: 0.005471] [G loss: -0.010612]\n",
      "[Epoch 34/200] [Batch 12/44] [D loss: 0.005979] [G loss: -0.010629]\n",
      "[Epoch 34/200] [Batch 14/44] [D loss: 0.005018] [G loss: -0.010631]\n",
      "[Epoch 34/200] [Batch 16/44] [D loss: 0.006571] [G loss: -0.010613]\n",
      "[Epoch 34/200] [Batch 18/44] [D loss: 0.005027] [G loss: -0.010608]\n",
      "[Epoch 34/200] [Batch 20/44] [D loss: 0.006061] [G loss: -0.010617]\n",
      "[Epoch 34/200] [Batch 22/44] [D loss: 0.006586] [G loss: -0.010604]\n",
      "[Epoch 34/200] [Batch 24/44] [D loss: 0.006194] [G loss: -0.010614]\n",
      "[Epoch 34/200] [Batch 26/44] [D loss: 0.005772] [G loss: -0.010618]\n",
      "[Epoch 34/200] [Batch 28/44] [D loss: 0.005468] [G loss: -0.010616]\n",
      "[Epoch 34/200] [Batch 30/44] [D loss: 0.002804] [G loss: -0.010635]\n",
      "[Epoch 34/200] [Batch 32/44] [D loss: 0.004897] [G loss: -0.010628]\n",
      "[Epoch 34/200] [Batch 34/44] [D loss: 0.005315] [G loss: -0.010636]\n",
      "[Epoch 34/200] [Batch 36/44] [D loss: 0.006796] [G loss: -0.010620]\n",
      "[Epoch 34/200] [Batch 38/44] [D loss: 0.006644] [G loss: -0.010621]\n",
      "[Epoch 34/200] [Batch 40/44] [D loss: 0.006606] [G loss: -0.010620]\n",
      "[Epoch 34/200] [Batch 42/44] [D loss: 0.006166] [G loss: -0.010613]\n",
      "[Epoch 35/200] [Batch 0/44] [D loss: 0.005420] [G loss: -0.010601]\n",
      "[Epoch 35/200] [Batch 2/44] [D loss: 0.007519] [G loss: -0.010605]\n",
      "[Epoch 35/200] [Batch 4/44] [D loss: 0.006069] [G loss: -0.010624]\n",
      "[Epoch 35/200] [Batch 6/44] [D loss: 0.005813] [G loss: -0.010635]\n",
      "[Epoch 35/200] [Batch 8/44] [D loss: 0.007470] [G loss: -0.010642]\n",
      "[Epoch 35/200] [Batch 10/44] [D loss: 0.004897] [G loss: -0.010632]\n",
      "[Epoch 35/200] [Batch 12/44] [D loss: 0.005549] [G loss: -0.010604]\n",
      "[Epoch 35/200] [Batch 14/44] [D loss: 0.007757] [G loss: -0.010594]\n",
      "[Epoch 35/200] [Batch 16/44] [D loss: 0.002543] [G loss: -0.010621]\n",
      "[Epoch 35/200] [Batch 18/44] [D loss: 0.006107] [G loss: -0.010608]\n",
      "[Epoch 35/200] [Batch 20/44] [D loss: 0.004382] [G loss: -0.010635]\n",
      "[Epoch 35/200] [Batch 22/44] [D loss: 0.005337] [G loss: -0.010618]\n",
      "[Epoch 35/200] [Batch 24/44] [D loss: 0.004489] [G loss: -0.010608]\n",
      "[Epoch 35/200] [Batch 26/44] [D loss: 0.006281] [G loss: -0.010598]\n",
      "[Epoch 35/200] [Batch 28/44] [D loss: 0.006455] [G loss: -0.010623]\n",
      "[Epoch 35/200] [Batch 30/44] [D loss: 0.002233] [G loss: -0.010624]\n",
      "[Epoch 35/200] [Batch 32/44] [D loss: 0.005997] [G loss: -0.010602]\n",
      "[Epoch 35/200] [Batch 34/44] [D loss: 0.003358] [G loss: -0.010624]\n",
      "[Epoch 35/200] [Batch 36/44] [D loss: 0.005413] [G loss: -0.010602]\n",
      "[Epoch 35/200] [Batch 38/44] [D loss: 0.006241] [G loss: -0.010636]\n",
      "[Epoch 35/200] [Batch 40/44] [D loss: 0.006328] [G loss: -0.010624]\n",
      "[Epoch 35/200] [Batch 42/44] [D loss: 0.004876] [G loss: -0.010596]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 36/200] [Batch 0/44] [D loss: 0.003712] [G loss: -0.010620]\n",
      "[Epoch 36/200] [Batch 2/44] [D loss: 0.005001] [G loss: -0.010598]\n",
      "[Epoch 36/200] [Batch 4/44] [D loss: 0.006476] [G loss: -0.010633]\n",
      "[Epoch 36/200] [Batch 6/44] [D loss: 0.005577] [G loss: -0.010635]\n",
      "[Epoch 36/200] [Batch 8/44] [D loss: 0.004592] [G loss: -0.010625]\n",
      "[Epoch 36/200] [Batch 10/44] [D loss: 0.005626] [G loss: -0.010617]\n",
      "[Epoch 36/200] [Batch 12/44] [D loss: 0.005944] [G loss: -0.010610]\n",
      "[Epoch 36/200] [Batch 14/44] [D loss: 0.005741] [G loss: -0.010617]\n",
      "[Epoch 36/200] [Batch 16/44] [D loss: 0.005868] [G loss: -0.010631]\n",
      "[Epoch 36/200] [Batch 18/44] [D loss: 0.004915] [G loss: -0.010607]\n",
      "[Epoch 36/200] [Batch 20/44] [D loss: 0.003599] [G loss: -0.010625]\n",
      "[Epoch 36/200] [Batch 22/44] [D loss: 0.003678] [G loss: -0.010620]\n",
      "[Epoch 36/200] [Batch 24/44] [D loss: 0.005278] [G loss: -0.010635]\n",
      "[Epoch 36/200] [Batch 26/44] [D loss: 0.005945] [G loss: -0.010605]\n",
      "[Epoch 36/200] [Batch 28/44] [D loss: 0.006738] [G loss: -0.010627]\n",
      "[Epoch 36/200] [Batch 30/44] [D loss: 0.006001] [G loss: -0.010619]\n",
      "[Epoch 36/200] [Batch 32/44] [D loss: 0.005471] [G loss: -0.010631]\n",
      "[Epoch 36/200] [Batch 34/44] [D loss: 0.005701] [G loss: -0.010617]\n",
      "[Epoch 36/200] [Batch 36/44] [D loss: 0.006131] [G loss: -0.010615]\n",
      "[Epoch 36/200] [Batch 38/44] [D loss: 0.006224] [G loss: -0.010620]\n",
      "[Epoch 36/200] [Batch 40/44] [D loss: 0.005139] [G loss: -0.010624]\n",
      "[Epoch 36/200] [Batch 42/44] [D loss: 0.004990] [G loss: -0.010629]\n",
      "[Epoch 37/200] [Batch 0/44] [D loss: 0.005835] [G loss: -0.010623]\n",
      "[Epoch 37/200] [Batch 2/44] [D loss: 0.005649] [G loss: -0.010609]\n",
      "[Epoch 37/200] [Batch 4/44] [D loss: 0.006112] [G loss: -0.010595]\n",
      "[Epoch 37/200] [Batch 6/44] [D loss: 0.006155] [G loss: -0.010603]\n",
      "[Epoch 37/200] [Batch 8/44] [D loss: 0.005950] [G loss: -0.010633]\n",
      "[Epoch 37/200] [Batch 10/44] [D loss: 0.003306] [G loss: -0.010619]\n",
      "[Epoch 37/200] [Batch 12/44] [D loss: 0.004852] [G loss: -0.010631]\n",
      "[Epoch 37/200] [Batch 14/44] [D loss: 0.005824] [G loss: -0.010610]\n",
      "[Epoch 37/200] [Batch 16/44] [D loss: 0.006288] [G loss: -0.010624]\n",
      "[Epoch 37/200] [Batch 18/44] [D loss: 0.005374] [G loss: -0.010602]\n",
      "[Epoch 37/200] [Batch 20/44] [D loss: 0.006181] [G loss: -0.010615]\n",
      "[Epoch 37/200] [Batch 22/44] [D loss: 0.003904] [G loss: -0.010620]\n",
      "[Epoch 37/200] [Batch 24/44] [D loss: 0.006225] [G loss: -0.010623]\n",
      "[Epoch 37/200] [Batch 26/44] [D loss: 0.007383] [G loss: -0.010609]\n",
      "[Epoch 37/200] [Batch 28/44] [D loss: 0.005760] [G loss: -0.010611]\n",
      "[Epoch 37/200] [Batch 30/44] [D loss: 0.007092] [G loss: -0.010635]\n",
      "[Epoch 37/200] [Batch 32/44] [D loss: 0.006204] [G loss: -0.010627]\n",
      "[Epoch 37/200] [Batch 34/44] [D loss: 0.006628] [G loss: -0.010617]\n",
      "[Epoch 37/200] [Batch 36/44] [D loss: 0.005349] [G loss: -0.010603]\n",
      "[Epoch 37/200] [Batch 38/44] [D loss: 0.005252] [G loss: -0.010612]\n",
      "[Epoch 37/200] [Batch 40/44] [D loss: 0.006296] [G loss: -0.010626]\n",
      "[Epoch 37/200] [Batch 42/44] [D loss: 0.003588] [G loss: -0.010604]\n",
      "[Epoch 38/200] [Batch 0/44] [D loss: 0.004968] [G loss: -0.010647]\n",
      "[Epoch 38/200] [Batch 2/44] [D loss: 0.006422] [G loss: -0.010625]\n",
      "[Epoch 38/200] [Batch 4/44] [D loss: 0.005285] [G loss: -0.010607]\n",
      "[Epoch 38/200] [Batch 6/44] [D loss: 0.005742] [G loss: -0.010597]\n",
      "[Epoch 38/200] [Batch 8/44] [D loss: 0.006955] [G loss: -0.010609]\n",
      "[Epoch 38/200] [Batch 10/44] [D loss: 0.004622] [G loss: -0.010622]\n",
      "[Epoch 38/200] [Batch 12/44] [D loss: 0.006388] [G loss: -0.010618]\n",
      "[Epoch 38/200] [Batch 14/44] [D loss: 0.005638] [G loss: -0.010600]\n",
      "[Epoch 38/200] [Batch 16/44] [D loss: 0.006913] [G loss: -0.010619]\n",
      "[Epoch 38/200] [Batch 18/44] [D loss: 0.005830] [G loss: -0.010634]\n",
      "[Epoch 38/200] [Batch 20/44] [D loss: 0.006800] [G loss: -0.010588]\n",
      "[Epoch 38/200] [Batch 22/44] [D loss: 0.005526] [G loss: -0.010630]\n",
      "[Epoch 38/200] [Batch 24/44] [D loss: 0.003688] [G loss: -0.010624]\n",
      "[Epoch 38/200] [Batch 26/44] [D loss: 0.005527] [G loss: -0.010617]\n",
      "[Epoch 38/200] [Batch 28/44] [D loss: 0.006241] [G loss: -0.010637]\n",
      "[Epoch 38/200] [Batch 30/44] [D loss: 0.005489] [G loss: -0.010616]\n",
      "[Epoch 38/200] [Batch 32/44] [D loss: 0.005631] [G loss: -0.010595]\n",
      "[Epoch 38/200] [Batch 34/44] [D loss: 0.005956] [G loss: -0.010624]\n",
      "[Epoch 38/200] [Batch 36/44] [D loss: 0.004797] [G loss: -0.010618]\n",
      "[Epoch 38/200] [Batch 38/44] [D loss: 0.006172] [G loss: -0.010600]\n",
      "[Epoch 38/200] [Batch 40/44] [D loss: 0.004456] [G loss: -0.010607]\n",
      "[Epoch 38/200] [Batch 42/44] [D loss: 0.006187] [G loss: -0.010626]\n",
      "[Epoch 39/200] [Batch 0/44] [D loss: 0.006625] [G loss: -0.010603]\n",
      "[Epoch 39/200] [Batch 2/44] [D loss: 0.005974] [G loss: -0.010628]\n",
      "[Epoch 39/200] [Batch 4/44] [D loss: 0.005976] [G loss: -0.010599]\n",
      "[Epoch 39/200] [Batch 6/44] [D loss: 0.004896] [G loss: -0.010615]\n",
      "[Epoch 39/200] [Batch 8/44] [D loss: 0.004263] [G loss: -0.010616]\n",
      "[Epoch 39/200] [Batch 10/44] [D loss: 0.006287] [G loss: -0.010614]\n",
      "[Epoch 39/200] [Batch 12/44] [D loss: 0.003673] [G loss: -0.010622]\n",
      "[Epoch 39/200] [Batch 14/44] [D loss: 0.004129] [G loss: -0.010597]\n",
      "[Epoch 39/200] [Batch 16/44] [D loss: 0.006290] [G loss: -0.010632]\n",
      "[Epoch 39/200] [Batch 18/44] [D loss: 0.006970] [G loss: -0.010611]\n",
      "[Epoch 39/200] [Batch 20/44] [D loss: 0.006978] [G loss: -0.010612]\n",
      "[Epoch 39/200] [Batch 22/44] [D loss: 0.006488] [G loss: -0.010628]\n",
      "[Epoch 39/200] [Batch 24/44] [D loss: 0.006813] [G loss: -0.010638]\n",
      "[Epoch 39/200] [Batch 26/44] [D loss: 0.005585] [G loss: -0.010604]\n",
      "[Epoch 39/200] [Batch 28/44] [D loss: 0.005338] [G loss: -0.010620]\n",
      "[Epoch 39/200] [Batch 30/44] [D loss: 0.005569] [G loss: -0.010584]\n",
      "[Epoch 39/200] [Batch 32/44] [D loss: 0.007188] [G loss: -0.010631]\n",
      "[Epoch 39/200] [Batch 34/44] [D loss: 0.005017] [G loss: -0.010620]\n",
      "[Epoch 39/200] [Batch 36/44] [D loss: 0.004553] [G loss: -0.010625]\n",
      "[Epoch 39/200] [Batch 38/44] [D loss: 0.006072] [G loss: -0.010617]\n",
      "[Epoch 39/200] [Batch 40/44] [D loss: 0.007361] [G loss: -0.010612]\n",
      "[Epoch 39/200] [Batch 42/44] [D loss: 0.002062] [G loss: -0.010620]\n",
      "[Epoch 40/200] [Batch 0/44] [D loss: 0.004844] [G loss: -0.010600]\n",
      "[Epoch 40/200] [Batch 2/44] [D loss: 0.004483] [G loss: -0.010623]\n",
      "[Epoch 40/200] [Batch 4/44] [D loss: 0.005160] [G loss: -0.010612]\n",
      "[Epoch 40/200] [Batch 6/44] [D loss: 0.004524] [G loss: -0.010616]\n",
      "[Epoch 40/200] [Batch 8/44] [D loss: 0.005740] [G loss: -0.010639]\n",
      "[Epoch 40/200] [Batch 10/44] [D loss: 0.005792] [G loss: -0.010598]\n",
      "[Epoch 40/200] [Batch 12/44] [D loss: 0.004565] [G loss: -0.010607]\n",
      "[Epoch 40/200] [Batch 14/44] [D loss: 0.004234] [G loss: -0.010605]\n",
      "[Epoch 40/200] [Batch 16/44] [D loss: 0.002636] [G loss: -0.010616]\n",
      "[Epoch 40/200] [Batch 18/44] [D loss: 0.007259] [G loss: -0.010630]\n",
      "[Epoch 40/200] [Batch 20/44] [D loss: 0.005911] [G loss: -0.010608]\n",
      "[Epoch 40/200] [Batch 22/44] [D loss: 0.005187] [G loss: -0.010626]\n",
      "[Epoch 40/200] [Batch 24/44] [D loss: 0.008028] [G loss: -0.010610]\n",
      "[Epoch 40/200] [Batch 26/44] [D loss: 0.005038] [G loss: -0.010617]\n",
      "[Epoch 40/200] [Batch 28/44] [D loss: 0.004991] [G loss: -0.010617]\n",
      "[Epoch 40/200] [Batch 30/44] [D loss: 0.004654] [G loss: -0.010625]\n",
      "[Epoch 40/200] [Batch 32/44] [D loss: 0.005621] [G loss: -0.010627]\n",
      "[Epoch 40/200] [Batch 34/44] [D loss: 0.003380] [G loss: -0.010627]\n",
      "[Epoch 40/200] [Batch 36/44] [D loss: 0.006222] [G loss: -0.010644]\n",
      "[Epoch 40/200] [Batch 38/44] [D loss: 0.006410] [G loss: -0.010624]\n",
      "[Epoch 40/200] [Batch 40/44] [D loss: 0.005929] [G loss: -0.010604]\n",
      "[Epoch 40/200] [Batch 42/44] [D loss: 0.006199] [G loss: -0.010610]\n",
      "[Epoch 41/200] [Batch 0/44] [D loss: 0.006020] [G loss: -0.010601]\n",
      "[Epoch 41/200] [Batch 2/44] [D loss: 0.006575] [G loss: -0.010609]\n",
      "[Epoch 41/200] [Batch 4/44] [D loss: 0.007013] [G loss: -0.010640]\n",
      "[Epoch 41/200] [Batch 6/44] [D loss: 0.007354] [G loss: -0.010604]\n",
      "[Epoch 41/200] [Batch 8/44] [D loss: 0.004515] [G loss: -0.010628]\n",
      "[Epoch 41/200] [Batch 10/44] [D loss: 0.003182] [G loss: -0.010639]\n",
      "[Epoch 41/200] [Batch 12/44] [D loss: 0.006831] [G loss: -0.010633]\n",
      "[Epoch 41/200] [Batch 14/44] [D loss: 0.003711] [G loss: -0.010651]\n",
      "[Epoch 41/200] [Batch 16/44] [D loss: 0.005551] [G loss: -0.010638]\n",
      "[Epoch 41/200] [Batch 18/44] [D loss: 0.005104] [G loss: -0.010595]\n",
      "[Epoch 41/200] [Batch 20/44] [D loss: 0.006431] [G loss: -0.010608]\n",
      "[Epoch 41/200] [Batch 22/44] [D loss: 0.006873] [G loss: -0.010630]\n",
      "[Epoch 41/200] [Batch 24/44] [D loss: 0.003072] [G loss: -0.010632]\n",
      "[Epoch 41/200] [Batch 26/44] [D loss: 0.005336] [G loss: -0.010604]\n",
      "[Epoch 41/200] [Batch 28/44] [D loss: 0.005440] [G loss: -0.010604]\n",
      "[Epoch 41/200] [Batch 30/44] [D loss: 0.006136] [G loss: -0.010588]\n",
      "[Epoch 41/200] [Batch 32/44] [D loss: 0.006250] [G loss: -0.010615]\n",
      "[Epoch 41/200] [Batch 34/44] [D loss: 0.006530] [G loss: -0.010610]\n",
      "[Epoch 41/200] [Batch 36/44] [D loss: 0.005990] [G loss: -0.010633]\n",
      "[Epoch 41/200] [Batch 38/44] [D loss: 0.005604] [G loss: -0.010641]\n",
      "[Epoch 41/200] [Batch 40/44] [D loss: 0.005305] [G loss: -0.010592]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 41/200] [Batch 42/44] [D loss: 0.007929] [G loss: -0.010632]\n",
      "[Epoch 42/200] [Batch 0/44] [D loss: 0.006750] [G loss: -0.010608]\n",
      "[Epoch 42/200] [Batch 2/44] [D loss: 0.006241] [G loss: -0.010611]\n",
      "[Epoch 42/200] [Batch 4/44] [D loss: 0.005515] [G loss: -0.010628]\n",
      "[Epoch 42/200] [Batch 6/44] [D loss: 0.005063] [G loss: -0.010636]\n",
      "[Epoch 42/200] [Batch 8/44] [D loss: 0.004531] [G loss: -0.010615]\n",
      "[Epoch 42/200] [Batch 10/44] [D loss: 0.005496] [G loss: -0.010639]\n",
      "[Epoch 42/200] [Batch 12/44] [D loss: 0.005124] [G loss: -0.010607]\n",
      "[Epoch 42/200] [Batch 14/44] [D loss: 0.005818] [G loss: -0.010611]\n",
      "[Epoch 42/200] [Batch 16/44] [D loss: 0.005736] [G loss: -0.010627]\n",
      "[Epoch 42/200] [Batch 18/44] [D loss: 0.004840] [G loss: -0.010593]\n",
      "[Epoch 42/200] [Batch 20/44] [D loss: 0.003639] [G loss: -0.010603]\n",
      "[Epoch 42/200] [Batch 22/44] [D loss: 0.006345] [G loss: -0.010597]\n",
      "[Epoch 42/200] [Batch 24/44] [D loss: 0.005110] [G loss: -0.010592]\n",
      "[Epoch 42/200] [Batch 26/44] [D loss: 0.006150] [G loss: -0.010618]\n",
      "[Epoch 42/200] [Batch 28/44] [D loss: 0.003925] [G loss: -0.010615]\n",
      "[Epoch 42/200] [Batch 30/44] [D loss: 0.006474] [G loss: -0.010600]\n",
      "[Epoch 42/200] [Batch 32/44] [D loss: 0.004736] [G loss: -0.010610]\n",
      "[Epoch 42/200] [Batch 34/44] [D loss: 0.006919] [G loss: -0.010638]\n",
      "[Epoch 42/200] [Batch 36/44] [D loss: 0.005286] [G loss: -0.010605]\n",
      "[Epoch 42/200] [Batch 38/44] [D loss: 0.005975] [G loss: -0.010603]\n",
      "[Epoch 42/200] [Batch 40/44] [D loss: 0.005915] [G loss: -0.010603]\n",
      "[Epoch 42/200] [Batch 42/44] [D loss: 0.004968] [G loss: -0.010619]\n",
      "[Epoch 43/200] [Batch 0/44] [D loss: 0.006560] [G loss: -0.010613]\n",
      "[Epoch 43/200] [Batch 2/44] [D loss: 0.004920] [G loss: -0.010628]\n",
      "[Epoch 43/200] [Batch 4/44] [D loss: 0.006680] [G loss: -0.010628]\n",
      "[Epoch 43/200] [Batch 6/44] [D loss: 0.005388] [G loss: -0.010614]\n",
      "[Epoch 43/200] [Batch 8/44] [D loss: 0.005804] [G loss: -0.010621]\n",
      "[Epoch 43/200] [Batch 10/44] [D loss: 0.004923] [G loss: -0.010615]\n",
      "[Epoch 43/200] [Batch 12/44] [D loss: 0.006667] [G loss: -0.010600]\n",
      "[Epoch 43/200] [Batch 14/44] [D loss: 0.004189] [G loss: -0.010623]\n",
      "[Epoch 43/200] [Batch 16/44] [D loss: 0.005063] [G loss: -0.010616]\n",
      "[Epoch 43/200] [Batch 18/44] [D loss: 0.005555] [G loss: -0.010622]\n",
      "[Epoch 43/200] [Batch 20/44] [D loss: 0.007273] [G loss: -0.010618]\n",
      "[Epoch 43/200] [Batch 22/44] [D loss: 0.006402] [G loss: -0.010611]\n",
      "[Epoch 43/200] [Batch 24/44] [D loss: 0.002753] [G loss: -0.010611]\n",
      "[Epoch 43/200] [Batch 26/44] [D loss: 0.004721] [G loss: -0.010588]\n",
      "[Epoch 43/200] [Batch 28/44] [D loss: 0.004670] [G loss: -0.010599]\n",
      "[Epoch 43/200] [Batch 30/44] [D loss: 0.005664] [G loss: -0.010609]\n",
      "[Epoch 43/200] [Batch 32/44] [D loss: 0.006580] [G loss: -0.010616]\n",
      "[Epoch 43/200] [Batch 34/44] [D loss: 0.006738] [G loss: -0.010598]\n",
      "[Epoch 43/200] [Batch 36/44] [D loss: 0.004643] [G loss: -0.010603]\n",
      "[Epoch 43/200] [Batch 38/44] [D loss: 0.006255] [G loss: -0.010637]\n",
      "[Epoch 43/200] [Batch 40/44] [D loss: 0.005642] [G loss: -0.010605]\n",
      "[Epoch 43/200] [Batch 42/44] [D loss: 0.006298] [G loss: -0.010630]\n",
      "[Epoch 44/200] [Batch 0/44] [D loss: 0.006890] [G loss: -0.010628]\n",
      "[Epoch 44/200] [Batch 2/44] [D loss: 0.006938] [G loss: -0.010606]\n",
      "[Epoch 44/200] [Batch 4/44] [D loss: 0.005029] [G loss: -0.010630]\n",
      "[Epoch 44/200] [Batch 6/44] [D loss: 0.003923] [G loss: -0.010628]\n",
      "[Epoch 44/200] [Batch 8/44] [D loss: 0.003491] [G loss: -0.010607]\n",
      "[Epoch 44/200] [Batch 10/44] [D loss: 0.005583] [G loss: -0.010621]\n",
      "[Epoch 44/200] [Batch 12/44] [D loss: 0.004755] [G loss: -0.010624]\n",
      "[Epoch 44/200] [Batch 14/44] [D loss: 0.005386] [G loss: -0.010601]\n",
      "[Epoch 44/200] [Batch 16/44] [D loss: 0.005080] [G loss: -0.010615]\n",
      "[Epoch 44/200] [Batch 18/44] [D loss: 0.006170] [G loss: -0.010610]\n",
      "[Epoch 44/200] [Batch 20/44] [D loss: 0.002935] [G loss: -0.010600]\n",
      "[Epoch 44/200] [Batch 22/44] [D loss: 0.007159] [G loss: -0.010630]\n",
      "[Epoch 44/200] [Batch 24/44] [D loss: 0.005626] [G loss: -0.010602]\n",
      "[Epoch 44/200] [Batch 26/44] [D loss: 0.006405] [G loss: -0.010631]\n",
      "[Epoch 44/200] [Batch 28/44] [D loss: 0.005707] [G loss: -0.010615]\n",
      "[Epoch 44/200] [Batch 30/44] [D loss: 0.005425] [G loss: -0.010610]\n",
      "[Epoch 44/200] [Batch 32/44] [D loss: 0.005955] [G loss: -0.010610]\n",
      "[Epoch 44/200] [Batch 34/44] [D loss: 0.005588] [G loss: -0.010612]\n",
      "[Epoch 44/200] [Batch 36/44] [D loss: 0.004897] [G loss: -0.010605]\n",
      "[Epoch 44/200] [Batch 38/44] [D loss: 0.006356] [G loss: -0.010628]\n",
      "[Epoch 44/200] [Batch 40/44] [D loss: 0.003322] [G loss: -0.010628]\n",
      "[Epoch 44/200] [Batch 42/44] [D loss: 0.005694] [G loss: -0.010619]\n",
      "[Epoch 45/200] [Batch 0/44] [D loss: 0.005921] [G loss: -0.010609]\n",
      "[Epoch 45/200] [Batch 2/44] [D loss: 0.003759] [G loss: -0.010609]\n",
      "[Epoch 45/200] [Batch 4/44] [D loss: 0.004455] [G loss: -0.010627]\n",
      "[Epoch 45/200] [Batch 6/44] [D loss: 0.006390] [G loss: -0.010618]\n",
      "[Epoch 45/200] [Batch 8/44] [D loss: 0.005430] [G loss: -0.010620]\n",
      "[Epoch 45/200] [Batch 10/44] [D loss: 0.004941] [G loss: -0.010616]\n",
      "[Epoch 45/200] [Batch 12/44] [D loss: 0.005684] [G loss: -0.010620]\n",
      "[Epoch 45/200] [Batch 14/44] [D loss: 0.005720] [G loss: -0.010621]\n",
      "[Epoch 45/200] [Batch 16/44] [D loss: 0.005457] [G loss: -0.010599]\n",
      "[Epoch 45/200] [Batch 18/44] [D loss: 0.005832] [G loss: -0.010622]\n",
      "[Epoch 45/200] [Batch 20/44] [D loss: 0.006031] [G loss: -0.010617]\n",
      "[Epoch 45/200] [Batch 22/44] [D loss: 0.007028] [G loss: -0.010602]\n",
      "[Epoch 45/200] [Batch 24/44] [D loss: 0.005673] [G loss: -0.010606]\n",
      "[Epoch 45/200] [Batch 26/44] [D loss: 0.004580] [G loss: -0.010627]\n",
      "[Epoch 45/200] [Batch 28/44] [D loss: 0.006030] [G loss: -0.010612]\n",
      "[Epoch 45/200] [Batch 30/44] [D loss: 0.004979] [G loss: -0.010626]\n",
      "[Epoch 45/200] [Batch 32/44] [D loss: 0.004406] [G loss: -0.010609]\n",
      "[Epoch 45/200] [Batch 34/44] [D loss: 0.005783] [G loss: -0.010631]\n",
      "[Epoch 45/200] [Batch 36/44] [D loss: 0.006108] [G loss: -0.010637]\n",
      "[Epoch 45/200] [Batch 38/44] [D loss: 0.006463] [G loss: -0.010610]\n",
      "[Epoch 45/200] [Batch 40/44] [D loss: 0.003954] [G loss: -0.010625]\n",
      "[Epoch 45/200] [Batch 42/44] [D loss: 0.005267] [G loss: -0.010631]\n",
      "[Epoch 46/200] [Batch 0/44] [D loss: 0.007212] [G loss: -0.010626]\n",
      "[Epoch 46/200] [Batch 2/44] [D loss: 0.006396] [G loss: -0.010614]\n",
      "[Epoch 46/200] [Batch 4/44] [D loss: 0.005683] [G loss: -0.010613]\n",
      "[Epoch 46/200] [Batch 6/44] [D loss: 0.006437] [G loss: -0.010646]\n",
      "[Epoch 46/200] [Batch 8/44] [D loss: 0.005674] [G loss: -0.010615]\n",
      "[Epoch 46/200] [Batch 10/44] [D loss: 0.002571] [G loss: -0.010617]\n",
      "[Epoch 46/200] [Batch 12/44] [D loss: 0.004371] [G loss: -0.010619]\n",
      "[Epoch 46/200] [Batch 14/44] [D loss: 0.003836] [G loss: -0.010641]\n",
      "[Epoch 46/200] [Batch 16/44] [D loss: 0.006742] [G loss: -0.010611]\n",
      "[Epoch 46/200] [Batch 18/44] [D loss: 0.006767] [G loss: -0.010620]\n",
      "[Epoch 46/200] [Batch 20/44] [D loss: 0.005594] [G loss: -0.010607]\n",
      "[Epoch 46/200] [Batch 22/44] [D loss: 0.007100] [G loss: -0.010614]\n",
      "[Epoch 46/200] [Batch 24/44] [D loss: 0.006205] [G loss: -0.010635]\n",
      "[Epoch 46/200] [Batch 26/44] [D loss: 0.006255] [G loss: -0.010646]\n",
      "[Epoch 46/200] [Batch 28/44] [D loss: 0.005081] [G loss: -0.010626]\n",
      "[Epoch 46/200] [Batch 30/44] [D loss: 0.004615] [G loss: -0.010636]\n",
      "[Epoch 46/200] [Batch 32/44] [D loss: 0.004891] [G loss: -0.010600]\n",
      "[Epoch 46/200] [Batch 34/44] [D loss: 0.006527] [G loss: -0.010612]\n",
      "[Epoch 46/200] [Batch 36/44] [D loss: 0.006374] [G loss: -0.010625]\n",
      "[Epoch 46/200] [Batch 38/44] [D loss: 0.006350] [G loss: -0.010599]\n",
      "[Epoch 46/200] [Batch 40/44] [D loss: 0.005676] [G loss: -0.010613]\n",
      "[Epoch 46/200] [Batch 42/44] [D loss: 0.005583] [G loss: -0.010596]\n",
      "[Epoch 47/200] [Batch 0/44] [D loss: 0.006188] [G loss: -0.010606]\n",
      "[Epoch 47/200] [Batch 2/44] [D loss: 0.005192] [G loss: -0.010604]\n",
      "[Epoch 47/200] [Batch 4/44] [D loss: 0.004932] [G loss: -0.010611]\n",
      "[Epoch 47/200] [Batch 6/44] [D loss: 0.006857] [G loss: -0.010605]\n",
      "[Epoch 47/200] [Batch 8/44] [D loss: 0.004948] [G loss: -0.010615]\n",
      "[Epoch 47/200] [Batch 10/44] [D loss: 0.005003] [G loss: -0.010619]\n",
      "[Epoch 47/200] [Batch 12/44] [D loss: 0.006571] [G loss: -0.010610]\n",
      "[Epoch 47/200] [Batch 14/44] [D loss: 0.006913] [G loss: -0.010601]\n",
      "[Epoch 47/200] [Batch 16/44] [D loss: 0.006693] [G loss: -0.010607]\n",
      "[Epoch 47/200] [Batch 18/44] [D loss: 0.006154] [G loss: -0.010625]\n",
      "[Epoch 47/200] [Batch 20/44] [D loss: 0.005783] [G loss: -0.010629]\n",
      "[Epoch 47/200] [Batch 22/44] [D loss: 0.005462] [G loss: -0.010621]\n",
      "[Epoch 47/200] [Batch 24/44] [D loss: 0.006490] [G loss: -0.010622]\n",
      "[Epoch 47/200] [Batch 26/44] [D loss: 0.005246] [G loss: -0.010632]\n",
      "[Epoch 47/200] [Batch 28/44] [D loss: 0.006007] [G loss: -0.010606]\n",
      "[Epoch 47/200] [Batch 30/44] [D loss: 0.006530] [G loss: -0.010613]\n",
      "[Epoch 47/200] [Batch 32/44] [D loss: 0.006607] [G loss: -0.010616]\n",
      "[Epoch 47/200] [Batch 34/44] [D loss: 0.006720] [G loss: -0.010626]\n",
      "[Epoch 47/200] [Batch 36/44] [D loss: 0.005302] [G loss: -0.010642]\n",
      "[Epoch 47/200] [Batch 38/44] [D loss: 0.006622] [G loss: -0.010615]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 47/200] [Batch 40/44] [D loss: 0.003772] [G loss: -0.010652]\n",
      "[Epoch 47/200] [Batch 42/44] [D loss: 0.006203] [G loss: -0.010602]\n",
      "[Epoch 48/200] [Batch 0/44] [D loss: 0.005328] [G loss: -0.010621]\n",
      "[Epoch 48/200] [Batch 2/44] [D loss: 0.006462] [G loss: -0.010620]\n",
      "[Epoch 48/200] [Batch 4/44] [D loss: 0.006580] [G loss: -0.010588]\n",
      "[Epoch 48/200] [Batch 6/44] [D loss: 0.005485] [G loss: -0.010616]\n",
      "[Epoch 48/200] [Batch 8/44] [D loss: 0.005439] [G loss: -0.010587]\n",
      "[Epoch 48/200] [Batch 10/44] [D loss: 0.006750] [G loss: -0.010615]\n",
      "[Epoch 48/200] [Batch 12/44] [D loss: 0.005280] [G loss: -0.010620]\n",
      "[Epoch 48/200] [Batch 14/44] [D loss: 0.006201] [G loss: -0.010607]\n",
      "[Epoch 48/200] [Batch 16/44] [D loss: 0.007329] [G loss: -0.010606]\n",
      "[Epoch 48/200] [Batch 18/44] [D loss: 0.005499] [G loss: -0.010612]\n",
      "[Epoch 48/200] [Batch 20/44] [D loss: 0.002643] [G loss: -0.010613]\n",
      "[Epoch 48/200] [Batch 22/44] [D loss: 0.004619] [G loss: -0.010634]\n",
      "[Epoch 48/200] [Batch 24/44] [D loss: 0.004156] [G loss: -0.010639]\n",
      "[Epoch 48/200] [Batch 26/44] [D loss: 0.007165] [G loss: -0.010618]\n",
      "[Epoch 48/200] [Batch 28/44] [D loss: 0.005052] [G loss: -0.010637]\n",
      "[Epoch 48/200] [Batch 30/44] [D loss: 0.006533] [G loss: -0.010616]\n",
      "[Epoch 48/200] [Batch 32/44] [D loss: 0.008692] [G loss: -0.010637]\n",
      "[Epoch 48/200] [Batch 34/44] [D loss: 0.003921] [G loss: -0.010610]\n",
      "[Epoch 48/200] [Batch 36/44] [D loss: 0.006290] [G loss: -0.010630]\n",
      "[Epoch 48/200] [Batch 38/44] [D loss: 0.006226] [G loss: -0.010606]\n",
      "[Epoch 48/200] [Batch 40/44] [D loss: 0.006687] [G loss: -0.010620]\n",
      "[Epoch 48/200] [Batch 42/44] [D loss: 0.006614] [G loss: -0.010643]\n",
      "[Epoch 49/200] [Batch 0/44] [D loss: 0.004698] [G loss: -0.010621]\n",
      "[Epoch 49/200] [Batch 2/44] [D loss: 0.003107] [G loss: -0.010620]\n",
      "[Epoch 49/200] [Batch 4/44] [D loss: 0.008447] [G loss: -0.010638]\n",
      "[Epoch 49/200] [Batch 6/44] [D loss: 0.005721] [G loss: -0.010592]\n",
      "[Epoch 49/200] [Batch 8/44] [D loss: 0.008234] [G loss: -0.010629]\n",
      "[Epoch 49/200] [Batch 10/44] [D loss: 0.005563] [G loss: -0.010624]\n",
      "[Epoch 49/200] [Batch 12/44] [D loss: 0.005983] [G loss: -0.010639]\n",
      "[Epoch 49/200] [Batch 14/44] [D loss: 0.005707] [G loss: -0.010628]\n",
      "[Epoch 49/200] [Batch 16/44] [D loss: 0.003949] [G loss: -0.010635]\n",
      "[Epoch 49/200] [Batch 18/44] [D loss: 0.003854] [G loss: -0.010602]\n",
      "[Epoch 49/200] [Batch 20/44] [D loss: 0.005161] [G loss: -0.010619]\n",
      "[Epoch 49/200] [Batch 22/44] [D loss: 0.004561] [G loss: -0.010612]\n",
      "[Epoch 49/200] [Batch 24/44] [D loss: 0.005645] [G loss: -0.010604]\n",
      "[Epoch 49/200] [Batch 26/44] [D loss: 0.006078] [G loss: -0.010622]\n",
      "[Epoch 49/200] [Batch 28/44] [D loss: 0.004055] [G loss: -0.010637]\n",
      "[Epoch 49/200] [Batch 30/44] [D loss: 0.004839] [G loss: -0.010624]\n",
      "[Epoch 49/200] [Batch 32/44] [D loss: 0.004157] [G loss: -0.010617]\n",
      "[Epoch 49/200] [Batch 34/44] [D loss: 0.006611] [G loss: -0.010613]\n",
      "[Epoch 49/200] [Batch 36/44] [D loss: 0.006443] [G loss: -0.010617]\n",
      "[Epoch 49/200] [Batch 38/44] [D loss: 0.004789] [G loss: -0.010620]\n",
      "[Epoch 49/200] [Batch 40/44] [D loss: 0.005863] [G loss: -0.010610]\n",
      "[Epoch 49/200] [Batch 42/44] [D loss: 0.005626] [G loss: -0.010626]\n",
      "[Epoch 50/200] [Batch 0/44] [D loss: 0.005236] [G loss: -0.010611]\n",
      "[Epoch 50/200] [Batch 2/44] [D loss: 0.004683] [G loss: -0.010623]\n",
      "[Epoch 50/200] [Batch 4/44] [D loss: 0.004362] [G loss: -0.010611]\n",
      "[Epoch 50/200] [Batch 6/44] [D loss: 0.005452] [G loss: -0.010619]\n",
      "[Epoch 50/200] [Batch 8/44] [D loss: 0.005202] [G loss: -0.010643]\n",
      "[Epoch 50/200] [Batch 10/44] [D loss: 0.004939] [G loss: -0.010597]\n",
      "[Epoch 50/200] [Batch 12/44] [D loss: 0.005799] [G loss: -0.010604]\n",
      "[Epoch 50/200] [Batch 14/44] [D loss: 0.005147] [G loss: -0.010611]\n",
      "[Epoch 50/200] [Batch 16/44] [D loss: 0.007615] [G loss: -0.010607]\n",
      "[Epoch 50/200] [Batch 18/44] [D loss: 0.007949] [G loss: -0.010616]\n",
      "[Epoch 50/200] [Batch 20/44] [D loss: 0.005997] [G loss: -0.010590]\n",
      "[Epoch 50/200] [Batch 22/44] [D loss: 0.004138] [G loss: -0.010620]\n",
      "[Epoch 50/200] [Batch 24/44] [D loss: 0.007383] [G loss: -0.010616]\n",
      "[Epoch 50/200] [Batch 26/44] [D loss: 0.006950] [G loss: -0.010623]\n",
      "[Epoch 50/200] [Batch 28/44] [D loss: 0.003059] [G loss: -0.010609]\n",
      "[Epoch 50/200] [Batch 30/44] [D loss: 0.006177] [G loss: -0.010592]\n",
      "[Epoch 50/200] [Batch 32/44] [D loss: 0.005924] [G loss: -0.010609]\n",
      "[Epoch 50/200] [Batch 34/44] [D loss: 0.006469] [G loss: -0.010608]\n",
      "[Epoch 50/200] [Batch 36/44] [D loss: 0.005272] [G loss: -0.010609]\n",
      "[Epoch 50/200] [Batch 38/44] [D loss: 0.005663] [G loss: -0.010633]\n",
      "[Epoch 50/200] [Batch 40/44] [D loss: 0.005156] [G loss: -0.010617]\n",
      "[Epoch 50/200] [Batch 42/44] [D loss: 0.005464] [G loss: -0.010615]\n",
      "[Epoch 51/200] [Batch 0/44] [D loss: 0.006319] [G loss: -0.010634]\n",
      "[Epoch 51/200] [Batch 2/44] [D loss: 0.006639] [G loss: -0.010607]\n",
      "[Epoch 51/200] [Batch 4/44] [D loss: 0.004841] [G loss: -0.010622]\n",
      "[Epoch 51/200] [Batch 6/44] [D loss: 0.004105] [G loss: -0.010625]\n",
      "[Epoch 51/200] [Batch 8/44] [D loss: 0.007361] [G loss: -0.010611]\n",
      "[Epoch 51/200] [Batch 10/44] [D loss: 0.004596] [G loss: -0.010612]\n",
      "[Epoch 51/200] [Batch 12/44] [D loss: 0.005132] [G loss: -0.010639]\n",
      "[Epoch 51/200] [Batch 14/44] [D loss: 0.004425] [G loss: -0.010616]\n",
      "[Epoch 51/200] [Batch 16/44] [D loss: 0.005776] [G loss: -0.010619]\n",
      "[Epoch 51/200] [Batch 18/44] [D loss: 0.007163] [G loss: -0.010622]\n",
      "[Epoch 51/200] [Batch 20/44] [D loss: 0.005597] [G loss: -0.010619]\n",
      "[Epoch 51/200] [Batch 22/44] [D loss: 0.004068] [G loss: -0.010607]\n",
      "[Epoch 51/200] [Batch 24/44] [D loss: 0.004955] [G loss: -0.010632]\n",
      "[Epoch 51/200] [Batch 26/44] [D loss: 0.006072] [G loss: -0.010614]\n",
      "[Epoch 51/200] [Batch 28/44] [D loss: 0.006857] [G loss: -0.010617]\n",
      "[Epoch 51/200] [Batch 30/44] [D loss: 0.006717] [G loss: -0.010610]\n",
      "[Epoch 51/200] [Batch 32/44] [D loss: 0.007036] [G loss: -0.010607]\n",
      "[Epoch 51/200] [Batch 34/44] [D loss: 0.006892] [G loss: -0.010622]\n",
      "[Epoch 51/200] [Batch 36/44] [D loss: 0.005038] [G loss: -0.010608]\n",
      "[Epoch 51/200] [Batch 38/44] [D loss: 0.004677] [G loss: -0.010628]\n",
      "[Epoch 51/200] [Batch 40/44] [D loss: 0.003987] [G loss: -0.010603]\n",
      "[Epoch 51/200] [Batch 42/44] [D loss: 0.005462] [G loss: -0.010622]\n",
      "[Epoch 52/200] [Batch 0/44] [D loss: 0.004769] [G loss: -0.010634]\n",
      "[Epoch 52/200] [Batch 2/44] [D loss: 0.005554] [G loss: -0.010623]\n",
      "[Epoch 52/200] [Batch 4/44] [D loss: 0.004186] [G loss: -0.010611]\n",
      "[Epoch 52/200] [Batch 6/44] [D loss: 0.006845] [G loss: -0.010603]\n",
      "[Epoch 52/200] [Batch 8/44] [D loss: 0.006538] [G loss: -0.010612]\n",
      "[Epoch 52/200] [Batch 10/44] [D loss: 0.003899] [G loss: -0.010619]\n",
      "[Epoch 52/200] [Batch 12/44] [D loss: 0.006290] [G loss: -0.010627]\n",
      "[Epoch 52/200] [Batch 14/44] [D loss: 0.004854] [G loss: -0.010611]\n",
      "[Epoch 52/200] [Batch 16/44] [D loss: 0.005490] [G loss: -0.010618]\n",
      "[Epoch 52/200] [Batch 18/44] [D loss: 0.004200] [G loss: -0.010618]\n",
      "[Epoch 52/200] [Batch 20/44] [D loss: 0.006716] [G loss: -0.010609]\n",
      "[Epoch 52/200] [Batch 22/44] [D loss: 0.007577] [G loss: -0.010627]\n",
      "[Epoch 52/200] [Batch 24/44] [D loss: 0.006626] [G loss: -0.010629]\n",
      "[Epoch 52/200] [Batch 26/44] [D loss: 0.006627] [G loss: -0.010627]\n",
      "[Epoch 52/200] [Batch 28/44] [D loss: 0.004947] [G loss: -0.010616]\n",
      "[Epoch 52/200] [Batch 30/44] [D loss: 0.004564] [G loss: -0.010608]\n",
      "[Epoch 52/200] [Batch 32/44] [D loss: 0.003149] [G loss: -0.010603]\n",
      "[Epoch 52/200] [Batch 34/44] [D loss: 0.004798] [G loss: -0.010641]\n",
      "[Epoch 52/200] [Batch 36/44] [D loss: 0.003804] [G loss: -0.010630]\n",
      "[Epoch 52/200] [Batch 38/44] [D loss: 0.004751] [G loss: -0.010605]\n",
      "[Epoch 52/200] [Batch 40/44] [D loss: 0.006793] [G loss: -0.010633]\n",
      "[Epoch 52/200] [Batch 42/44] [D loss: 0.004616] [G loss: -0.010634]\n",
      "[Epoch 53/200] [Batch 0/44] [D loss: 0.005567] [G loss: -0.010611]\n",
      "[Epoch 53/200] [Batch 2/44] [D loss: 0.006143] [G loss: -0.010613]\n",
      "[Epoch 53/200] [Batch 4/44] [D loss: 0.006902] [G loss: -0.010637]\n",
      "[Epoch 53/200] [Batch 6/44] [D loss: 0.006200] [G loss: -0.010632]\n",
      "[Epoch 53/200] [Batch 8/44] [D loss: 0.005869] [G loss: -0.010593]\n",
      "[Epoch 53/200] [Batch 10/44] [D loss: 0.006955] [G loss: -0.010619]\n",
      "[Epoch 53/200] [Batch 12/44] [D loss: 0.005360] [G loss: -0.010615]\n",
      "[Epoch 53/200] [Batch 14/44] [D loss: 0.005832] [G loss: -0.010616]\n",
      "[Epoch 53/200] [Batch 16/44] [D loss: 0.006238] [G loss: -0.010640]\n",
      "[Epoch 53/200] [Batch 18/44] [D loss: 0.005886] [G loss: -0.010613]\n",
      "[Epoch 53/200] [Batch 20/44] [D loss: 0.007845] [G loss: -0.010617]\n",
      "[Epoch 53/200] [Batch 22/44] [D loss: 0.003902] [G loss: -0.010603]\n",
      "[Epoch 53/200] [Batch 24/44] [D loss: 0.003546] [G loss: -0.010622]\n",
      "[Epoch 53/200] [Batch 26/44] [D loss: 0.004841] [G loss: -0.010631]\n",
      "[Epoch 53/200] [Batch 28/44] [D loss: 0.005828] [G loss: -0.010631]\n",
      "[Epoch 53/200] [Batch 30/44] [D loss: 0.006728] [G loss: -0.010627]\n",
      "[Epoch 53/200] [Batch 32/44] [D loss: 0.005984] [G loss: -0.010619]\n",
      "[Epoch 53/200] [Batch 34/44] [D loss: 0.003049] [G loss: -0.010625]\n",
      "[Epoch 53/200] [Batch 36/44] [D loss: 0.005864] [G loss: -0.010619]\n",
      "[Epoch 53/200] [Batch 38/44] [D loss: 0.006194] [G loss: -0.010595]\n",
      "[Epoch 53/200] [Batch 40/44] [D loss: 0.004165] [G loss: -0.010619]\n",
      "[Epoch 53/200] [Batch 42/44] [D loss: 0.005496] [G loss: -0.010635]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 54/200] [Batch 0/44] [D loss: 0.007586] [G loss: -0.010632]\n",
      "[Epoch 54/200] [Batch 2/44] [D loss: 0.006645] [G loss: -0.010615]\n",
      "[Epoch 54/200] [Batch 4/44] [D loss: 0.006400] [G loss: -0.010639]\n",
      "[Epoch 54/200] [Batch 6/44] [D loss: 0.005048] [G loss: -0.010613]\n",
      "[Epoch 54/200] [Batch 8/44] [D loss: 0.004709] [G loss: -0.010615]\n",
      "[Epoch 54/200] [Batch 10/44] [D loss: 0.005245] [G loss: -0.010579]\n",
      "[Epoch 54/200] [Batch 12/44] [D loss: 0.006292] [G loss: -0.010629]\n",
      "[Epoch 54/200] [Batch 14/44] [D loss: 0.005896] [G loss: -0.010624]\n",
      "[Epoch 54/200] [Batch 16/44] [D loss: 0.005922] [G loss: -0.010618]\n",
      "[Epoch 54/200] [Batch 18/44] [D loss: 0.003023] [G loss: -0.010599]\n",
      "[Epoch 54/200] [Batch 20/44] [D loss: 0.005089] [G loss: -0.010617]\n",
      "[Epoch 54/200] [Batch 22/44] [D loss: 0.005713] [G loss: -0.010628]\n",
      "[Epoch 54/200] [Batch 24/44] [D loss: 0.006553] [G loss: -0.010625]\n",
      "[Epoch 54/200] [Batch 26/44] [D loss: 0.004985] [G loss: -0.010598]\n",
      "[Epoch 54/200] [Batch 28/44] [D loss: 0.005978] [G loss: -0.010610]\n",
      "[Epoch 54/200] [Batch 30/44] [D loss: 0.006006] [G loss: -0.010637]\n",
      "[Epoch 54/200] [Batch 32/44] [D loss: 0.004728] [G loss: -0.010618]\n",
      "[Epoch 54/200] [Batch 34/44] [D loss: 0.004755] [G loss: -0.010620]\n",
      "[Epoch 54/200] [Batch 36/44] [D loss: 0.005444] [G loss: -0.010617]\n",
      "[Epoch 54/200] [Batch 38/44] [D loss: 0.007204] [G loss: -0.010612]\n",
      "[Epoch 54/200] [Batch 40/44] [D loss: 0.004989] [G loss: -0.010603]\n",
      "[Epoch 54/200] [Batch 42/44] [D loss: 0.004184] [G loss: -0.010627]\n",
      "[Epoch 55/200] [Batch 0/44] [D loss: 0.004478] [G loss: -0.010615]\n",
      "[Epoch 55/200] [Batch 2/44] [D loss: 0.005754] [G loss: -0.010617]\n",
      "[Epoch 55/200] [Batch 4/44] [D loss: 0.004183] [G loss: -0.010616]\n",
      "[Epoch 55/200] [Batch 6/44] [D loss: 0.006664] [G loss: -0.010613]\n",
      "[Epoch 55/200] [Batch 8/44] [D loss: 0.006971] [G loss: -0.010615]\n",
      "[Epoch 55/200] [Batch 10/44] [D loss: 0.004453] [G loss: -0.010611]\n",
      "[Epoch 55/200] [Batch 12/44] [D loss: 0.004288] [G loss: -0.010606]\n",
      "[Epoch 55/200] [Batch 14/44] [D loss: 0.005550] [G loss: -0.010598]\n",
      "[Epoch 55/200] [Batch 16/44] [D loss: 0.004904] [G loss: -0.010618]\n",
      "[Epoch 55/200] [Batch 18/44] [D loss: 0.001779] [G loss: -0.010631]\n",
      "[Epoch 55/200] [Batch 20/44] [D loss: 0.006199] [G loss: -0.010599]\n",
      "[Epoch 55/200] [Batch 22/44] [D loss: 0.006462] [G loss: -0.010621]\n",
      "[Epoch 55/200] [Batch 24/44] [D loss: 0.006251] [G loss: -0.010631]\n",
      "[Epoch 55/200] [Batch 26/44] [D loss: 0.004187] [G loss: -0.010607]\n",
      "[Epoch 55/200] [Batch 28/44] [D loss: 0.005624] [G loss: -0.010606]\n",
      "[Epoch 55/200] [Batch 30/44] [D loss: 0.004519] [G loss: -0.010621]\n",
      "[Epoch 55/200] [Batch 32/44] [D loss: 0.005304] [G loss: -0.010621]\n",
      "[Epoch 55/200] [Batch 34/44] [D loss: 0.005591] [G loss: -0.010611]\n",
      "[Epoch 55/200] [Batch 36/44] [D loss: 0.006186] [G loss: -0.010615]\n",
      "[Epoch 55/200] [Batch 38/44] [D loss: 0.005294] [G loss: -0.010599]\n",
      "[Epoch 55/200] [Batch 40/44] [D loss: 0.006095] [G loss: -0.010634]\n",
      "[Epoch 55/200] [Batch 42/44] [D loss: 0.006570] [G loss: -0.010614]\n",
      "[Epoch 56/200] [Batch 0/44] [D loss: 0.002443] [G loss: -0.010642]\n",
      "[Epoch 56/200] [Batch 2/44] [D loss: 0.005986] [G loss: -0.010583]\n",
      "[Epoch 56/200] [Batch 4/44] [D loss: 0.007018] [G loss: -0.010617]\n",
      "[Epoch 56/200] [Batch 6/44] [D loss: 0.006743] [G loss: -0.010614]\n",
      "[Epoch 56/200] [Batch 8/44] [D loss: 0.005230] [G loss: -0.010623]\n",
      "[Epoch 56/200] [Batch 10/44] [D loss: 0.006072] [G loss: -0.010616]\n",
      "[Epoch 56/200] [Batch 12/44] [D loss: 0.005456] [G loss: -0.010622]\n",
      "[Epoch 56/200] [Batch 14/44] [D loss: 0.005690] [G loss: -0.010601]\n",
      "[Epoch 56/200] [Batch 16/44] [D loss: 0.005732] [G loss: -0.010602]\n",
      "[Epoch 56/200] [Batch 18/44] [D loss: 0.005088] [G loss: -0.010621]\n",
      "[Epoch 56/200] [Batch 20/44] [D loss: 0.004821] [G loss: -0.010605]\n",
      "[Epoch 56/200] [Batch 22/44] [D loss: 0.005173] [G loss: -0.010603]\n",
      "[Epoch 56/200] [Batch 24/44] [D loss: 0.006856] [G loss: -0.010612]\n",
      "[Epoch 56/200] [Batch 26/44] [D loss: 0.004844] [G loss: -0.010606]\n",
      "[Epoch 56/200] [Batch 28/44] [D loss: 0.004623] [G loss: -0.010633]\n",
      "[Epoch 56/200] [Batch 30/44] [D loss: 0.005866] [G loss: -0.010592]\n",
      "[Epoch 56/200] [Batch 32/44] [D loss: 0.007465] [G loss: -0.010592]\n",
      "[Epoch 56/200] [Batch 34/44] [D loss: 0.006645] [G loss: -0.010597]\n",
      "[Epoch 56/200] [Batch 36/44] [D loss: 0.007096] [G loss: -0.010625]\n",
      "[Epoch 56/200] [Batch 38/44] [D loss: 0.004633] [G loss: -0.010614]\n",
      "[Epoch 56/200] [Batch 40/44] [D loss: 0.007845] [G loss: -0.010610]\n",
      "[Epoch 56/200] [Batch 42/44] [D loss: 0.005480] [G loss: -0.010606]\n",
      "[Epoch 57/200] [Batch 0/44] [D loss: 0.004310] [G loss: -0.010632]\n",
      "[Epoch 57/200] [Batch 2/44] [D loss: 0.005647] [G loss: -0.010603]\n",
      "[Epoch 57/200] [Batch 4/44] [D loss: 0.006536] [G loss: -0.010619]\n",
      "[Epoch 57/200] [Batch 6/44] [D loss: 0.006483] [G loss: -0.010626]\n",
      "[Epoch 57/200] [Batch 8/44] [D loss: 0.004513] [G loss: -0.010630]\n",
      "[Epoch 57/200] [Batch 10/44] [D loss: 0.005061] [G loss: -0.010628]\n",
      "[Epoch 57/200] [Batch 12/44] [D loss: 0.004258] [G loss: -0.010592]\n",
      "[Epoch 57/200] [Batch 14/44] [D loss: 0.005933] [G loss: -0.010628]\n",
      "[Epoch 57/200] [Batch 16/44] [D loss: 0.006503] [G loss: -0.010617]\n",
      "[Epoch 57/200] [Batch 18/44] [D loss: 0.005786] [G loss: -0.010592]\n",
      "[Epoch 57/200] [Batch 20/44] [D loss: 0.005296] [G loss: -0.010604]\n",
      "[Epoch 57/200] [Batch 22/44] [D loss: 0.006736] [G loss: -0.010631]\n",
      "[Epoch 57/200] [Batch 24/44] [D loss: 0.006204] [G loss: -0.010618]\n",
      "[Epoch 57/200] [Batch 26/44] [D loss: 0.006512] [G loss: -0.010602]\n",
      "[Epoch 57/200] [Batch 28/44] [D loss: 0.006672] [G loss: -0.010624]\n",
      "[Epoch 57/200] [Batch 30/44] [D loss: 0.004282] [G loss: -0.010630]\n",
      "[Epoch 57/200] [Batch 32/44] [D loss: 0.005392] [G loss: -0.010604]\n",
      "[Epoch 57/200] [Batch 34/44] [D loss: 0.005824] [G loss: -0.010599]\n",
      "[Epoch 57/200] [Batch 36/44] [D loss: 0.005205] [G loss: -0.010622]\n",
      "[Epoch 57/200] [Batch 38/44] [D loss: 0.004893] [G loss: -0.010607]\n",
      "[Epoch 57/200] [Batch 40/44] [D loss: 0.006186] [G loss: -0.010609]\n",
      "[Epoch 57/200] [Batch 42/44] [D loss: 0.004175] [G loss: -0.010613]\n",
      "[Epoch 58/200] [Batch 0/44] [D loss: 0.007718] [G loss: -0.010606]\n",
      "[Epoch 58/200] [Batch 2/44] [D loss: 0.006133] [G loss: -0.010606]\n",
      "[Epoch 58/200] [Batch 4/44] [D loss: 0.005653] [G loss: -0.010616]\n",
      "[Epoch 58/200] [Batch 6/44] [D loss: 0.005247] [G loss: -0.010606]\n",
      "[Epoch 58/200] [Batch 8/44] [D loss: 0.004595] [G loss: -0.010623]\n",
      "[Epoch 58/200] [Batch 10/44] [D loss: 0.005770] [G loss: -0.010632]\n",
      "[Epoch 58/200] [Batch 12/44] [D loss: 0.003879] [G loss: -0.010611]\n",
      "[Epoch 58/200] [Batch 14/44] [D loss: 0.006536] [G loss: -0.010619]\n",
      "[Epoch 58/200] [Batch 16/44] [D loss: 0.006477] [G loss: -0.010626]\n",
      "[Epoch 58/200] [Batch 18/44] [D loss: 0.003268] [G loss: -0.010619]\n",
      "[Epoch 58/200] [Batch 20/44] [D loss: 0.004469] [G loss: -0.010607]\n",
      "[Epoch 58/200] [Batch 22/44] [D loss: 0.004952] [G loss: -0.010607]\n",
      "[Epoch 58/200] [Batch 24/44] [D loss: 0.004243] [G loss: -0.010619]\n",
      "[Epoch 58/200] [Batch 26/44] [D loss: 0.006172] [G loss: -0.010604]\n",
      "[Epoch 58/200] [Batch 28/44] [D loss: 0.007338] [G loss: -0.010631]\n",
      "[Epoch 58/200] [Batch 30/44] [D loss: 0.007500] [G loss: -0.010621]\n",
      "[Epoch 58/200] [Batch 32/44] [D loss: 0.004992] [G loss: -0.010594]\n",
      "[Epoch 58/200] [Batch 34/44] [D loss: 0.004004] [G loss: -0.010603]\n",
      "[Epoch 58/200] [Batch 36/44] [D loss: 0.005488] [G loss: -0.010601]\n",
      "[Epoch 58/200] [Batch 38/44] [D loss: 0.004187] [G loss: -0.010624]\n",
      "[Epoch 58/200] [Batch 40/44] [D loss: 0.005705] [G loss: -0.010612]\n",
      "[Epoch 58/200] [Batch 42/44] [D loss: 0.005176] [G loss: -0.010621]\n",
      "[Epoch 59/200] [Batch 0/44] [D loss: 0.004145] [G loss: -0.010618]\n",
      "[Epoch 59/200] [Batch 2/44] [D loss: 0.003664] [G loss: -0.010619]\n",
      "[Epoch 59/200] [Batch 4/44] [D loss: 0.006064] [G loss: -0.010622]\n",
      "[Epoch 59/200] [Batch 6/44] [D loss: 0.007346] [G loss: -0.010622]\n",
      "[Epoch 59/200] [Batch 8/44] [D loss: 0.004814] [G loss: -0.010618]\n",
      "[Epoch 59/200] [Batch 10/44] [D loss: 0.004440] [G loss: -0.010612]\n",
      "[Epoch 59/200] [Batch 12/44] [D loss: 0.004989] [G loss: -0.010631]\n",
      "[Epoch 59/200] [Batch 14/44] [D loss: 0.006159] [G loss: -0.010607]\n",
      "[Epoch 59/200] [Batch 16/44] [D loss: 0.005568] [G loss: -0.010645]\n",
      "[Epoch 59/200] [Batch 18/44] [D loss: 0.005434] [G loss: -0.010607]\n",
      "[Epoch 59/200] [Batch 20/44] [D loss: 0.004108] [G loss: -0.010608]\n",
      "[Epoch 59/200] [Batch 22/44] [D loss: 0.006511] [G loss: -0.010623]\n",
      "[Epoch 59/200] [Batch 24/44] [D loss: 0.004087] [G loss: -0.010618]\n",
      "[Epoch 59/200] [Batch 26/44] [D loss: 0.006109] [G loss: -0.010609]\n",
      "[Epoch 59/200] [Batch 28/44] [D loss: 0.004987] [G loss: -0.010629]\n",
      "[Epoch 59/200] [Batch 30/44] [D loss: 0.006036] [G loss: -0.010620]\n",
      "[Epoch 59/200] [Batch 32/44] [D loss: 0.005556] [G loss: -0.010613]\n",
      "[Epoch 59/200] [Batch 34/44] [D loss: 0.008250] [G loss: -0.010626]\n",
      "[Epoch 59/200] [Batch 36/44] [D loss: 0.005309] [G loss: -0.010605]\n",
      "[Epoch 59/200] [Batch 38/44] [D loss: 0.004388] [G loss: -0.010603]\n",
      "[Epoch 59/200] [Batch 40/44] [D loss: 0.006141] [G loss: -0.010608]\n",
      "[Epoch 59/200] [Batch 42/44] [D loss: 0.007361] [G loss: -0.010650]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 60/200] [Batch 0/44] [D loss: 0.005597] [G loss: -0.010630]\n",
      "[Epoch 60/200] [Batch 2/44] [D loss: 0.005707] [G loss: -0.010617]\n",
      "[Epoch 60/200] [Batch 4/44] [D loss: 0.004291] [G loss: -0.010611]\n",
      "[Epoch 60/200] [Batch 6/44] [D loss: 0.006552] [G loss: -0.010618]\n",
      "[Epoch 60/200] [Batch 8/44] [D loss: 0.004662] [G loss: -0.010613]\n",
      "[Epoch 60/200] [Batch 10/44] [D loss: 0.003305] [G loss: -0.010611]\n",
      "[Epoch 60/200] [Batch 12/44] [D loss: 0.006834] [G loss: -0.010605]\n",
      "[Epoch 60/200] [Batch 14/44] [D loss: 0.004787] [G loss: -0.010613]\n",
      "[Epoch 60/200] [Batch 16/44] [D loss: 0.003794] [G loss: -0.010633]\n",
      "[Epoch 60/200] [Batch 18/44] [D loss: 0.006818] [G loss: -0.010631]\n",
      "[Epoch 60/200] [Batch 20/44] [D loss: 0.004407] [G loss: -0.010607]\n",
      "[Epoch 60/200] [Batch 22/44] [D loss: 0.007469] [G loss: -0.010619]\n",
      "[Epoch 60/200] [Batch 24/44] [D loss: 0.004562] [G loss: -0.010620]\n",
      "[Epoch 60/200] [Batch 26/44] [D loss: 0.006701] [G loss: -0.010595]\n",
      "[Epoch 60/200] [Batch 28/44] [D loss: 0.004857] [G loss: -0.010613]\n",
      "[Epoch 60/200] [Batch 30/44] [D loss: 0.003264] [G loss: -0.010641]\n",
      "[Epoch 60/200] [Batch 32/44] [D loss: 0.004672] [G loss: -0.010595]\n",
      "[Epoch 60/200] [Batch 34/44] [D loss: 0.006509] [G loss: -0.010612]\n",
      "[Epoch 60/200] [Batch 36/44] [D loss: 0.006318] [G loss: -0.010628]\n",
      "[Epoch 60/200] [Batch 38/44] [D loss: 0.007394] [G loss: -0.010596]\n",
      "[Epoch 60/200] [Batch 40/44] [D loss: 0.004932] [G loss: -0.010613]\n",
      "[Epoch 60/200] [Batch 42/44] [D loss: 0.004529] [G loss: -0.010616]\n",
      "[Epoch 61/200] [Batch 0/44] [D loss: 0.006102] [G loss: -0.010623]\n",
      "[Epoch 61/200] [Batch 2/44] [D loss: 0.005590] [G loss: -0.010614]\n",
      "[Epoch 61/200] [Batch 4/44] [D loss: 0.005217] [G loss: -0.010625]\n",
      "[Epoch 61/200] [Batch 6/44] [D loss: 0.005793] [G loss: -0.010603]\n",
      "[Epoch 61/200] [Batch 8/44] [D loss: 0.005318] [G loss: -0.010610]\n",
      "[Epoch 61/200] [Batch 10/44] [D loss: 0.006651] [G loss: -0.010603]\n",
      "[Epoch 61/200] [Batch 12/44] [D loss: 0.005683] [G loss: -0.010624]\n",
      "[Epoch 61/200] [Batch 14/44] [D loss: 0.007325] [G loss: -0.010601]\n",
      "[Epoch 61/200] [Batch 16/44] [D loss: 0.004393] [G loss: -0.010620]\n",
      "[Epoch 61/200] [Batch 18/44] [D loss: 0.005122] [G loss: -0.010652]\n",
      "[Epoch 61/200] [Batch 20/44] [D loss: 0.005038] [G loss: -0.010610]\n",
      "[Epoch 61/200] [Batch 22/44] [D loss: 0.005580] [G loss: -0.010600]\n",
      "[Epoch 61/200] [Batch 24/44] [D loss: 0.006028] [G loss: -0.010617]\n",
      "[Epoch 61/200] [Batch 26/44] [D loss: 0.006246] [G loss: -0.010618]\n",
      "[Epoch 61/200] [Batch 28/44] [D loss: 0.007000] [G loss: -0.010615]\n",
      "[Epoch 61/200] [Batch 30/44] [D loss: 0.005091] [G loss: -0.010603]\n",
      "[Epoch 61/200] [Batch 32/44] [D loss: 0.006514] [G loss: -0.010607]\n",
      "[Epoch 61/200] [Batch 34/44] [D loss: 0.005433] [G loss: -0.010653]\n",
      "[Epoch 61/200] [Batch 36/44] [D loss: 0.005884] [G loss: -0.010632]\n",
      "[Epoch 61/200] [Batch 38/44] [D loss: 0.005700] [G loss: -0.010617]\n",
      "[Epoch 61/200] [Batch 40/44] [D loss: 0.007179] [G loss: -0.010618]\n",
      "[Epoch 61/200] [Batch 42/44] [D loss: 0.004989] [G loss: -0.010623]\n",
      "[Epoch 62/200] [Batch 0/44] [D loss: 0.005217] [G loss: -0.010610]\n",
      "[Epoch 62/200] [Batch 2/44] [D loss: 0.005277] [G loss: -0.010622]\n",
      "[Epoch 62/200] [Batch 4/44] [D loss: 0.007417] [G loss: -0.010629]\n",
      "[Epoch 62/200] [Batch 6/44] [D loss: 0.005901] [G loss: -0.010621]\n",
      "[Epoch 62/200] [Batch 8/44] [D loss: 0.005842] [G loss: -0.010608]\n",
      "[Epoch 62/200] [Batch 10/44] [D loss: 0.004687] [G loss: -0.010620]\n",
      "[Epoch 62/200] [Batch 12/44] [D loss: 0.004307] [G loss: -0.010624]\n",
      "[Epoch 62/200] [Batch 14/44] [D loss: 0.006371] [G loss: -0.010608]\n",
      "[Epoch 62/200] [Batch 16/44] [D loss: 0.004278] [G loss: -0.010612]\n",
      "[Epoch 62/200] [Batch 18/44] [D loss: 0.005579] [G loss: -0.010641]\n",
      "[Epoch 62/200] [Batch 20/44] [D loss: 0.004611] [G loss: -0.010629]\n",
      "[Epoch 62/200] [Batch 22/44] [D loss: 0.005342] [G loss: -0.010628]\n",
      "[Epoch 62/200] [Batch 24/44] [D loss: 0.006962] [G loss: -0.010633]\n",
      "[Epoch 62/200] [Batch 26/44] [D loss: 0.005747] [G loss: -0.010617]\n",
      "[Epoch 62/200] [Batch 28/44] [D loss: 0.004183] [G loss: -0.010602]\n",
      "[Epoch 62/200] [Batch 30/44] [D loss: 0.005756] [G loss: -0.010623]\n",
      "[Epoch 62/200] [Batch 32/44] [D loss: 0.003569] [G loss: -0.010619]\n",
      "[Epoch 62/200] [Batch 34/44] [D loss: 0.005303] [G loss: -0.010621]\n",
      "[Epoch 62/200] [Batch 36/44] [D loss: 0.004842] [G loss: -0.010631]\n",
      "[Epoch 62/200] [Batch 38/44] [D loss: 0.006931] [G loss: -0.010608]\n",
      "[Epoch 62/200] [Batch 40/44] [D loss: 0.006240] [G loss: -0.010624]\n",
      "[Epoch 62/200] [Batch 42/44] [D loss: 0.007145] [G loss: -0.010627]\n",
      "[Epoch 63/200] [Batch 0/44] [D loss: 0.004336] [G loss: -0.010600]\n",
      "[Epoch 63/200] [Batch 2/44] [D loss: 0.004262] [G loss: -0.010616]\n",
      "[Epoch 63/200] [Batch 4/44] [D loss: 0.007796] [G loss: -0.010602]\n",
      "[Epoch 63/200] [Batch 6/44] [D loss: 0.006609] [G loss: -0.010600]\n",
      "[Epoch 63/200] [Batch 8/44] [D loss: 0.002657] [G loss: -0.010620]\n",
      "[Epoch 63/200] [Batch 10/44] [D loss: 0.005081] [G loss: -0.010628]\n",
      "[Epoch 63/200] [Batch 12/44] [D loss: 0.003706] [G loss: -0.010615]\n",
      "[Epoch 63/200] [Batch 14/44] [D loss: 0.006823] [G loss: -0.010610]\n",
      "[Epoch 63/200] [Batch 16/44] [D loss: 0.004828] [G loss: -0.010620]\n",
      "[Epoch 63/200] [Batch 18/44] [D loss: 0.005856] [G loss: -0.010604]\n",
      "[Epoch 63/200] [Batch 20/44] [D loss: 0.005442] [G loss: -0.010603]\n",
      "[Epoch 63/200] [Batch 22/44] [D loss: 0.004179] [G loss: -0.010610]\n",
      "[Epoch 63/200] [Batch 24/44] [D loss: 0.006827] [G loss: -0.010620]\n",
      "[Epoch 63/200] [Batch 26/44] [D loss: 0.004116] [G loss: -0.010601]\n",
      "[Epoch 63/200] [Batch 28/44] [D loss: 0.003472] [G loss: -0.010628]\n",
      "[Epoch 63/200] [Batch 30/44] [D loss: 0.004732] [G loss: -0.010609]\n",
      "[Epoch 63/200] [Batch 32/44] [D loss: 0.005534] [G loss: -0.010613]\n",
      "[Epoch 63/200] [Batch 34/44] [D loss: 0.004771] [G loss: -0.010608]\n",
      "[Epoch 63/200] [Batch 36/44] [D loss: 0.006615] [G loss: -0.010619]\n",
      "[Epoch 63/200] [Batch 38/44] [D loss: 0.005823] [G loss: -0.010613]\n",
      "[Epoch 63/200] [Batch 40/44] [D loss: 0.006270] [G loss: -0.010614]\n",
      "[Epoch 63/200] [Batch 42/44] [D loss: 0.006931] [G loss: -0.010629]\n",
      "[Epoch 64/200] [Batch 0/44] [D loss: 0.004169] [G loss: -0.010598]\n",
      "[Epoch 64/200] [Batch 2/44] [D loss: 0.007922] [G loss: -0.010620]\n",
      "[Epoch 64/200] [Batch 4/44] [D loss: 0.006946] [G loss: -0.010624]\n",
      "[Epoch 64/200] [Batch 6/44] [D loss: 0.005187] [G loss: -0.010614]\n",
      "[Epoch 64/200] [Batch 8/44] [D loss: 0.006899] [G loss: -0.010620]\n",
      "[Epoch 64/200] [Batch 10/44] [D loss: 0.004952] [G loss: -0.010610]\n",
      "[Epoch 64/200] [Batch 12/44] [D loss: 0.005382] [G loss: -0.010613]\n",
      "[Epoch 64/200] [Batch 14/44] [D loss: 0.005964] [G loss: -0.010645]\n",
      "[Epoch 64/200] [Batch 16/44] [D loss: 0.005052] [G loss: -0.010618]\n",
      "[Epoch 64/200] [Batch 18/44] [D loss: 0.007934] [G loss: -0.010627]\n",
      "[Epoch 64/200] [Batch 20/44] [D loss: 0.007690] [G loss: -0.010603]\n",
      "[Epoch 64/200] [Batch 22/44] [D loss: 0.004765] [G loss: -0.010620]\n",
      "[Epoch 64/200] [Batch 24/44] [D loss: 0.007044] [G loss: -0.010631]\n",
      "[Epoch 64/200] [Batch 26/44] [D loss: 0.005836] [G loss: -0.010624]\n",
      "[Epoch 64/200] [Batch 28/44] [D loss: 0.007272] [G loss: -0.010612]\n",
      "[Epoch 64/200] [Batch 30/44] [D loss: 0.006096] [G loss: -0.010634]\n",
      "[Epoch 64/200] [Batch 32/44] [D loss: 0.006513] [G loss: -0.010615]\n",
      "[Epoch 64/200] [Batch 34/44] [D loss: 0.004163] [G loss: -0.010608]\n",
      "[Epoch 64/200] [Batch 36/44] [D loss: 0.004667] [G loss: -0.010615]\n",
      "[Epoch 64/200] [Batch 38/44] [D loss: 0.005543] [G loss: -0.010626]\n",
      "[Epoch 64/200] [Batch 40/44] [D loss: 0.006501] [G loss: -0.010619]\n",
      "[Epoch 64/200] [Batch 42/44] [D loss: 0.004964] [G loss: -0.010625]\n",
      "[Epoch 65/200] [Batch 0/44] [D loss: 0.007021] [G loss: -0.010600]\n",
      "[Epoch 65/200] [Batch 2/44] [D loss: 0.004791] [G loss: -0.010611]\n",
      "[Epoch 65/200] [Batch 4/44] [D loss: 0.005050] [G loss: -0.010619]\n",
      "[Epoch 65/200] [Batch 6/44] [D loss: 0.006787] [G loss: -0.010616]\n",
      "[Epoch 65/200] [Batch 8/44] [D loss: 0.003849] [G loss: -0.010606]\n",
      "[Epoch 65/200] [Batch 10/44] [D loss: 0.006899] [G loss: -0.010604]\n",
      "[Epoch 65/200] [Batch 12/44] [D loss: 0.005914] [G loss: -0.010639]\n",
      "[Epoch 65/200] [Batch 14/44] [D loss: 0.004650] [G loss: -0.010612]\n",
      "[Epoch 65/200] [Batch 16/44] [D loss: 0.006966] [G loss: -0.010608]\n",
      "[Epoch 65/200] [Batch 18/44] [D loss: 0.006415] [G loss: -0.010611]\n",
      "[Epoch 65/200] [Batch 20/44] [D loss: 0.004601] [G loss: -0.010621]\n",
      "[Epoch 65/200] [Batch 22/44] [D loss: 0.003968] [G loss: -0.010626]\n",
      "[Epoch 65/200] [Batch 24/44] [D loss: 0.005900] [G loss: -0.010629]\n",
      "[Epoch 65/200] [Batch 26/44] [D loss: 0.003521] [G loss: -0.010620]\n",
      "[Epoch 65/200] [Batch 28/44] [D loss: 0.006848] [G loss: -0.010623]\n",
      "[Epoch 65/200] [Batch 30/44] [D loss: 0.006297] [G loss: -0.010628]\n",
      "[Epoch 65/200] [Batch 32/44] [D loss: 0.005102] [G loss: -0.010599]\n",
      "[Epoch 65/200] [Batch 34/44] [D loss: 0.003702] [G loss: -0.010601]\n",
      "[Epoch 65/200] [Batch 36/44] [D loss: 0.005910] [G loss: -0.010626]\n",
      "[Epoch 65/200] [Batch 38/44] [D loss: 0.005064] [G loss: -0.010635]\n",
      "[Epoch 65/200] [Batch 40/44] [D loss: 0.005864] [G loss: -0.010616]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 65/200] [Batch 42/44] [D loss: 0.004897] [G loss: -0.010622]\n",
      "[Epoch 66/200] [Batch 0/44] [D loss: 0.005653] [G loss: -0.010598]\n",
      "[Epoch 66/200] [Batch 2/44] [D loss: 0.006825] [G loss: -0.010633]\n",
      "[Epoch 66/200] [Batch 4/44] [D loss: 0.004680] [G loss: -0.010618]\n",
      "[Epoch 66/200] [Batch 6/44] [D loss: 0.005578] [G loss: -0.010604]\n",
      "[Epoch 66/200] [Batch 8/44] [D loss: 0.006839] [G loss: -0.010631]\n",
      "[Epoch 66/200] [Batch 10/44] [D loss: 0.003908] [G loss: -0.010622]\n",
      "[Epoch 66/200] [Batch 12/44] [D loss: 0.006220] [G loss: -0.010620]\n",
      "[Epoch 66/200] [Batch 14/44] [D loss: 0.006086] [G loss: -0.010609]\n",
      "[Epoch 66/200] [Batch 16/44] [D loss: 0.004493] [G loss: -0.010617]\n",
      "[Epoch 66/200] [Batch 18/44] [D loss: 0.005355] [G loss: -0.010618]\n",
      "[Epoch 66/200] [Batch 20/44] [D loss: 0.006479] [G loss: -0.010633]\n",
      "[Epoch 66/200] [Batch 22/44] [D loss: 0.004491] [G loss: -0.010631]\n",
      "[Epoch 66/200] [Batch 24/44] [D loss: 0.004656] [G loss: -0.010612]\n",
      "[Epoch 66/200] [Batch 26/44] [D loss: 0.005180] [G loss: -0.010634]\n",
      "[Epoch 66/200] [Batch 28/44] [D loss: 0.004804] [G loss: -0.010618]\n",
      "[Epoch 66/200] [Batch 30/44] [D loss: 0.007204] [G loss: -0.010612]\n",
      "[Epoch 66/200] [Batch 32/44] [D loss: 0.006352] [G loss: -0.010618]\n",
      "[Epoch 66/200] [Batch 34/44] [D loss: 0.004312] [G loss: -0.010607]\n",
      "[Epoch 66/200] [Batch 36/44] [D loss: 0.006434] [G loss: -0.010618]\n",
      "[Epoch 66/200] [Batch 38/44] [D loss: 0.006870] [G loss: -0.010612]\n",
      "[Epoch 66/200] [Batch 40/44] [D loss: 0.003993] [G loss: -0.010619]\n",
      "[Epoch 66/200] [Batch 42/44] [D loss: 0.004372] [G loss: -0.010635]\n",
      "[Epoch 67/200] [Batch 0/44] [D loss: 0.005750] [G loss: -0.010626]\n",
      "[Epoch 67/200] [Batch 2/44] [D loss: 0.004860] [G loss: -0.010616]\n",
      "[Epoch 67/200] [Batch 4/44] [D loss: 0.003578] [G loss: -0.010621]\n",
      "[Epoch 67/200] [Batch 6/44] [D loss: 0.005638] [G loss: -0.010603]\n",
      "[Epoch 67/200] [Batch 8/44] [D loss: 0.007853] [G loss: -0.010610]\n",
      "[Epoch 67/200] [Batch 10/44] [D loss: 0.006165] [G loss: -0.010622]\n",
      "[Epoch 67/200] [Batch 12/44] [D loss: 0.004656] [G loss: -0.010616]\n",
      "[Epoch 67/200] [Batch 14/44] [D loss: 0.005626] [G loss: -0.010614]\n",
      "[Epoch 67/200] [Batch 16/44] [D loss: 0.008439] [G loss: -0.010606]\n",
      "[Epoch 67/200] [Batch 18/44] [D loss: 0.005603] [G loss: -0.010598]\n",
      "[Epoch 67/200] [Batch 20/44] [D loss: 0.005264] [G loss: -0.010649]\n",
      "[Epoch 67/200] [Batch 22/44] [D loss: 0.007369] [G loss: -0.010644]\n",
      "[Epoch 67/200] [Batch 24/44] [D loss: 0.002567] [G loss: -0.010634]\n",
      "[Epoch 67/200] [Batch 26/44] [D loss: 0.005017] [G loss: -0.010635]\n",
      "[Epoch 67/200] [Batch 28/44] [D loss: 0.005264] [G loss: -0.010628]\n",
      "[Epoch 67/200] [Batch 30/44] [D loss: 0.006850] [G loss: -0.010616]\n",
      "[Epoch 67/200] [Batch 32/44] [D loss: 0.004889] [G loss: -0.010610]\n",
      "[Epoch 67/200] [Batch 34/44] [D loss: 0.005503] [G loss: -0.010608]\n",
      "[Epoch 67/200] [Batch 36/44] [D loss: 0.007082] [G loss: -0.010627]\n",
      "[Epoch 67/200] [Batch 38/44] [D loss: 0.005261] [G loss: -0.010602]\n",
      "[Epoch 67/200] [Batch 40/44] [D loss: 0.008564] [G loss: -0.010610]\n",
      "[Epoch 67/200] [Batch 42/44] [D loss: 0.005548] [G loss: -0.010627]\n",
      "[Epoch 68/200] [Batch 0/44] [D loss: 0.006237] [G loss: -0.010604]\n",
      "[Epoch 68/200] [Batch 2/44] [D loss: 0.008079] [G loss: -0.010609]\n",
      "[Epoch 68/200] [Batch 4/44] [D loss: 0.006071] [G loss: -0.010622]\n",
      "[Epoch 68/200] [Batch 6/44] [D loss: 0.005871] [G loss: -0.010622]\n",
      "[Epoch 68/200] [Batch 8/44] [D loss: 0.006100] [G loss: -0.010612]\n",
      "[Epoch 68/200] [Batch 10/44] [D loss: 0.006485] [G loss: -0.010645]\n",
      "[Epoch 68/200] [Batch 12/44] [D loss: 0.004235] [G loss: -0.010621]\n",
      "[Epoch 68/200] [Batch 14/44] [D loss: 0.005238] [G loss: -0.010608]\n",
      "[Epoch 68/200] [Batch 16/44] [D loss: 0.003464] [G loss: -0.010620]\n",
      "[Epoch 68/200] [Batch 18/44] [D loss: 0.002906] [G loss: -0.010622]\n",
      "[Epoch 68/200] [Batch 20/44] [D loss: 0.005021] [G loss: -0.010624]\n",
      "[Epoch 68/200] [Batch 22/44] [D loss: 0.004751] [G loss: -0.010614]\n",
      "[Epoch 68/200] [Batch 24/44] [D loss: 0.004573] [G loss: -0.010608]\n",
      "[Epoch 68/200] [Batch 26/44] [D loss: 0.006527] [G loss: -0.010604]\n",
      "[Epoch 68/200] [Batch 28/44] [D loss: 0.003872] [G loss: -0.010616]\n",
      "[Epoch 68/200] [Batch 30/44] [D loss: 0.005705] [G loss: -0.010601]\n",
      "[Epoch 68/200] [Batch 32/44] [D loss: 0.005513] [G loss: -0.010596]\n",
      "[Epoch 68/200] [Batch 34/44] [D loss: 0.006104] [G loss: -0.010617]\n",
      "[Epoch 68/200] [Batch 36/44] [D loss: 0.005695] [G loss: -0.010606]\n",
      "[Epoch 68/200] [Batch 38/44] [D loss: 0.004928] [G loss: -0.010601]\n",
      "[Epoch 68/200] [Batch 40/44] [D loss: 0.002083] [G loss: -0.010613]\n",
      "[Epoch 68/200] [Batch 42/44] [D loss: 0.005254] [G loss: -0.010625]\n",
      "[Epoch 69/200] [Batch 0/44] [D loss: 0.003669] [G loss: -0.010596]\n",
      "[Epoch 69/200] [Batch 2/44] [D loss: 0.005303] [G loss: -0.010613]\n",
      "[Epoch 69/200] [Batch 4/44] [D loss: 0.006678] [G loss: -0.010638]\n",
      "[Epoch 69/200] [Batch 6/44] [D loss: 0.006746] [G loss: -0.010610]\n",
      "[Epoch 69/200] [Batch 8/44] [D loss: 0.005479] [G loss: -0.010612]\n",
      "[Epoch 69/200] [Batch 10/44] [D loss: 0.005051] [G loss: -0.010618]\n",
      "[Epoch 69/200] [Batch 12/44] [D loss: 0.005564] [G loss: -0.010621]\n",
      "[Epoch 69/200] [Batch 14/44] [D loss: 0.006236] [G loss: -0.010623]\n",
      "[Epoch 69/200] [Batch 16/44] [D loss: 0.005838] [G loss: -0.010609]\n",
      "[Epoch 69/200] [Batch 18/44] [D loss: 0.005626] [G loss: -0.010620]\n",
      "[Epoch 69/200] [Batch 20/44] [D loss: 0.004353] [G loss: -0.010608]\n",
      "[Epoch 69/200] [Batch 22/44] [D loss: 0.004805] [G loss: -0.010637]\n",
      "[Epoch 69/200] [Batch 24/44] [D loss: 0.005900] [G loss: -0.010623]\n",
      "[Epoch 69/200] [Batch 26/44] [D loss: 0.003945] [G loss: -0.010627]\n",
      "[Epoch 69/200] [Batch 28/44] [D loss: 0.005346] [G loss: -0.010597]\n",
      "[Epoch 69/200] [Batch 30/44] [D loss: 0.004494] [G loss: -0.010609]\n",
      "[Epoch 69/200] [Batch 32/44] [D loss: 0.005854] [G loss: -0.010594]\n",
      "[Epoch 69/200] [Batch 34/44] [D loss: 0.004839] [G loss: -0.010594]\n",
      "[Epoch 69/200] [Batch 36/44] [D loss: 0.003967] [G loss: -0.010606]\n",
      "[Epoch 69/200] [Batch 38/44] [D loss: 0.005132] [G loss: -0.010616]\n",
      "[Epoch 69/200] [Batch 40/44] [D loss: 0.004478] [G loss: -0.010644]\n",
      "[Epoch 69/200] [Batch 42/44] [D loss: 0.007380] [G loss: -0.010623]\n",
      "[Epoch 70/200] [Batch 0/44] [D loss: 0.004191] [G loss: -0.010632]\n",
      "[Epoch 70/200] [Batch 2/44] [D loss: 0.005430] [G loss: -0.010610]\n",
      "[Epoch 70/200] [Batch 4/44] [D loss: 0.002995] [G loss: -0.010620]\n",
      "[Epoch 70/200] [Batch 6/44] [D loss: 0.003048] [G loss: -0.010625]\n",
      "[Epoch 70/200] [Batch 8/44] [D loss: 0.007454] [G loss: -0.010617]\n",
      "[Epoch 70/200] [Batch 10/44] [D loss: 0.004684] [G loss: -0.010619]\n",
      "[Epoch 70/200] [Batch 12/44] [D loss: 0.004170] [G loss: -0.010592]\n",
      "[Epoch 70/200] [Batch 14/44] [D loss: 0.006569] [G loss: -0.010632]\n",
      "[Epoch 70/200] [Batch 16/44] [D loss: 0.003156] [G loss: -0.010609]\n",
      "[Epoch 70/200] [Batch 18/44] [D loss: 0.005784] [G loss: -0.010615]\n",
      "[Epoch 70/200] [Batch 20/44] [D loss: 0.007549] [G loss: -0.010624]\n",
      "[Epoch 70/200] [Batch 22/44] [D loss: 0.006441] [G loss: -0.010619]\n",
      "[Epoch 70/200] [Batch 24/44] [D loss: 0.004037] [G loss: -0.010619]\n",
      "[Epoch 70/200] [Batch 26/44] [D loss: 0.007650] [G loss: -0.010609]\n",
      "[Epoch 70/200] [Batch 28/44] [D loss: 0.005864] [G loss: -0.010612]\n",
      "[Epoch 70/200] [Batch 30/44] [D loss: 0.004494] [G loss: -0.010618]\n",
      "[Epoch 70/200] [Batch 32/44] [D loss: 0.006156] [G loss: -0.010648]\n",
      "[Epoch 70/200] [Batch 34/44] [D loss: 0.006964] [G loss: -0.010626]\n",
      "[Epoch 70/200] [Batch 36/44] [D loss: 0.005556] [G loss: -0.010615]\n",
      "[Epoch 70/200] [Batch 38/44] [D loss: 0.004819] [G loss: -0.010619]\n",
      "[Epoch 70/200] [Batch 40/44] [D loss: 0.004060] [G loss: -0.010619]\n",
      "[Epoch 70/200] [Batch 42/44] [D loss: 0.005096] [G loss: -0.010624]\n",
      "[Epoch 71/200] [Batch 0/44] [D loss: 0.004914] [G loss: -0.010605]\n",
      "[Epoch 71/200] [Batch 2/44] [D loss: 0.007849] [G loss: -0.010619]\n",
      "[Epoch 71/200] [Batch 4/44] [D loss: 0.006312] [G loss: -0.010637]\n",
      "[Epoch 71/200] [Batch 6/44] [D loss: 0.005098] [G loss: -0.010625]\n",
      "[Epoch 71/200] [Batch 8/44] [D loss: 0.006046] [G loss: -0.010648]\n",
      "[Epoch 71/200] [Batch 10/44] [D loss: 0.004919] [G loss: -0.010607]\n",
      "[Epoch 71/200] [Batch 12/44] [D loss: 0.006590] [G loss: -0.010625]\n",
      "[Epoch 71/200] [Batch 14/44] [D loss: 0.006020] [G loss: -0.010624]\n",
      "[Epoch 71/200] [Batch 16/44] [D loss: 0.004434] [G loss: -0.010608]\n",
      "[Epoch 71/200] [Batch 18/44] [D loss: 0.006310] [G loss: -0.010606]\n",
      "[Epoch 71/200] [Batch 20/44] [D loss: 0.004884] [G loss: -0.010592]\n",
      "[Epoch 71/200] [Batch 22/44] [D loss: 0.006016] [G loss: -0.010618]\n",
      "[Epoch 71/200] [Batch 24/44] [D loss: 0.005207] [G loss: -0.010627]\n",
      "[Epoch 71/200] [Batch 26/44] [D loss: 0.005098] [G loss: -0.010604]\n",
      "[Epoch 71/200] [Batch 28/44] [D loss: 0.004396] [G loss: -0.010649]\n",
      "[Epoch 71/200] [Batch 30/44] [D loss: 0.006252] [G loss: -0.010613]\n",
      "[Epoch 71/200] [Batch 32/44] [D loss: 0.005877] [G loss: -0.010616]\n",
      "[Epoch 71/200] [Batch 34/44] [D loss: 0.003585] [G loss: -0.010622]\n",
      "[Epoch 71/200] [Batch 36/44] [D loss: 0.007057] [G loss: -0.010616]\n",
      "[Epoch 71/200] [Batch 38/44] [D loss: 0.005024] [G loss: -0.010625]\n",
      "[Epoch 71/200] [Batch 40/44] [D loss: 0.005292] [G loss: -0.010600]\n",
      "[Epoch 71/200] [Batch 42/44] [D loss: 0.008164] [G loss: -0.010602]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 72/200] [Batch 0/44] [D loss: 0.005040] [G loss: -0.010601]\n",
      "[Epoch 72/200] [Batch 2/44] [D loss: 0.006372] [G loss: -0.010620]\n",
      "[Epoch 72/200] [Batch 4/44] [D loss: 0.006620] [G loss: -0.010607]\n",
      "[Epoch 72/200] [Batch 6/44] [D loss: 0.006155] [G loss: -0.010612]\n",
      "[Epoch 72/200] [Batch 8/44] [D loss: 0.005437] [G loss: -0.010619]\n",
      "[Epoch 72/200] [Batch 10/44] [D loss: 0.007374] [G loss: -0.010609]\n",
      "[Epoch 72/200] [Batch 12/44] [D loss: 0.004894] [G loss: -0.010626]\n",
      "[Epoch 72/200] [Batch 14/44] [D loss: 0.004632] [G loss: -0.010598]\n",
      "[Epoch 72/200] [Batch 16/44] [D loss: 0.006126] [G loss: -0.010611]\n",
      "[Epoch 72/200] [Batch 18/44] [D loss: 0.007439] [G loss: -0.010633]\n",
      "[Epoch 72/200] [Batch 20/44] [D loss: 0.006429] [G loss: -0.010617]\n",
      "[Epoch 72/200] [Batch 22/44] [D loss: 0.006649] [G loss: -0.010615]\n",
      "[Epoch 72/200] [Batch 24/44] [D loss: 0.006965] [G loss: -0.010622]\n",
      "[Epoch 72/200] [Batch 26/44] [D loss: 0.006271] [G loss: -0.010620]\n",
      "[Epoch 72/200] [Batch 28/44] [D loss: 0.006158] [G loss: -0.010609]\n",
      "[Epoch 72/200] [Batch 30/44] [D loss: 0.006443] [G loss: -0.010649]\n",
      "[Epoch 72/200] [Batch 32/44] [D loss: 0.005654] [G loss: -0.010608]\n",
      "[Epoch 72/200] [Batch 34/44] [D loss: 0.004232] [G loss: -0.010610]\n",
      "[Epoch 72/200] [Batch 36/44] [D loss: 0.004492] [G loss: -0.010621]\n",
      "[Epoch 72/200] [Batch 38/44] [D loss: 0.004845] [G loss: -0.010636]\n",
      "[Epoch 72/200] [Batch 40/44] [D loss: 0.003730] [G loss: -0.010638]\n",
      "[Epoch 72/200] [Batch 42/44] [D loss: 0.005718] [G loss: -0.010629]\n",
      "[Epoch 73/200] [Batch 0/44] [D loss: 0.006235] [G loss: -0.010602]\n",
      "[Epoch 73/200] [Batch 2/44] [D loss: 0.005636] [G loss: -0.010625]\n",
      "[Epoch 73/200] [Batch 4/44] [D loss: 0.006658] [G loss: -0.010625]\n",
      "[Epoch 73/200] [Batch 6/44] [D loss: 0.004414] [G loss: -0.010620]\n",
      "[Epoch 73/200] [Batch 8/44] [D loss: 0.006946] [G loss: -0.010643]\n",
      "[Epoch 73/200] [Batch 10/44] [D loss: 0.006026] [G loss: -0.010625]\n",
      "[Epoch 73/200] [Batch 12/44] [D loss: 0.006629] [G loss: -0.010626]\n",
      "[Epoch 73/200] [Batch 14/44] [D loss: 0.004491] [G loss: -0.010605]\n",
      "[Epoch 73/200] [Batch 16/44] [D loss: 0.006226] [G loss: -0.010619]\n",
      "[Epoch 73/200] [Batch 18/44] [D loss: 0.003013] [G loss: -0.010627]\n",
      "[Epoch 73/200] [Batch 20/44] [D loss: 0.006336] [G loss: -0.010609]\n",
      "[Epoch 73/200] [Batch 22/44] [D loss: 0.002844] [G loss: -0.010606]\n",
      "[Epoch 73/200] [Batch 24/44] [D loss: 0.005284] [G loss: -0.010613]\n",
      "[Epoch 73/200] [Batch 26/44] [D loss: 0.005998] [G loss: -0.010625]\n",
      "[Epoch 73/200] [Batch 28/44] [D loss: 0.004329] [G loss: -0.010611]\n",
      "[Epoch 73/200] [Batch 30/44] [D loss: 0.006431] [G loss: -0.010608]\n",
      "[Epoch 73/200] [Batch 32/44] [D loss: 0.006010] [G loss: -0.010651]\n",
      "[Epoch 73/200] [Batch 34/44] [D loss: 0.004128] [G loss: -0.010614]\n",
      "[Epoch 73/200] [Batch 36/44] [D loss: 0.004337] [G loss: -0.010618]\n",
      "[Epoch 73/200] [Batch 38/44] [D loss: 0.006535] [G loss: -0.010635]\n",
      "[Epoch 73/200] [Batch 40/44] [D loss: 0.006274] [G loss: -0.010609]\n",
      "[Epoch 73/200] [Batch 42/44] [D loss: 0.006763] [G loss: -0.010618]\n",
      "[Epoch 74/200] [Batch 0/44] [D loss: 0.005958] [G loss: -0.010611]\n",
      "[Epoch 74/200] [Batch 2/44] [D loss: 0.004116] [G loss: -0.010620]\n",
      "[Epoch 74/200] [Batch 4/44] [D loss: 0.005323] [G loss: -0.010618]\n",
      "[Epoch 74/200] [Batch 6/44] [D loss: 0.005892] [G loss: -0.010633]\n",
      "[Epoch 74/200] [Batch 8/44] [D loss: 0.006316] [G loss: -0.010621]\n",
      "[Epoch 74/200] [Batch 10/44] [D loss: 0.004774] [G loss: -0.010605]\n",
      "[Epoch 74/200] [Batch 12/44] [D loss: 0.004199] [G loss: -0.010602]\n",
      "[Epoch 74/200] [Batch 14/44] [D loss: 0.005658] [G loss: -0.010626]\n",
      "[Epoch 74/200] [Batch 16/44] [D loss: 0.005197] [G loss: -0.010619]\n",
      "[Epoch 74/200] [Batch 18/44] [D loss: 0.004260] [G loss: -0.010626]\n",
      "[Epoch 74/200] [Batch 20/44] [D loss: 0.005817] [G loss: -0.010596]\n",
      "[Epoch 74/200] [Batch 22/44] [D loss: 0.006280] [G loss: -0.010631]\n",
      "[Epoch 74/200] [Batch 24/44] [D loss: 0.005187] [G loss: -0.010612]\n",
      "[Epoch 74/200] [Batch 26/44] [D loss: 0.003862] [G loss: -0.010629]\n",
      "[Epoch 74/200] [Batch 28/44] [D loss: 0.009263] [G loss: -0.010621]\n",
      "[Epoch 74/200] [Batch 30/44] [D loss: 0.005341] [G loss: -0.010628]\n",
      "[Epoch 74/200] [Batch 32/44] [D loss: 0.006352] [G loss: -0.010623]\n",
      "[Epoch 74/200] [Batch 34/44] [D loss: 0.004956] [G loss: -0.010637]\n",
      "[Epoch 74/200] [Batch 36/44] [D loss: 0.003498] [G loss: -0.010619]\n",
      "[Epoch 74/200] [Batch 38/44] [D loss: 0.007769] [G loss: -0.010621]\n",
      "[Epoch 74/200] [Batch 40/44] [D loss: 0.005149] [G loss: -0.010604]\n",
      "[Epoch 74/200] [Batch 42/44] [D loss: 0.006985] [G loss: -0.010627]\n",
      "[Epoch 75/200] [Batch 0/44] [D loss: 0.005646] [G loss: -0.010606]\n",
      "[Epoch 75/200] [Batch 2/44] [D loss: 0.005061] [G loss: -0.010607]\n",
      "[Epoch 75/200] [Batch 4/44] [D loss: 0.005187] [G loss: -0.010632]\n",
      "[Epoch 75/200] [Batch 6/44] [D loss: 0.005985] [G loss: -0.010632]\n",
      "[Epoch 75/200] [Batch 8/44] [D loss: 0.007432] [G loss: -0.010620]\n",
      "[Epoch 75/200] [Batch 10/44] [D loss: 0.004837] [G loss: -0.010624]\n",
      "[Epoch 75/200] [Batch 12/44] [D loss: 0.005185] [G loss: -0.010620]\n",
      "[Epoch 75/200] [Batch 14/44] [D loss: 0.006202] [G loss: -0.010606]\n",
      "[Epoch 75/200] [Batch 16/44] [D loss: 0.005382] [G loss: -0.010626]\n",
      "[Epoch 75/200] [Batch 18/44] [D loss: 0.007197] [G loss: -0.010631]\n",
      "[Epoch 75/200] [Batch 20/44] [D loss: 0.006473] [G loss: -0.010599]\n",
      "[Epoch 75/200] [Batch 22/44] [D loss: 0.004913] [G loss: -0.010624]\n",
      "[Epoch 75/200] [Batch 24/44] [D loss: 0.004126] [G loss: -0.010613]\n",
      "[Epoch 75/200] [Batch 26/44] [D loss: 0.004635] [G loss: -0.010629]\n",
      "[Epoch 75/200] [Batch 28/44] [D loss: 0.005360] [G loss: -0.010630]\n",
      "[Epoch 75/200] [Batch 30/44] [D loss: 0.004947] [G loss: -0.010629]\n",
      "[Epoch 75/200] [Batch 32/44] [D loss: 0.003303] [G loss: -0.010621]\n",
      "[Epoch 75/200] [Batch 34/44] [D loss: 0.004323] [G loss: -0.010624]\n",
      "[Epoch 75/200] [Batch 36/44] [D loss: 0.005883] [G loss: -0.010610]\n",
      "[Epoch 75/200] [Batch 38/44] [D loss: 0.006025] [G loss: -0.010601]\n",
      "[Epoch 75/200] [Batch 40/44] [D loss: 0.005405] [G loss: -0.010614]\n",
      "[Epoch 75/200] [Batch 42/44] [D loss: 0.005375] [G loss: -0.010601]\n",
      "[Epoch 76/200] [Batch 0/44] [D loss: 0.005218] [G loss: -0.010608]\n",
      "[Epoch 76/200] [Batch 2/44] [D loss: 0.004992] [G loss: -0.010639]\n",
      "[Epoch 76/200] [Batch 4/44] [D loss: 0.004563] [G loss: -0.010613]\n",
      "[Epoch 76/200] [Batch 6/44] [D loss: 0.005891] [G loss: -0.010631]\n",
      "[Epoch 76/200] [Batch 8/44] [D loss: 0.006510] [G loss: -0.010623]\n",
      "[Epoch 76/200] [Batch 10/44] [D loss: 0.004316] [G loss: -0.010603]\n",
      "[Epoch 76/200] [Batch 12/44] [D loss: 0.005393] [G loss: -0.010642]\n",
      "[Epoch 76/200] [Batch 14/44] [D loss: 0.002917] [G loss: -0.010607]\n",
      "[Epoch 76/200] [Batch 16/44] [D loss: 0.004977] [G loss: -0.010628]\n",
      "[Epoch 76/200] [Batch 18/44] [D loss: 0.005466] [G loss: -0.010603]\n",
      "[Epoch 76/200] [Batch 20/44] [D loss: 0.004493] [G loss: -0.010637]\n",
      "[Epoch 76/200] [Batch 22/44] [D loss: 0.006414] [G loss: -0.010613]\n",
      "[Epoch 76/200] [Batch 24/44] [D loss: 0.005524] [G loss: -0.010622]\n",
      "[Epoch 76/200] [Batch 26/44] [D loss: 0.006841] [G loss: -0.010625]\n",
      "[Epoch 76/200] [Batch 28/44] [D loss: 0.004448] [G loss: -0.010600]\n",
      "[Epoch 76/200] [Batch 30/44] [D loss: 0.006098] [G loss: -0.010623]\n",
      "[Epoch 76/200] [Batch 32/44] [D loss: 0.007015] [G loss: -0.010635]\n",
      "[Epoch 76/200] [Batch 34/44] [D loss: 0.005227] [G loss: -0.010626]\n",
      "[Epoch 76/200] [Batch 36/44] [D loss: 0.005100] [G loss: -0.010631]\n",
      "[Epoch 76/200] [Batch 38/44] [D loss: 0.005362] [G loss: -0.010627]\n",
      "[Epoch 76/200] [Batch 40/44] [D loss: 0.007129] [G loss: -0.010609]\n",
      "[Epoch 76/200] [Batch 42/44] [D loss: 0.006803] [G loss: -0.010601]\n",
      "[Epoch 77/200] [Batch 0/44] [D loss: 0.005346] [G loss: -0.010603]\n",
      "[Epoch 77/200] [Batch 2/44] [D loss: 0.006359] [G loss: -0.010619]\n",
      "[Epoch 77/200] [Batch 4/44] [D loss: 0.007734] [G loss: -0.010628]\n",
      "[Epoch 77/200] [Batch 6/44] [D loss: 0.006614] [G loss: -0.010635]\n",
      "[Epoch 77/200] [Batch 8/44] [D loss: 0.005608] [G loss: -0.010617]\n",
      "[Epoch 77/200] [Batch 10/44] [D loss: 0.006121] [G loss: -0.010626]\n",
      "[Epoch 77/200] [Batch 12/44] [D loss: 0.005420] [G loss: -0.010618]\n",
      "[Epoch 77/200] [Batch 14/44] [D loss: 0.006545] [G loss: -0.010613]\n",
      "[Epoch 77/200] [Batch 16/44] [D loss: 0.006850] [G loss: -0.010616]\n",
      "[Epoch 77/200] [Batch 18/44] [D loss: 0.004680] [G loss: -0.010628]\n",
      "[Epoch 77/200] [Batch 20/44] [D loss: 0.005444] [G loss: -0.010629]\n",
      "[Epoch 77/200] [Batch 22/44] [D loss: 0.006154] [G loss: -0.010639]\n",
      "[Epoch 77/200] [Batch 24/44] [D loss: 0.007114] [G loss: -0.010638]\n",
      "[Epoch 77/200] [Batch 26/44] [D loss: 0.006759] [G loss: -0.010601]\n",
      "[Epoch 77/200] [Batch 28/44] [D loss: 0.006739] [G loss: -0.010621]\n",
      "[Epoch 77/200] [Batch 30/44] [D loss: 0.006079] [G loss: -0.010625]\n",
      "[Epoch 77/200] [Batch 32/44] [D loss: 0.005421] [G loss: -0.010616]\n",
      "[Epoch 77/200] [Batch 34/44] [D loss: 0.003749] [G loss: -0.010623]\n",
      "[Epoch 77/200] [Batch 36/44] [D loss: 0.006245] [G loss: -0.010629]\n",
      "[Epoch 77/200] [Batch 38/44] [D loss: 0.004829] [G loss: -0.010626]\n",
      "[Epoch 77/200] [Batch 40/44] [D loss: 0.005587] [G loss: -0.010610]\n",
      "[Epoch 77/200] [Batch 42/44] [D loss: 0.004523] [G loss: -0.010602]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 78/200] [Batch 0/44] [D loss: 0.006018] [G loss: -0.010617]\n",
      "[Epoch 78/200] [Batch 2/44] [D loss: 0.003501] [G loss: -0.010623]\n",
      "[Epoch 78/200] [Batch 4/44] [D loss: 0.006218] [G loss: -0.010625]\n",
      "[Epoch 78/200] [Batch 6/44] [D loss: 0.007546] [G loss: -0.010638]\n",
      "[Epoch 78/200] [Batch 8/44] [D loss: 0.004918] [G loss: -0.010633]\n",
      "[Epoch 78/200] [Batch 10/44] [D loss: 0.006078] [G loss: -0.010629]\n",
      "[Epoch 78/200] [Batch 12/44] [D loss: 0.005625] [G loss: -0.010624]\n",
      "[Epoch 78/200] [Batch 14/44] [D loss: 0.004908] [G loss: -0.010623]\n",
      "[Epoch 78/200] [Batch 16/44] [D loss: 0.006574] [G loss: -0.010623]\n",
      "[Epoch 78/200] [Batch 18/44] [D loss: 0.005186] [G loss: -0.010620]\n",
      "[Epoch 78/200] [Batch 20/44] [D loss: 0.007023] [G loss: -0.010620]\n",
      "[Epoch 78/200] [Batch 22/44] [D loss: 0.006677] [G loss: -0.010642]\n",
      "[Epoch 78/200] [Batch 24/44] [D loss: 0.005488] [G loss: -0.010639]\n",
      "[Epoch 78/200] [Batch 26/44] [D loss: 0.005193] [G loss: -0.010621]\n",
      "[Epoch 78/200] [Batch 28/44] [D loss: 0.007099] [G loss: -0.010611]\n",
      "[Epoch 78/200] [Batch 30/44] [D loss: 0.006647] [G loss: -0.010620]\n",
      "[Epoch 78/200] [Batch 32/44] [D loss: 0.004807] [G loss: -0.010607]\n",
      "[Epoch 78/200] [Batch 34/44] [D loss: 0.004282] [G loss: -0.010611]\n",
      "[Epoch 78/200] [Batch 36/44] [D loss: 0.006994] [G loss: -0.010618]\n",
      "[Epoch 78/200] [Batch 38/44] [D loss: 0.004898] [G loss: -0.010617]\n",
      "[Epoch 78/200] [Batch 40/44] [D loss: 0.004920] [G loss: -0.010607]\n",
      "[Epoch 78/200] [Batch 42/44] [D loss: 0.004393] [G loss: -0.010627]\n",
      "[Epoch 79/200] [Batch 0/44] [D loss: 0.006288] [G loss: -0.010622]\n",
      "[Epoch 79/200] [Batch 2/44] [D loss: 0.006608] [G loss: -0.010615]\n",
      "[Epoch 79/200] [Batch 4/44] [D loss: 0.005745] [G loss: -0.010615]\n",
      "[Epoch 79/200] [Batch 6/44] [D loss: 0.004157] [G loss: -0.010624]\n",
      "[Epoch 79/200] [Batch 8/44] [D loss: 0.006141] [G loss: -0.010619]\n",
      "[Epoch 79/200] [Batch 10/44] [D loss: 0.004582] [G loss: -0.010616]\n",
      "[Epoch 79/200] [Batch 12/44] [D loss: 0.006774] [G loss: -0.010612]\n",
      "[Epoch 79/200] [Batch 14/44] [D loss: 0.007409] [G loss: -0.010617]\n",
      "[Epoch 79/200] [Batch 16/44] [D loss: 0.005925] [G loss: -0.010625]\n",
      "[Epoch 79/200] [Batch 18/44] [D loss: 0.005538] [G loss: -0.010615]\n",
      "[Epoch 79/200] [Batch 20/44] [D loss: 0.006174] [G loss: -0.010640]\n",
      "[Epoch 79/200] [Batch 22/44] [D loss: 0.006033] [G loss: -0.010624]\n",
      "[Epoch 79/200] [Batch 24/44] [D loss: 0.006064] [G loss: -0.010635]\n",
      "[Epoch 79/200] [Batch 26/44] [D loss: 0.006871] [G loss: -0.010635]\n",
      "[Epoch 79/200] [Batch 28/44] [D loss: 0.005924] [G loss: -0.010616]\n",
      "[Epoch 79/200] [Batch 30/44] [D loss: 0.005071] [G loss: -0.010636]\n",
      "[Epoch 79/200] [Batch 32/44] [D loss: 0.003681] [G loss: -0.010602]\n",
      "[Epoch 79/200] [Batch 34/44] [D loss: 0.002980] [G loss: -0.010618]\n",
      "[Epoch 79/200] [Batch 36/44] [D loss: 0.006242] [G loss: -0.010615]\n",
      "[Epoch 79/200] [Batch 38/44] [D loss: 0.005216] [G loss: -0.010626]\n",
      "[Epoch 79/200] [Batch 40/44] [D loss: 0.005912] [G loss: -0.010609]\n",
      "[Epoch 79/200] [Batch 42/44] [D loss: 0.005004] [G loss: -0.010607]\n",
      "[Epoch 80/200] [Batch 0/44] [D loss: 0.004519] [G loss: -0.010630]\n",
      "[Epoch 80/200] [Batch 2/44] [D loss: 0.006076] [G loss: -0.010590]\n",
      "[Epoch 80/200] [Batch 4/44] [D loss: 0.003891] [G loss: -0.010628]\n",
      "[Epoch 80/200] [Batch 6/44] [D loss: 0.004531] [G loss: -0.010601]\n",
      "[Epoch 80/200] [Batch 8/44] [D loss: 0.006530] [G loss: -0.010619]\n",
      "[Epoch 80/200] [Batch 10/44] [D loss: 0.003788] [G loss: -0.010609]\n",
      "[Epoch 80/200] [Batch 12/44] [D loss: 0.006085] [G loss: -0.010605]\n",
      "[Epoch 80/200] [Batch 14/44] [D loss: 0.004767] [G loss: -0.010628]\n",
      "[Epoch 80/200] [Batch 16/44] [D loss: 0.004813] [G loss: -0.010616]\n",
      "[Epoch 80/200] [Batch 18/44] [D loss: 0.005153] [G loss: -0.010600]\n",
      "[Epoch 80/200] [Batch 20/44] [D loss: 0.006553] [G loss: -0.010628]\n",
      "[Epoch 80/200] [Batch 22/44] [D loss: 0.004915] [G loss: -0.010613]\n",
      "[Epoch 80/200] [Batch 24/44] [D loss: 0.004902] [G loss: -0.010618]\n",
      "[Epoch 80/200] [Batch 26/44] [D loss: 0.005787] [G loss: -0.010631]\n",
      "[Epoch 80/200] [Batch 28/44] [D loss: 0.006715] [G loss: -0.010624]\n",
      "[Epoch 80/200] [Batch 30/44] [D loss: 0.007489] [G loss: -0.010611]\n",
      "[Epoch 80/200] [Batch 32/44] [D loss: 0.003881] [G loss: -0.010587]\n",
      "[Epoch 80/200] [Batch 34/44] [D loss: 0.005251] [G loss: -0.010613]\n",
      "[Epoch 80/200] [Batch 36/44] [D loss: 0.006269] [G loss: -0.010613]\n",
      "[Epoch 80/200] [Batch 38/44] [D loss: 0.006758] [G loss: -0.010614]\n",
      "[Epoch 80/200] [Batch 40/44] [D loss: 0.008072] [G loss: -0.010613]\n",
      "[Epoch 80/200] [Batch 42/44] [D loss: 0.007038] [G loss: -0.010612]\n",
      "[Epoch 81/200] [Batch 0/44] [D loss: 0.005065] [G loss: -0.010616]\n",
      "[Epoch 81/200] [Batch 2/44] [D loss: 0.005536] [G loss: -0.010621]\n",
      "[Epoch 81/200] [Batch 4/44] [D loss: 0.004565] [G loss: -0.010607]\n",
      "[Epoch 81/200] [Batch 6/44] [D loss: 0.006153] [G loss: -0.010617]\n",
      "[Epoch 81/200] [Batch 8/44] [D loss: 0.005925] [G loss: -0.010631]\n",
      "[Epoch 81/200] [Batch 10/44] [D loss: 0.004553] [G loss: -0.010631]\n",
      "[Epoch 81/200] [Batch 12/44] [D loss: 0.004177] [G loss: -0.010610]\n",
      "[Epoch 81/200] [Batch 14/44] [D loss: 0.006843] [G loss: -0.010614]\n",
      "[Epoch 81/200] [Batch 16/44] [D loss: 0.004177] [G loss: -0.010623]\n",
      "[Epoch 81/200] [Batch 18/44] [D loss: 0.005668] [G loss: -0.010632]\n",
      "[Epoch 81/200] [Batch 20/44] [D loss: 0.004797] [G loss: -0.010613]\n",
      "[Epoch 81/200] [Batch 22/44] [D loss: 0.005903] [G loss: -0.010627]\n",
      "[Epoch 81/200] [Batch 24/44] [D loss: 0.005275] [G loss: -0.010612]\n",
      "[Epoch 81/200] [Batch 26/44] [D loss: 0.006860] [G loss: -0.010600]\n",
      "[Epoch 81/200] [Batch 28/44] [D loss: 0.004830] [G loss: -0.010638]\n",
      "[Epoch 81/200] [Batch 30/44] [D loss: 0.004641] [G loss: -0.010624]\n",
      "[Epoch 81/200] [Batch 32/44] [D loss: 0.009005] [G loss: -0.010615]\n",
      "[Epoch 81/200] [Batch 34/44] [D loss: 0.003425] [G loss: -0.010650]\n",
      "[Epoch 81/200] [Batch 36/44] [D loss: 0.007406] [G loss: -0.010609]\n",
      "[Epoch 81/200] [Batch 38/44] [D loss: 0.006622] [G loss: -0.010620]\n",
      "[Epoch 81/200] [Batch 40/44] [D loss: 0.005612] [G loss: -0.010609]\n",
      "[Epoch 81/200] [Batch 42/44] [D loss: 0.006736] [G loss: -0.010621]\n",
      "[Epoch 82/200] [Batch 0/44] [D loss: 0.006000] [G loss: -0.010595]\n",
      "[Epoch 82/200] [Batch 2/44] [D loss: 0.005843] [G loss: -0.010653]\n",
      "[Epoch 82/200] [Batch 4/44] [D loss: 0.005213] [G loss: -0.010608]\n",
      "[Epoch 82/200] [Batch 6/44] [D loss: 0.004891] [G loss: -0.010625]\n",
      "[Epoch 82/200] [Batch 8/44] [D loss: 0.008643] [G loss: -0.010608]\n",
      "[Epoch 82/200] [Batch 10/44] [D loss: 0.004501] [G loss: -0.010623]\n",
      "[Epoch 82/200] [Batch 12/44] [D loss: 0.005278] [G loss: -0.010622]\n",
      "[Epoch 82/200] [Batch 14/44] [D loss: 0.005408] [G loss: -0.010638]\n",
      "[Epoch 82/200] [Batch 16/44] [D loss: 0.005408] [G loss: -0.010619]\n",
      "[Epoch 82/200] [Batch 18/44] [D loss: 0.006284] [G loss: -0.010640]\n",
      "[Epoch 82/200] [Batch 20/44] [D loss: 0.005905] [G loss: -0.010628]\n",
      "[Epoch 82/200] [Batch 22/44] [D loss: 0.006371] [G loss: -0.010620]\n",
      "[Epoch 82/200] [Batch 24/44] [D loss: 0.006439] [G loss: -0.010628]\n",
      "[Epoch 82/200] [Batch 26/44] [D loss: 0.005217] [G loss: -0.010605]\n",
      "[Epoch 82/200] [Batch 28/44] [D loss: 0.005388] [G loss: -0.010610]\n",
      "[Epoch 82/200] [Batch 30/44] [D loss: 0.006528] [G loss: -0.010614]\n",
      "[Epoch 82/200] [Batch 32/44] [D loss: 0.005436] [G loss: -0.010631]\n",
      "[Epoch 82/200] [Batch 34/44] [D loss: 0.003886] [G loss: -0.010616]\n",
      "[Epoch 82/200] [Batch 36/44] [D loss: 0.006236] [G loss: -0.010623]\n",
      "[Epoch 82/200] [Batch 38/44] [D loss: 0.005745] [G loss: -0.010633]\n",
      "[Epoch 82/200] [Batch 40/44] [D loss: 0.006822] [G loss: -0.010608]\n",
      "[Epoch 82/200] [Batch 42/44] [D loss: 0.006051] [G loss: -0.010616]\n",
      "[Epoch 83/200] [Batch 0/44] [D loss: 0.004524] [G loss: -0.010605]\n",
      "[Epoch 83/200] [Batch 2/44] [D loss: 0.005648] [G loss: -0.010627]\n",
      "[Epoch 83/200] [Batch 4/44] [D loss: 0.004934] [G loss: -0.010615]\n",
      "[Epoch 83/200] [Batch 6/44] [D loss: 0.003683] [G loss: -0.010603]\n",
      "[Epoch 83/200] [Batch 8/44] [D loss: 0.007732] [G loss: -0.010623]\n",
      "[Epoch 83/200] [Batch 10/44] [D loss: 0.005981] [G loss: -0.010604]\n",
      "[Epoch 83/200] [Batch 12/44] [D loss: 0.006560] [G loss: -0.010619]\n",
      "[Epoch 83/200] [Batch 14/44] [D loss: 0.004820] [G loss: -0.010621]\n",
      "[Epoch 83/200] [Batch 16/44] [D loss: 0.005831] [G loss: -0.010593]\n",
      "[Epoch 83/200] [Batch 18/44] [D loss: 0.005159] [G loss: -0.010605]\n",
      "[Epoch 83/200] [Batch 20/44] [D loss: 0.006341] [G loss: -0.010625]\n",
      "[Epoch 83/200] [Batch 22/44] [D loss: 0.002345] [G loss: -0.010634]\n",
      "[Epoch 83/200] [Batch 24/44] [D loss: 0.004784] [G loss: -0.010600]\n",
      "[Epoch 83/200] [Batch 26/44] [D loss: 0.006600] [G loss: -0.010633]\n",
      "[Epoch 83/200] [Batch 28/44] [D loss: 0.006209] [G loss: -0.010612]\n",
      "[Epoch 83/200] [Batch 30/44] [D loss: 0.005977] [G loss: -0.010604]\n",
      "[Epoch 83/200] [Batch 32/44] [D loss: 0.004789] [G loss: -0.010621]\n",
      "[Epoch 83/200] [Batch 34/44] [D loss: 0.006682] [G loss: -0.010624]\n",
      "[Epoch 83/200] [Batch 36/44] [D loss: 0.005106] [G loss: -0.010603]\n",
      "[Epoch 83/200] [Batch 38/44] [D loss: 0.004203] [G loss: -0.010630]\n",
      "[Epoch 83/200] [Batch 40/44] [D loss: 0.006423] [G loss: -0.010601]\n",
      "[Epoch 83/200] [Batch 42/44] [D loss: 0.005194] [G loss: -0.010620]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 84/200] [Batch 0/44] [D loss: 0.006022] [G loss: -0.010610]\n",
      "[Epoch 84/200] [Batch 2/44] [D loss: 0.006408] [G loss: -0.010611]\n",
      "[Epoch 84/200] [Batch 4/44] [D loss: 0.004938] [G loss: -0.010604]\n",
      "[Epoch 84/200] [Batch 6/44] [D loss: 0.005201] [G loss: -0.010616]\n",
      "[Epoch 84/200] [Batch 8/44] [D loss: 0.004854] [G loss: -0.010629]\n",
      "[Epoch 84/200] [Batch 10/44] [D loss: 0.005436] [G loss: -0.010603]\n",
      "[Epoch 84/200] [Batch 12/44] [D loss: 0.007448] [G loss: -0.010608]\n",
      "[Epoch 84/200] [Batch 14/44] [D loss: 0.005706] [G loss: -0.010636]\n",
      "[Epoch 84/200] [Batch 16/44] [D loss: 0.006436] [G loss: -0.010598]\n",
      "[Epoch 84/200] [Batch 18/44] [D loss: 0.006722] [G loss: -0.010627]\n",
      "[Epoch 84/200] [Batch 20/44] [D loss: 0.006526] [G loss: -0.010621]\n",
      "[Epoch 84/200] [Batch 22/44] [D loss: 0.005058] [G loss: -0.010620]\n",
      "[Epoch 84/200] [Batch 24/44] [D loss: 0.007559] [G loss: -0.010638]\n",
      "[Epoch 84/200] [Batch 26/44] [D loss: 0.004746] [G loss: -0.010602]\n",
      "[Epoch 84/200] [Batch 28/44] [D loss: 0.004403] [G loss: -0.010615]\n",
      "[Epoch 84/200] [Batch 30/44] [D loss: 0.005939] [G loss: -0.010608]\n",
      "[Epoch 84/200] [Batch 32/44] [D loss: 0.005430] [G loss: -0.010634]\n",
      "[Epoch 84/200] [Batch 34/44] [D loss: 0.005693] [G loss: -0.010618]\n",
      "[Epoch 84/200] [Batch 36/44] [D loss: 0.005073] [G loss: -0.010620]\n",
      "[Epoch 84/200] [Batch 38/44] [D loss: 0.003515] [G loss: -0.010604]\n",
      "[Epoch 84/200] [Batch 40/44] [D loss: 0.005766] [G loss: -0.010612]\n",
      "[Epoch 84/200] [Batch 42/44] [D loss: 0.007016] [G loss: -0.010607]\n",
      "[Epoch 85/200] [Batch 0/44] [D loss: 0.004471] [G loss: -0.010603]\n",
      "[Epoch 85/200] [Batch 2/44] [D loss: 0.005871] [G loss: -0.010630]\n",
      "[Epoch 85/200] [Batch 4/44] [D loss: 0.005020] [G loss: -0.010627]\n",
      "[Epoch 85/200] [Batch 6/44] [D loss: 0.006369] [G loss: -0.010632]\n",
      "[Epoch 85/200] [Batch 8/44] [D loss: 0.006592] [G loss: -0.010629]\n",
      "[Epoch 85/200] [Batch 10/44] [D loss: 0.002739] [G loss: -0.010634]\n",
      "[Epoch 85/200] [Batch 12/44] [D loss: 0.003091] [G loss: -0.010609]\n",
      "[Epoch 85/200] [Batch 14/44] [D loss: 0.005424] [G loss: -0.010627]\n",
      "[Epoch 85/200] [Batch 16/44] [D loss: 0.005487] [G loss: -0.010600]\n",
      "[Epoch 85/200] [Batch 18/44] [D loss: 0.004051] [G loss: -0.010629]\n",
      "[Epoch 85/200] [Batch 20/44] [D loss: 0.006363] [G loss: -0.010620]\n",
      "[Epoch 85/200] [Batch 22/44] [D loss: 0.004216] [G loss: -0.010637]\n",
      "[Epoch 85/200] [Batch 24/44] [D loss: 0.003618] [G loss: -0.010625]\n",
      "[Epoch 85/200] [Batch 26/44] [D loss: 0.005902] [G loss: -0.010628]\n",
      "[Epoch 85/200] [Batch 28/44] [D loss: 0.003395] [G loss: -0.010634]\n",
      "[Epoch 85/200] [Batch 30/44] [D loss: 0.005234] [G loss: -0.010606]\n",
      "[Epoch 85/200] [Batch 32/44] [D loss: 0.004704] [G loss: -0.010591]\n",
      "[Epoch 85/200] [Batch 34/44] [D loss: 0.004518] [G loss: -0.010615]\n",
      "[Epoch 85/200] [Batch 36/44] [D loss: 0.006301] [G loss: -0.010606]\n",
      "[Epoch 85/200] [Batch 38/44] [D loss: 0.004895] [G loss: -0.010618]\n",
      "[Epoch 85/200] [Batch 40/44] [D loss: 0.006342] [G loss: -0.010622]\n",
      "[Epoch 85/200] [Batch 42/44] [D loss: 0.004339] [G loss: -0.010619]\n",
      "[Epoch 86/200] [Batch 0/44] [D loss: 0.004685] [G loss: -0.010626]\n",
      "[Epoch 86/200] [Batch 2/44] [D loss: 0.005719] [G loss: -0.010631]\n",
      "[Epoch 86/200] [Batch 4/44] [D loss: 0.006492] [G loss: -0.010618]\n",
      "[Epoch 86/200] [Batch 6/44] [D loss: 0.003658] [G loss: -0.010614]\n",
      "[Epoch 86/200] [Batch 8/44] [D loss: 0.007565] [G loss: -0.010644]\n",
      "[Epoch 86/200] [Batch 10/44] [D loss: 0.005102] [G loss: -0.010625]\n",
      "[Epoch 86/200] [Batch 12/44] [D loss: 0.004690] [G loss: -0.010610]\n",
      "[Epoch 86/200] [Batch 14/44] [D loss: 0.004621] [G loss: -0.010613]\n",
      "[Epoch 86/200] [Batch 16/44] [D loss: 0.005765] [G loss: -0.010612]\n",
      "[Epoch 86/200] [Batch 18/44] [D loss: 0.004785] [G loss: -0.010592]\n",
      "[Epoch 86/200] [Batch 20/44] [D loss: 0.005066] [G loss: -0.010613]\n",
      "[Epoch 86/200] [Batch 22/44] [D loss: 0.003623] [G loss: -0.010624]\n",
      "[Epoch 86/200] [Batch 24/44] [D loss: 0.006303] [G loss: -0.010645]\n",
      "[Epoch 86/200] [Batch 26/44] [D loss: 0.002736] [G loss: -0.010629]\n",
      "[Epoch 86/200] [Batch 28/44] [D loss: 0.005214] [G loss: -0.010630]\n",
      "[Epoch 86/200] [Batch 30/44] [D loss: 0.005862] [G loss: -0.010624]\n",
      "[Epoch 86/200] [Batch 32/44] [D loss: 0.006221] [G loss: -0.010614]\n",
      "[Epoch 86/200] [Batch 34/44] [D loss: 0.004323] [G loss: -0.010621]\n",
      "[Epoch 86/200] [Batch 36/44] [D loss: 0.008624] [G loss: -0.010629]\n",
      "[Epoch 86/200] [Batch 38/44] [D loss: 0.005057] [G loss: -0.010633]\n",
      "[Epoch 86/200] [Batch 40/44] [D loss: 0.003584] [G loss: -0.010614]\n",
      "[Epoch 86/200] [Batch 42/44] [D loss: 0.008292] [G loss: -0.010601]\n",
      "[Epoch 87/200] [Batch 0/44] [D loss: 0.006884] [G loss: -0.010632]\n",
      "[Epoch 87/200] [Batch 2/44] [D loss: 0.005234] [G loss: -0.010617]\n",
      "[Epoch 87/200] [Batch 4/44] [D loss: 0.006756] [G loss: -0.010600]\n",
      "[Epoch 87/200] [Batch 6/44] [D loss: 0.003835] [G loss: -0.010595]\n",
      "[Epoch 87/200] [Batch 8/44] [D loss: 0.003191] [G loss: -0.010613]\n",
      "[Epoch 87/200] [Batch 10/44] [D loss: 0.004870] [G loss: -0.010608]\n",
      "[Epoch 87/200] [Batch 12/44] [D loss: 0.004916] [G loss: -0.010636]\n",
      "[Epoch 87/200] [Batch 14/44] [D loss: 0.006846] [G loss: -0.010623]\n",
      "[Epoch 87/200] [Batch 16/44] [D loss: 0.007569] [G loss: -0.010643]\n",
      "[Epoch 87/200] [Batch 18/44] [D loss: 0.006098] [G loss: -0.010611]\n",
      "[Epoch 87/200] [Batch 20/44] [D loss: 0.007046] [G loss: -0.010599]\n",
      "[Epoch 87/200] [Batch 22/44] [D loss: 0.005037] [G loss: -0.010617]\n",
      "[Epoch 87/200] [Batch 24/44] [D loss: 0.006016] [G loss: -0.010618]\n",
      "[Epoch 87/200] [Batch 26/44] [D loss: 0.003882] [G loss: -0.010613]\n",
      "[Epoch 87/200] [Batch 28/44] [D loss: 0.006085] [G loss: -0.010609]\n",
      "[Epoch 87/200] [Batch 30/44] [D loss: 0.005244] [G loss: -0.010598]\n",
      "[Epoch 87/200] [Batch 32/44] [D loss: 0.004173] [G loss: -0.010594]\n",
      "[Epoch 87/200] [Batch 34/44] [D loss: 0.005670] [G loss: -0.010640]\n",
      "[Epoch 87/200] [Batch 36/44] [D loss: 0.005293] [G loss: -0.010603]\n",
      "[Epoch 87/200] [Batch 38/44] [D loss: 0.006893] [G loss: -0.010606]\n",
      "[Epoch 87/200] [Batch 40/44] [D loss: 0.006793] [G loss: -0.010606]\n",
      "[Epoch 87/200] [Batch 42/44] [D loss: 0.004731] [G loss: -0.010621]\n",
      "[Epoch 88/200] [Batch 0/44] [D loss: 0.004938] [G loss: -0.010627]\n",
      "[Epoch 88/200] [Batch 2/44] [D loss: 0.006095] [G loss: -0.010625]\n",
      "[Epoch 88/200] [Batch 4/44] [D loss: 0.006163] [G loss: -0.010624]\n",
      "[Epoch 88/200] [Batch 6/44] [D loss: 0.004207] [G loss: -0.010630]\n",
      "[Epoch 88/200] [Batch 8/44] [D loss: 0.004737] [G loss: -0.010607]\n",
      "[Epoch 88/200] [Batch 10/44] [D loss: 0.004622] [G loss: -0.010631]\n",
      "[Epoch 88/200] [Batch 12/44] [D loss: 0.005328] [G loss: -0.010601]\n",
      "[Epoch 88/200] [Batch 14/44] [D loss: 0.004768] [G loss: -0.010605]\n",
      "[Epoch 88/200] [Batch 16/44] [D loss: 0.003660] [G loss: -0.010619]\n",
      "[Epoch 88/200] [Batch 18/44] [D loss: 0.004615] [G loss: -0.010591]\n",
      "[Epoch 88/200] [Batch 20/44] [D loss: 0.005922] [G loss: -0.010625]\n",
      "[Epoch 88/200] [Batch 22/44] [D loss: 0.006230] [G loss: -0.010625]\n",
      "[Epoch 88/200] [Batch 24/44] [D loss: 0.006680] [G loss: -0.010627]\n",
      "[Epoch 88/200] [Batch 26/44] [D loss: 0.004977] [G loss: -0.010643]\n",
      "[Epoch 88/200] [Batch 28/44] [D loss: 0.007279] [G loss: -0.010616]\n",
      "[Epoch 88/200] [Batch 30/44] [D loss: 0.005526] [G loss: -0.010615]\n",
      "[Epoch 88/200] [Batch 32/44] [D loss: 0.004549] [G loss: -0.010604]\n",
      "[Epoch 88/200] [Batch 34/44] [D loss: 0.005735] [G loss: -0.010619]\n",
      "[Epoch 88/200] [Batch 36/44] [D loss: 0.006060] [G loss: -0.010605]\n",
      "[Epoch 88/200] [Batch 38/44] [D loss: 0.004631] [G loss: -0.010596]\n",
      "[Epoch 88/200] [Batch 40/44] [D loss: 0.006832] [G loss: -0.010611]\n",
      "[Epoch 88/200] [Batch 42/44] [D loss: 0.005573] [G loss: -0.010622]\n",
      "[Epoch 89/200] [Batch 0/44] [D loss: 0.005918] [G loss: -0.010617]\n",
      "[Epoch 89/200] [Batch 2/44] [D loss: 0.005723] [G loss: -0.010617]\n",
      "[Epoch 89/200] [Batch 4/44] [D loss: 0.006402] [G loss: -0.010626]\n",
      "[Epoch 89/200] [Batch 6/44] [D loss: 0.004577] [G loss: -0.010616]\n",
      "[Epoch 89/200] [Batch 8/44] [D loss: 0.006113] [G loss: -0.010613]\n",
      "[Epoch 89/200] [Batch 10/44] [D loss: 0.006326] [G loss: -0.010627]\n",
      "[Epoch 89/200] [Batch 12/44] [D loss: 0.007043] [G loss: -0.010621]\n",
      "[Epoch 89/200] [Batch 14/44] [D loss: 0.004890] [G loss: -0.010608]\n",
      "[Epoch 89/200] [Batch 16/44] [D loss: 0.006441] [G loss: -0.010609]\n",
      "[Epoch 89/200] [Batch 18/44] [D loss: 0.004215] [G loss: -0.010633]\n",
      "[Epoch 89/200] [Batch 20/44] [D loss: 0.006498] [G loss: -0.010626]\n",
      "[Epoch 89/200] [Batch 22/44] [D loss: 0.004545] [G loss: -0.010596]\n",
      "[Epoch 89/200] [Batch 24/44] [D loss: 0.006435] [G loss: -0.010622]\n",
      "[Epoch 89/200] [Batch 26/44] [D loss: 0.005794] [G loss: -0.010628]\n",
      "[Epoch 89/200] [Batch 28/44] [D loss: 0.005560] [G loss: -0.010612]\n",
      "[Epoch 89/200] [Batch 30/44] [D loss: 0.004292] [G loss: -0.010608]\n",
      "[Epoch 89/200] [Batch 32/44] [D loss: 0.005990] [G loss: -0.010615]\n",
      "[Epoch 89/200] [Batch 34/44] [D loss: 0.005873] [G loss: -0.010611]\n",
      "[Epoch 89/200] [Batch 36/44] [D loss: 0.004892] [G loss: -0.010616]\n",
      "[Epoch 89/200] [Batch 38/44] [D loss: 0.004603] [G loss: -0.010609]\n",
      "[Epoch 89/200] [Batch 40/44] [D loss: 0.005783] [G loss: -0.010618]\n",
      "[Epoch 89/200] [Batch 42/44] [D loss: 0.005050] [G loss: -0.010630]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 90/200] [Batch 0/44] [D loss: 0.005178] [G loss: -0.010590]\n",
      "[Epoch 90/200] [Batch 2/44] [D loss: 0.003180] [G loss: -0.010626]\n",
      "[Epoch 90/200] [Batch 4/44] [D loss: 0.005344] [G loss: -0.010624]\n",
      "[Epoch 90/200] [Batch 6/44] [D loss: 0.006694] [G loss: -0.010602]\n",
      "[Epoch 90/200] [Batch 8/44] [D loss: 0.007143] [G loss: -0.010609]\n",
      "[Epoch 90/200] [Batch 10/44] [D loss: 0.004967] [G loss: -0.010624]\n",
      "[Epoch 90/200] [Batch 12/44] [D loss: 0.005869] [G loss: -0.010621]\n",
      "[Epoch 90/200] [Batch 14/44] [D loss: 0.005359] [G loss: -0.010606]\n",
      "[Epoch 90/200] [Batch 16/44] [D loss: 0.004886] [G loss: -0.010638]\n",
      "[Epoch 90/200] [Batch 18/44] [D loss: 0.006275] [G loss: -0.010616]\n",
      "[Epoch 90/200] [Batch 20/44] [D loss: 0.004239] [G loss: -0.010633]\n",
      "[Epoch 90/200] [Batch 22/44] [D loss: 0.005516] [G loss: -0.010629]\n",
      "[Epoch 90/200] [Batch 24/44] [D loss: 0.004270] [G loss: -0.010586]\n",
      "[Epoch 90/200] [Batch 26/44] [D loss: 0.003383] [G loss: -0.010599]\n",
      "[Epoch 90/200] [Batch 28/44] [D loss: 0.005137] [G loss: -0.010605]\n",
      "[Epoch 90/200] [Batch 30/44] [D loss: 0.006751] [G loss: -0.010614]\n",
      "[Epoch 90/200] [Batch 32/44] [D loss: 0.005122] [G loss: -0.010634]\n",
      "[Epoch 90/200] [Batch 34/44] [D loss: 0.005865] [G loss: -0.010623]\n",
      "[Epoch 90/200] [Batch 36/44] [D loss: 0.006745] [G loss: -0.010627]\n",
      "[Epoch 90/200] [Batch 38/44] [D loss: 0.006327] [G loss: -0.010612]\n",
      "[Epoch 90/200] [Batch 40/44] [D loss: 0.006060] [G loss: -0.010628]\n",
      "[Epoch 90/200] [Batch 42/44] [D loss: 0.005089] [G loss: -0.010622]\n",
      "[Epoch 91/200] [Batch 0/44] [D loss: 0.005354] [G loss: -0.010603]\n",
      "[Epoch 91/200] [Batch 2/44] [D loss: 0.005193] [G loss: -0.010632]\n",
      "[Epoch 91/200] [Batch 4/44] [D loss: 0.004157] [G loss: -0.010609]\n",
      "[Epoch 91/200] [Batch 6/44] [D loss: 0.007218] [G loss: -0.010621]\n",
      "[Epoch 91/200] [Batch 8/44] [D loss: 0.004600] [G loss: -0.010635]\n",
      "[Epoch 91/200] [Batch 10/44] [D loss: 0.006278] [G loss: -0.010621]\n",
      "[Epoch 91/200] [Batch 12/44] [D loss: 0.005127] [G loss: -0.010605]\n",
      "[Epoch 91/200] [Batch 14/44] [D loss: 0.005761] [G loss: -0.010608]\n",
      "[Epoch 91/200] [Batch 16/44] [D loss: 0.005453] [G loss: -0.010603]\n",
      "[Epoch 91/200] [Batch 18/44] [D loss: 0.007027] [G loss: -0.010637]\n",
      "[Epoch 91/200] [Batch 20/44] [D loss: 0.006713] [G loss: -0.010616]\n",
      "[Epoch 91/200] [Batch 22/44] [D loss: 0.006085] [G loss: -0.010602]\n",
      "[Epoch 91/200] [Batch 24/44] [D loss: 0.003152] [G loss: -0.010650]\n",
      "[Epoch 91/200] [Batch 26/44] [D loss: 0.005056] [G loss: -0.010608]\n",
      "[Epoch 91/200] [Batch 28/44] [D loss: 0.007430] [G loss: -0.010603]\n",
      "[Epoch 91/200] [Batch 30/44] [D loss: 0.005322] [G loss: -0.010609]\n",
      "[Epoch 91/200] [Batch 32/44] [D loss: 0.006685] [G loss: -0.010614]\n",
      "[Epoch 91/200] [Batch 34/44] [D loss: 0.005486] [G loss: -0.010622]\n",
      "[Epoch 91/200] [Batch 36/44] [D loss: 0.004434] [G loss: -0.010623]\n",
      "[Epoch 91/200] [Batch 38/44] [D loss: 0.007332] [G loss: -0.010616]\n",
      "[Epoch 91/200] [Batch 40/44] [D loss: 0.003286] [G loss: -0.010626]\n",
      "[Epoch 91/200] [Batch 42/44] [D loss: 0.004597] [G loss: -0.010630]\n",
      "[Epoch 92/200] [Batch 0/44] [D loss: 0.005165] [G loss: -0.010639]\n",
      "[Epoch 92/200] [Batch 2/44] [D loss: 0.006565] [G loss: -0.010610]\n",
      "[Epoch 92/200] [Batch 4/44] [D loss: 0.006807] [G loss: -0.010625]\n",
      "[Epoch 92/200] [Batch 6/44] [D loss: 0.003372] [G loss: -0.010596]\n",
      "[Epoch 92/200] [Batch 8/44] [D loss: 0.007505] [G loss: -0.010613]\n",
      "[Epoch 92/200] [Batch 10/44] [D loss: 0.004839] [G loss: -0.010617]\n",
      "[Epoch 92/200] [Batch 12/44] [D loss: 0.004398] [G loss: -0.010620]\n",
      "[Epoch 92/200] [Batch 14/44] [D loss: 0.005811] [G loss: -0.010640]\n",
      "[Epoch 92/200] [Batch 16/44] [D loss: 0.006574] [G loss: -0.010615]\n",
      "[Epoch 92/200] [Batch 18/44] [D loss: 0.004442] [G loss: -0.010608]\n",
      "[Epoch 92/200] [Batch 20/44] [D loss: 0.005047] [G loss: -0.010622]\n",
      "[Epoch 92/200] [Batch 22/44] [D loss: 0.005439] [G loss: -0.010611]\n",
      "[Epoch 92/200] [Batch 24/44] [D loss: 0.004956] [G loss: -0.010625]\n",
      "[Epoch 92/200] [Batch 26/44] [D loss: 0.006118] [G loss: -0.010589]\n",
      "[Epoch 92/200] [Batch 28/44] [D loss: 0.005037] [G loss: -0.010616]\n",
      "[Epoch 92/200] [Batch 30/44] [D loss: 0.003358] [G loss: -0.010619]\n",
      "[Epoch 92/200] [Batch 32/44] [D loss: 0.005471] [G loss: -0.010619]\n",
      "[Epoch 92/200] [Batch 34/44] [D loss: 0.006335] [G loss: -0.010603]\n",
      "[Epoch 92/200] [Batch 36/44] [D loss: 0.006279] [G loss: -0.010647]\n",
      "[Epoch 92/200] [Batch 38/44] [D loss: 0.004448] [G loss: -0.010647]\n",
      "[Epoch 92/200] [Batch 40/44] [D loss: 0.004232] [G loss: -0.010624]\n",
      "[Epoch 92/200] [Batch 42/44] [D loss: 0.005887] [G loss: -0.010605]\n",
      "[Epoch 93/200] [Batch 0/44] [D loss: 0.003625] [G loss: -0.010617]\n",
      "[Epoch 93/200] [Batch 2/44] [D loss: 0.003734] [G loss: -0.010627]\n",
      "[Epoch 93/200] [Batch 4/44] [D loss: 0.005447] [G loss: -0.010611]\n",
      "[Epoch 93/200] [Batch 6/44] [D loss: 0.006655] [G loss: -0.010599]\n",
      "[Epoch 93/200] [Batch 8/44] [D loss: 0.006983] [G loss: -0.010625]\n",
      "[Epoch 93/200] [Batch 10/44] [D loss: 0.007128] [G loss: -0.010604]\n",
      "[Epoch 93/200] [Batch 12/44] [D loss: 0.005675] [G loss: -0.010620]\n",
      "[Epoch 93/200] [Batch 14/44] [D loss: 0.006001] [G loss: -0.010634]\n",
      "[Epoch 93/200] [Batch 16/44] [D loss: 0.005933] [G loss: -0.010630]\n",
      "[Epoch 93/200] [Batch 18/44] [D loss: 0.005055] [G loss: -0.010614]\n",
      "[Epoch 93/200] [Batch 20/44] [D loss: 0.004524] [G loss: -0.010611]\n",
      "[Epoch 93/200] [Batch 22/44] [D loss: 0.004886] [G loss: -0.010604]\n",
      "[Epoch 93/200] [Batch 24/44] [D loss: 0.004863] [G loss: -0.010615]\n",
      "[Epoch 93/200] [Batch 26/44] [D loss: 0.003427] [G loss: -0.010612]\n",
      "[Epoch 93/200] [Batch 28/44] [D loss: 0.006087] [G loss: -0.010609]\n",
      "[Epoch 93/200] [Batch 30/44] [D loss: 0.005300] [G loss: -0.010650]\n",
      "[Epoch 93/200] [Batch 32/44] [D loss: 0.006601] [G loss: -0.010626]\n",
      "[Epoch 93/200] [Batch 34/44] [D loss: 0.005885] [G loss: -0.010630]\n",
      "[Epoch 93/200] [Batch 36/44] [D loss: 0.006395] [G loss: -0.010608]\n",
      "[Epoch 93/200] [Batch 38/44] [D loss: 0.005233] [G loss: -0.010632]\n",
      "[Epoch 93/200] [Batch 40/44] [D loss: 0.004616] [G loss: -0.010607]\n",
      "[Epoch 93/200] [Batch 42/44] [D loss: 0.003709] [G loss: -0.010631]\n",
      "[Epoch 94/200] [Batch 0/44] [D loss: 0.004667] [G loss: -0.010623]\n",
      "[Epoch 94/200] [Batch 2/44] [D loss: 0.006628] [G loss: -0.010631]\n",
      "[Epoch 94/200] [Batch 4/44] [D loss: 0.005660] [G loss: -0.010599]\n",
      "[Epoch 94/200] [Batch 6/44] [D loss: 0.004010] [G loss: -0.010605]\n",
      "[Epoch 94/200] [Batch 8/44] [D loss: 0.004921] [G loss: -0.010642]\n",
      "[Epoch 94/200] [Batch 10/44] [D loss: 0.005599] [G loss: -0.010615]\n",
      "[Epoch 94/200] [Batch 12/44] [D loss: 0.003542] [G loss: -0.010615]\n",
      "[Epoch 94/200] [Batch 14/44] [D loss: 0.006991] [G loss: -0.010619]\n",
      "[Epoch 94/200] [Batch 16/44] [D loss: 0.006353] [G loss: -0.010601]\n",
      "[Epoch 94/200] [Batch 18/44] [D loss: 0.005959] [G loss: -0.010620]\n",
      "[Epoch 94/200] [Batch 20/44] [D loss: 0.007504] [G loss: -0.010644]\n",
      "[Epoch 94/200] [Batch 22/44] [D loss: 0.004645] [G loss: -0.010623]\n",
      "[Epoch 94/200] [Batch 24/44] [D loss: 0.005886] [G loss: -0.010628]\n",
      "[Epoch 94/200] [Batch 26/44] [D loss: 0.006006] [G loss: -0.010637]\n",
      "[Epoch 94/200] [Batch 28/44] [D loss: 0.005107] [G loss: -0.010625]\n",
      "[Epoch 94/200] [Batch 30/44] [D loss: 0.004782] [G loss: -0.010618]\n",
      "[Epoch 94/200] [Batch 32/44] [D loss: 0.005196] [G loss: -0.010613]\n",
      "[Epoch 94/200] [Batch 34/44] [D loss: 0.004760] [G loss: -0.010643]\n",
      "[Epoch 94/200] [Batch 36/44] [D loss: 0.003223] [G loss: -0.010639]\n",
      "[Epoch 94/200] [Batch 38/44] [D loss: 0.005213] [G loss: -0.010614]\n",
      "[Epoch 94/200] [Batch 40/44] [D loss: 0.005689] [G loss: -0.010607]\n",
      "[Epoch 94/200] [Batch 42/44] [D loss: 0.003646] [G loss: -0.010632]\n",
      "[Epoch 95/200] [Batch 0/44] [D loss: 0.004548] [G loss: -0.010630]\n",
      "[Epoch 95/200] [Batch 2/44] [D loss: 0.004502] [G loss: -0.010609]\n",
      "[Epoch 95/200] [Batch 4/44] [D loss: 0.007710] [G loss: -0.010629]\n",
      "[Epoch 95/200] [Batch 6/44] [D loss: 0.005552] [G loss: -0.010619]\n",
      "[Epoch 95/200] [Batch 8/44] [D loss: 0.007227] [G loss: -0.010623]\n",
      "[Epoch 95/200] [Batch 10/44] [D loss: 0.005329] [G loss: -0.010612]\n",
      "[Epoch 95/200] [Batch 12/44] [D loss: 0.004848] [G loss: -0.010612]\n",
      "[Epoch 95/200] [Batch 14/44] [D loss: 0.005862] [G loss: -0.010624]\n",
      "[Epoch 95/200] [Batch 16/44] [D loss: 0.006494] [G loss: -0.010623]\n",
      "[Epoch 95/200] [Batch 18/44] [D loss: 0.007120] [G loss: -0.010632]\n",
      "[Epoch 95/200] [Batch 20/44] [D loss: 0.005219] [G loss: -0.010615]\n",
      "[Epoch 95/200] [Batch 22/44] [D loss: 0.005757] [G loss: -0.010611]\n",
      "[Epoch 95/200] [Batch 24/44] [D loss: 0.006312] [G loss: -0.010606]\n",
      "[Epoch 95/200] [Batch 26/44] [D loss: 0.005653] [G loss: -0.010644]\n",
      "[Epoch 95/200] [Batch 28/44] [D loss: 0.005909] [G loss: -0.010633]\n",
      "[Epoch 95/200] [Batch 30/44] [D loss: 0.003282] [G loss: -0.010630]\n",
      "[Epoch 95/200] [Batch 32/44] [D loss: 0.007980] [G loss: -0.010598]\n",
      "[Epoch 95/200] [Batch 34/44] [D loss: 0.005679] [G loss: -0.010602]\n",
      "[Epoch 95/200] [Batch 36/44] [D loss: 0.006577] [G loss: -0.010619]\n",
      "[Epoch 95/200] [Batch 38/44] [D loss: 0.003820] [G loss: -0.010611]\n",
      "[Epoch 95/200] [Batch 40/44] [D loss: 0.005540] [G loss: -0.010625]\n",
      "[Epoch 95/200] [Batch 42/44] [D loss: 0.006528] [G loss: -0.010624]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 96/200] [Batch 0/44] [D loss: 0.006548] [G loss: -0.010598]\n",
      "[Epoch 96/200] [Batch 2/44] [D loss: 0.005529] [G loss: -0.010619]\n",
      "[Epoch 96/200] [Batch 4/44] [D loss: 0.006357] [G loss: -0.010619]\n",
      "[Epoch 96/200] [Batch 6/44] [D loss: 0.005741] [G loss: -0.010630]\n",
      "[Epoch 96/200] [Batch 8/44] [D loss: 0.005627] [G loss: -0.010614]\n",
      "[Epoch 96/200] [Batch 10/44] [D loss: 0.003450] [G loss: -0.010602]\n",
      "[Epoch 96/200] [Batch 12/44] [D loss: 0.004691] [G loss: -0.010620]\n",
      "[Epoch 96/200] [Batch 14/44] [D loss: 0.006074] [G loss: -0.010580]\n",
      "[Epoch 96/200] [Batch 16/44] [D loss: 0.005668] [G loss: -0.010616]\n",
      "[Epoch 96/200] [Batch 18/44] [D loss: 0.004679] [G loss: -0.010601]\n",
      "[Epoch 96/200] [Batch 20/44] [D loss: 0.006860] [G loss: -0.010628]\n",
      "[Epoch 96/200] [Batch 22/44] [D loss: 0.006118] [G loss: -0.010592]\n",
      "[Epoch 96/200] [Batch 24/44] [D loss: 0.006237] [G loss: -0.010623]\n",
      "[Epoch 96/200] [Batch 26/44] [D loss: 0.007230] [G loss: -0.010623]\n",
      "[Epoch 96/200] [Batch 28/44] [D loss: 0.006411] [G loss: -0.010639]\n",
      "[Epoch 96/200] [Batch 30/44] [D loss: 0.006948] [G loss: -0.010618]\n",
      "[Epoch 96/200] [Batch 32/44] [D loss: 0.005507] [G loss: -0.010631]\n",
      "[Epoch 96/200] [Batch 34/44] [D loss: 0.005996] [G loss: -0.010597]\n",
      "[Epoch 96/200] [Batch 36/44] [D loss: 0.005196] [G loss: -0.010603]\n",
      "[Epoch 96/200] [Batch 38/44] [D loss: 0.004146] [G loss: -0.010609]\n",
      "[Epoch 96/200] [Batch 40/44] [D loss: 0.006877] [G loss: -0.010621]\n",
      "[Epoch 96/200] [Batch 42/44] [D loss: 0.003884] [G loss: -0.010621]\n",
      "[Epoch 97/200] [Batch 0/44] [D loss: 0.005826] [G loss: -0.010631]\n",
      "[Epoch 97/200] [Batch 2/44] [D loss: 0.006965] [G loss: -0.010611]\n",
      "[Epoch 97/200] [Batch 4/44] [D loss: 0.005976] [G loss: -0.010625]\n",
      "[Epoch 97/200] [Batch 6/44] [D loss: 0.006452] [G loss: -0.010630]\n",
      "[Epoch 97/200] [Batch 8/44] [D loss: 0.005470] [G loss: -0.010616]\n",
      "[Epoch 97/200] [Batch 10/44] [D loss: 0.007029] [G loss: -0.010614]\n",
      "[Epoch 97/200] [Batch 12/44] [D loss: 0.005472] [G loss: -0.010603]\n",
      "[Epoch 97/200] [Batch 14/44] [D loss: 0.004056] [G loss: -0.010608]\n",
      "[Epoch 97/200] [Batch 16/44] [D loss: 0.004869] [G loss: -0.010631]\n",
      "[Epoch 97/200] [Batch 18/44] [D loss: 0.006562] [G loss: -0.010599]\n",
      "[Epoch 97/200] [Batch 20/44] [D loss: 0.005577] [G loss: -0.010576]\n",
      "[Epoch 97/200] [Batch 22/44] [D loss: 0.006225] [G loss: -0.010610]\n",
      "[Epoch 97/200] [Batch 24/44] [D loss: 0.005755] [G loss: -0.010596]\n",
      "[Epoch 97/200] [Batch 26/44] [D loss: 0.003699] [G loss: -0.010618]\n",
      "[Epoch 97/200] [Batch 28/44] [D loss: 0.007516] [G loss: -0.010620]\n",
      "[Epoch 97/200] [Batch 30/44] [D loss: 0.004128] [G loss: -0.010628]\n",
      "[Epoch 97/200] [Batch 32/44] [D loss: 0.005930] [G loss: -0.010628]\n",
      "[Epoch 97/200] [Batch 34/44] [D loss: 0.006665] [G loss: -0.010623]\n",
      "[Epoch 97/200] [Batch 36/44] [D loss: 0.003998] [G loss: -0.010617]\n",
      "[Epoch 97/200] [Batch 38/44] [D loss: 0.004246] [G loss: -0.010610]\n",
      "[Epoch 97/200] [Batch 40/44] [D loss: 0.006307] [G loss: -0.010598]\n",
      "[Epoch 97/200] [Batch 42/44] [D loss: 0.005833] [G loss: -0.010604]\n",
      "[Epoch 98/200] [Batch 0/44] [D loss: 0.006992] [G loss: -0.010613]\n",
      "[Epoch 98/200] [Batch 2/44] [D loss: 0.006289] [G loss: -0.010621]\n",
      "[Epoch 98/200] [Batch 4/44] [D loss: 0.005697] [G loss: -0.010620]\n",
      "[Epoch 98/200] [Batch 6/44] [D loss: 0.003264] [G loss: -0.010611]\n",
      "[Epoch 98/200] [Batch 8/44] [D loss: 0.003706] [G loss: -0.010620]\n",
      "[Epoch 98/200] [Batch 10/44] [D loss: 0.004787] [G loss: -0.010603]\n",
      "[Epoch 98/200] [Batch 12/44] [D loss: 0.005104] [G loss: -0.010602]\n",
      "[Epoch 98/200] [Batch 14/44] [D loss: 0.005467] [G loss: -0.010615]\n",
      "[Epoch 98/200] [Batch 16/44] [D loss: 0.005971] [G loss: -0.010606]\n",
      "[Epoch 98/200] [Batch 18/44] [D loss: 0.005394] [G loss: -0.010587]\n",
      "[Epoch 98/200] [Batch 20/44] [D loss: 0.005333] [G loss: -0.010613]\n",
      "[Epoch 98/200] [Batch 22/44] [D loss: 0.004997] [G loss: -0.010612]\n",
      "[Epoch 98/200] [Batch 24/44] [D loss: 0.006164] [G loss: -0.010626]\n",
      "[Epoch 98/200] [Batch 26/44] [D loss: 0.005322] [G loss: -0.010619]\n",
      "[Epoch 98/200] [Batch 28/44] [D loss: 0.003521] [G loss: -0.010614]\n",
      "[Epoch 98/200] [Batch 30/44] [D loss: 0.003788] [G loss: -0.010611]\n",
      "[Epoch 98/200] [Batch 32/44] [D loss: 0.006366] [G loss: -0.010618]\n",
      "[Epoch 98/200] [Batch 34/44] [D loss: 0.007713] [G loss: -0.010633]\n",
      "[Epoch 98/200] [Batch 36/44] [D loss: 0.004169] [G loss: -0.010613]\n",
      "[Epoch 98/200] [Batch 38/44] [D loss: 0.004020] [G loss: -0.010610]\n",
      "[Epoch 98/200] [Batch 40/44] [D loss: 0.005892] [G loss: -0.010620]\n",
      "[Epoch 98/200] [Batch 42/44] [D loss: 0.007267] [G loss: -0.010616]\n",
      "[Epoch 99/200] [Batch 0/44] [D loss: 0.003857] [G loss: -0.010607]\n",
      "[Epoch 99/200] [Batch 2/44] [D loss: 0.005194] [G loss: -0.010620]\n",
      "[Epoch 99/200] [Batch 4/44] [D loss: 0.006445] [G loss: -0.010607]\n",
      "[Epoch 99/200] [Batch 6/44] [D loss: 0.005687] [G loss: -0.010620]\n",
      "[Epoch 99/200] [Batch 8/44] [D loss: 0.004519] [G loss: -0.010610]\n",
      "[Epoch 99/200] [Batch 10/44] [D loss: 0.005419] [G loss: -0.010633]\n",
      "[Epoch 99/200] [Batch 12/44] [D loss: 0.005067] [G loss: -0.010628]\n",
      "[Epoch 99/200] [Batch 14/44] [D loss: 0.005535] [G loss: -0.010595]\n",
      "[Epoch 99/200] [Batch 16/44] [D loss: 0.005744] [G loss: -0.010594]\n",
      "[Epoch 99/200] [Batch 18/44] [D loss: 0.006975] [G loss: -0.010609]\n",
      "[Epoch 99/200] [Batch 20/44] [D loss: 0.005720] [G loss: -0.010616]\n",
      "[Epoch 99/200] [Batch 22/44] [D loss: 0.006094] [G loss: -0.010630]\n",
      "[Epoch 99/200] [Batch 24/44] [D loss: 0.005368] [G loss: -0.010622]\n",
      "[Epoch 99/200] [Batch 26/44] [D loss: 0.005647] [G loss: -0.010608]\n",
      "[Epoch 99/200] [Batch 28/44] [D loss: 0.003980] [G loss: -0.010633]\n",
      "[Epoch 99/200] [Batch 30/44] [D loss: 0.004441] [G loss: -0.010596]\n",
      "[Epoch 99/200] [Batch 32/44] [D loss: 0.003994] [G loss: -0.010621]\n",
      "[Epoch 99/200] [Batch 34/44] [D loss: 0.006315] [G loss: -0.010600]\n",
      "[Epoch 99/200] [Batch 36/44] [D loss: 0.005030] [G loss: -0.010607]\n",
      "[Epoch 99/200] [Batch 38/44] [D loss: 0.005063] [G loss: -0.010611]\n",
      "[Epoch 99/200] [Batch 40/44] [D loss: 0.006751] [G loss: -0.010611]\n",
      "[Epoch 99/200] [Batch 42/44] [D loss: 0.007199] [G loss: -0.010623]\n",
      "[Epoch 100/200] [Batch 0/44] [D loss: 0.005973] [G loss: -0.010618]\n",
      "[Epoch 100/200] [Batch 2/44] [D loss: 0.006771] [G loss: -0.010620]\n",
      "[Epoch 100/200] [Batch 4/44] [D loss: 0.006927] [G loss: -0.010620]\n",
      "[Epoch 100/200] [Batch 6/44] [D loss: 0.005277] [G loss: -0.010643]\n",
      "[Epoch 100/200] [Batch 8/44] [D loss: 0.006594] [G loss: -0.010610]\n",
      "[Epoch 100/200] [Batch 10/44] [D loss: 0.003558] [G loss: -0.010611]\n",
      "[Epoch 100/200] [Batch 12/44] [D loss: 0.004569] [G loss: -0.010616]\n",
      "[Epoch 100/200] [Batch 14/44] [D loss: 0.005339] [G loss: -0.010628]\n",
      "[Epoch 100/200] [Batch 16/44] [D loss: 0.005036] [G loss: -0.010623]\n",
      "[Epoch 100/200] [Batch 18/44] [D loss: 0.005663] [G loss: -0.010626]\n",
      "[Epoch 100/200] [Batch 20/44] [D loss: 0.006423] [G loss: -0.010656]\n",
      "[Epoch 100/200] [Batch 22/44] [D loss: 0.006628] [G loss: -0.010629]\n",
      "[Epoch 100/200] [Batch 24/44] [D loss: 0.005616] [G loss: -0.010621]\n",
      "[Epoch 100/200] [Batch 26/44] [D loss: 0.006297] [G loss: -0.010638]\n",
      "[Epoch 100/200] [Batch 28/44] [D loss: 0.006158] [G loss: -0.010622]\n",
      "[Epoch 100/200] [Batch 30/44] [D loss: 0.005978] [G loss: -0.010621]\n",
      "[Epoch 100/200] [Batch 32/44] [D loss: 0.005515] [G loss: -0.010635]\n",
      "[Epoch 100/200] [Batch 34/44] [D loss: 0.006644] [G loss: -0.010609]\n",
      "[Epoch 100/200] [Batch 36/44] [D loss: 0.006460] [G loss: -0.010596]\n",
      "[Epoch 100/200] [Batch 38/44] [D loss: 0.006475] [G loss: -0.010631]\n",
      "[Epoch 100/200] [Batch 40/44] [D loss: 0.005436] [G loss: -0.010622]\n",
      "[Epoch 100/200] [Batch 42/44] [D loss: 0.005763] [G loss: -0.010618]\n",
      "[Epoch 101/200] [Batch 0/44] [D loss: 0.006738] [G loss: -0.010611]\n",
      "[Epoch 101/200] [Batch 2/44] [D loss: 0.005113] [G loss: -0.010633]\n",
      "[Epoch 101/200] [Batch 4/44] [D loss: 0.006531] [G loss: -0.010610]\n",
      "[Epoch 101/200] [Batch 6/44] [D loss: 0.004985] [G loss: -0.010640]\n",
      "[Epoch 101/200] [Batch 8/44] [D loss: 0.003601] [G loss: -0.010610]\n",
      "[Epoch 101/200] [Batch 10/44] [D loss: 0.005406] [G loss: -0.010617]\n",
      "[Epoch 101/200] [Batch 12/44] [D loss: 0.003648] [G loss: -0.010629]\n",
      "[Epoch 101/200] [Batch 14/44] [D loss: 0.005625] [G loss: -0.010611]\n",
      "[Epoch 101/200] [Batch 16/44] [D loss: 0.006406] [G loss: -0.010633]\n",
      "[Epoch 101/200] [Batch 18/44] [D loss: 0.005229] [G loss: -0.010632]\n",
      "[Epoch 101/200] [Batch 20/44] [D loss: 0.003351] [G loss: -0.010634]\n",
      "[Epoch 101/200] [Batch 22/44] [D loss: 0.004545] [G loss: -0.010614]\n",
      "[Epoch 101/200] [Batch 24/44] [D loss: 0.006331] [G loss: -0.010616]\n",
      "[Epoch 101/200] [Batch 26/44] [D loss: 0.005677] [G loss: -0.010629]\n",
      "[Epoch 101/200] [Batch 28/44] [D loss: 0.005565] [G loss: -0.010620]\n",
      "[Epoch 101/200] [Batch 30/44] [D loss: 0.005099] [G loss: -0.010625]\n",
      "[Epoch 101/200] [Batch 32/44] [D loss: 0.006000] [G loss: -0.010630]\n",
      "[Epoch 101/200] [Batch 34/44] [D loss: 0.006349] [G loss: -0.010593]\n",
      "[Epoch 101/200] [Batch 36/44] [D loss: 0.006711] [G loss: -0.010633]\n",
      "[Epoch 101/200] [Batch 38/44] [D loss: 0.004991] [G loss: -0.010609]\n",
      "[Epoch 101/200] [Batch 40/44] [D loss: 0.005578] [G loss: -0.010626]\n",
      "[Epoch 101/200] [Batch 42/44] [D loss: 0.004693] [G loss: -0.010618]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 102/200] [Batch 0/44] [D loss: 0.006413] [G loss: -0.010624]\n",
      "[Epoch 102/200] [Batch 2/44] [D loss: 0.006398] [G loss: -0.010619]\n",
      "[Epoch 102/200] [Batch 4/44] [D loss: 0.004150] [G loss: -0.010619]\n",
      "[Epoch 102/200] [Batch 6/44] [D loss: 0.005194] [G loss: -0.010624]\n",
      "[Epoch 102/200] [Batch 8/44] [D loss: 0.005169] [G loss: -0.010611]\n",
      "[Epoch 102/200] [Batch 10/44] [D loss: 0.006378] [G loss: -0.010628]\n",
      "[Epoch 102/200] [Batch 12/44] [D loss: 0.004310] [G loss: -0.010617]\n",
      "[Epoch 102/200] [Batch 14/44] [D loss: 0.005193] [G loss: -0.010626]\n",
      "[Epoch 102/200] [Batch 16/44] [D loss: 0.007036] [G loss: -0.010623]\n",
      "[Epoch 102/200] [Batch 18/44] [D loss: 0.007110] [G loss: -0.010628]\n",
      "[Epoch 102/200] [Batch 20/44] [D loss: 0.005715] [G loss: -0.010615]\n",
      "[Epoch 102/200] [Batch 22/44] [D loss: 0.005097] [G loss: -0.010618]\n",
      "[Epoch 102/200] [Batch 24/44] [D loss: 0.006059] [G loss: -0.010638]\n",
      "[Epoch 102/200] [Batch 26/44] [D loss: 0.004949] [G loss: -0.010623]\n",
      "[Epoch 102/200] [Batch 28/44] [D loss: 0.005250] [G loss: -0.010615]\n",
      "[Epoch 102/200] [Batch 30/44] [D loss: 0.007069] [G loss: -0.010615]\n",
      "[Epoch 102/200] [Batch 32/44] [D loss: 0.007036] [G loss: -0.010641]\n",
      "[Epoch 102/200] [Batch 34/44] [D loss: 0.006083] [G loss: -0.010597]\n",
      "[Epoch 102/200] [Batch 36/44] [D loss: 0.006728] [G loss: -0.010619]\n",
      "[Epoch 102/200] [Batch 38/44] [D loss: 0.006348] [G loss: -0.010636]\n",
      "[Epoch 102/200] [Batch 40/44] [D loss: 0.005037] [G loss: -0.010591]\n",
      "[Epoch 102/200] [Batch 42/44] [D loss: 0.006558] [G loss: -0.010609]\n",
      "[Epoch 103/200] [Batch 0/44] [D loss: 0.006496] [G loss: -0.010633]\n",
      "[Epoch 103/200] [Batch 2/44] [D loss: 0.004732] [G loss: -0.010626]\n",
      "[Epoch 103/200] [Batch 4/44] [D loss: 0.005274] [G loss: -0.010642]\n",
      "[Epoch 103/200] [Batch 6/44] [D loss: 0.006557] [G loss: -0.010627]\n",
      "[Epoch 103/200] [Batch 8/44] [D loss: 0.005662] [G loss: -0.010623]\n",
      "[Epoch 103/200] [Batch 10/44] [D loss: 0.005350] [G loss: -0.010606]\n",
      "[Epoch 103/200] [Batch 12/44] [D loss: 0.006740] [G loss: -0.010619]\n",
      "[Epoch 103/200] [Batch 14/44] [D loss: 0.004545] [G loss: -0.010617]\n",
      "[Epoch 103/200] [Batch 16/44] [D loss: 0.006509] [G loss: -0.010625]\n",
      "[Epoch 103/200] [Batch 18/44] [D loss: 0.004402] [G loss: -0.010616]\n",
      "[Epoch 103/200] [Batch 20/44] [D loss: 0.004307] [G loss: -0.010619]\n",
      "[Epoch 103/200] [Batch 22/44] [D loss: 0.005907] [G loss: -0.010628]\n",
      "[Epoch 103/200] [Batch 24/44] [D loss: 0.006183] [G loss: -0.010634]\n",
      "[Epoch 103/200] [Batch 26/44] [D loss: 0.004931] [G loss: -0.010617]\n",
      "[Epoch 103/200] [Batch 28/44] [D loss: 0.004651] [G loss: -0.010608]\n",
      "[Epoch 103/200] [Batch 30/44] [D loss: 0.006441] [G loss: -0.010603]\n",
      "[Epoch 103/200] [Batch 32/44] [D loss: 0.005653] [G loss: -0.010620]\n",
      "[Epoch 103/200] [Batch 34/44] [D loss: 0.006641] [G loss: -0.010607]\n",
      "[Epoch 103/200] [Batch 36/44] [D loss: 0.003605] [G loss: -0.010625]\n",
      "[Epoch 103/200] [Batch 38/44] [D loss: 0.006893] [G loss: -0.010634]\n",
      "[Epoch 103/200] [Batch 40/44] [D loss: 0.007281] [G loss: -0.010620]\n",
      "[Epoch 103/200] [Batch 42/44] [D loss: 0.006674] [G loss: -0.010612]\n",
      "[Epoch 104/200] [Batch 0/44] [D loss: 0.005910] [G loss: -0.010628]\n",
      "[Epoch 104/200] [Batch 2/44] [D loss: 0.005149] [G loss: -0.010625]\n",
      "[Epoch 104/200] [Batch 4/44] [D loss: 0.007349] [G loss: -0.010622]\n",
      "[Epoch 104/200] [Batch 6/44] [D loss: 0.004503] [G loss: -0.010618]\n",
      "[Epoch 104/200] [Batch 8/44] [D loss: 0.005133] [G loss: -0.010622]\n",
      "[Epoch 104/200] [Batch 10/44] [D loss: 0.004404] [G loss: -0.010601]\n",
      "[Epoch 104/200] [Batch 12/44] [D loss: 0.005551] [G loss: -0.010614]\n",
      "[Epoch 104/200] [Batch 14/44] [D loss: 0.007865] [G loss: -0.010629]\n",
      "[Epoch 104/200] [Batch 16/44] [D loss: 0.004995] [G loss: -0.010631]\n",
      "[Epoch 104/200] [Batch 18/44] [D loss: 0.007393] [G loss: -0.010633]\n",
      "[Epoch 104/200] [Batch 20/44] [D loss: 0.006664] [G loss: -0.010630]\n",
      "[Epoch 104/200] [Batch 22/44] [D loss: 0.004882] [G loss: -0.010640]\n",
      "[Epoch 104/200] [Batch 24/44] [D loss: 0.006120] [G loss: -0.010623]\n",
      "[Epoch 104/200] [Batch 26/44] [D loss: 0.003995] [G loss: -0.010613]\n",
      "[Epoch 104/200] [Batch 28/44] [D loss: 0.005304] [G loss: -0.010629]\n",
      "[Epoch 104/200] [Batch 30/44] [D loss: 0.004094] [G loss: -0.010599]\n",
      "[Epoch 104/200] [Batch 32/44] [D loss: 0.006448] [G loss: -0.010621]\n",
      "[Epoch 104/200] [Batch 34/44] [D loss: 0.006956] [G loss: -0.010602]\n",
      "[Epoch 104/200] [Batch 36/44] [D loss: 0.006882] [G loss: -0.010622]\n",
      "[Epoch 104/200] [Batch 38/44] [D loss: 0.003887] [G loss: -0.010599]\n",
      "[Epoch 104/200] [Batch 40/44] [D loss: 0.007478] [G loss: -0.010611]\n",
      "[Epoch 104/200] [Batch 42/44] [D loss: 0.005990] [G loss: -0.010585]\n",
      "[Epoch 105/200] [Batch 0/44] [D loss: 0.004749] [G loss: -0.010608]\n",
      "[Epoch 105/200] [Batch 2/44] [D loss: 0.007139] [G loss: -0.010599]\n",
      "[Epoch 105/200] [Batch 4/44] [D loss: 0.006570] [G loss: -0.010611]\n",
      "[Epoch 105/200] [Batch 6/44] [D loss: 0.005000] [G loss: -0.010622]\n",
      "[Epoch 105/200] [Batch 8/44] [D loss: 0.006490] [G loss: -0.010606]\n",
      "[Epoch 105/200] [Batch 10/44] [D loss: 0.004950] [G loss: -0.010605]\n",
      "[Epoch 105/200] [Batch 12/44] [D loss: 0.004767] [G loss: -0.010628]\n",
      "[Epoch 105/200] [Batch 14/44] [D loss: 0.007720] [G loss: -0.010615]\n",
      "[Epoch 105/200] [Batch 16/44] [D loss: 0.004590] [G loss: -0.010598]\n",
      "[Epoch 105/200] [Batch 18/44] [D loss: 0.005384] [G loss: -0.010610]\n",
      "[Epoch 105/200] [Batch 20/44] [D loss: 0.005906] [G loss: -0.010622]\n",
      "[Epoch 105/200] [Batch 22/44] [D loss: 0.004806] [G loss: -0.010612]\n",
      "[Epoch 105/200] [Batch 24/44] [D loss: 0.005914] [G loss: -0.010635]\n",
      "[Epoch 105/200] [Batch 26/44] [D loss: 0.004714] [G loss: -0.010610]\n",
      "[Epoch 105/200] [Batch 28/44] [D loss: 0.003714] [G loss: -0.010611]\n",
      "[Epoch 105/200] [Batch 30/44] [D loss: 0.006622] [G loss: -0.010629]\n",
      "[Epoch 105/200] [Batch 32/44] [D loss: 0.004344] [G loss: -0.010638]\n",
      "[Epoch 105/200] [Batch 34/44] [D loss: 0.006932] [G loss: -0.010594]\n",
      "[Epoch 105/200] [Batch 36/44] [D loss: 0.006826] [G loss: -0.010627]\n",
      "[Epoch 105/200] [Batch 38/44] [D loss: 0.005004] [G loss: -0.010644]\n",
      "[Epoch 105/200] [Batch 40/44] [D loss: 0.006055] [G loss: -0.010623]\n",
      "[Epoch 105/200] [Batch 42/44] [D loss: 0.005157] [G loss: -0.010606]\n",
      "[Epoch 106/200] [Batch 0/44] [D loss: 0.005576] [G loss: -0.010621]\n",
      "[Epoch 106/200] [Batch 2/44] [D loss: 0.003939] [G loss: -0.010619]\n",
      "[Epoch 106/200] [Batch 4/44] [D loss: 0.006134] [G loss: -0.010633]\n",
      "[Epoch 106/200] [Batch 6/44] [D loss: 0.005701] [G loss: -0.010612]\n",
      "[Epoch 106/200] [Batch 8/44] [D loss: 0.006566] [G loss: -0.010619]\n",
      "[Epoch 106/200] [Batch 10/44] [D loss: 0.004956] [G loss: -0.010610]\n",
      "[Epoch 106/200] [Batch 12/44] [D loss: 0.004953] [G loss: -0.010621]\n",
      "[Epoch 106/200] [Batch 14/44] [D loss: 0.008010] [G loss: -0.010618]\n",
      "[Epoch 106/200] [Batch 16/44] [D loss: 0.006981] [G loss: -0.010619]\n",
      "[Epoch 106/200] [Batch 18/44] [D loss: 0.005257] [G loss: -0.010624]\n",
      "[Epoch 106/200] [Batch 20/44] [D loss: 0.006225] [G loss: -0.010618]\n",
      "[Epoch 106/200] [Batch 22/44] [D loss: 0.004940] [G loss: -0.010622]\n",
      "[Epoch 106/200] [Batch 24/44] [D loss: 0.003631] [G loss: -0.010645]\n",
      "[Epoch 106/200] [Batch 26/44] [D loss: 0.007120] [G loss: -0.010635]\n",
      "[Epoch 106/200] [Batch 28/44] [D loss: 0.006275] [G loss: -0.010633]\n",
      "[Epoch 106/200] [Batch 30/44] [D loss: 0.005173] [G loss: -0.010620]\n",
      "[Epoch 106/200] [Batch 32/44] [D loss: 0.006825] [G loss: -0.010631]\n",
      "[Epoch 106/200] [Batch 34/44] [D loss: 0.006268] [G loss: -0.010617]\n",
      "[Epoch 106/200] [Batch 36/44] [D loss: 0.004216] [G loss: -0.010642]\n",
      "[Epoch 106/200] [Batch 38/44] [D loss: 0.005293] [G loss: -0.010617]\n",
      "[Epoch 106/200] [Batch 40/44] [D loss: 0.004961] [G loss: -0.010623]\n",
      "[Epoch 106/200] [Batch 42/44] [D loss: 0.005320] [G loss: -0.010617]\n",
      "[Epoch 107/200] [Batch 0/44] [D loss: 0.004133] [G loss: -0.010610]\n",
      "[Epoch 107/200] [Batch 2/44] [D loss: 0.007315] [G loss: -0.010614]\n",
      "[Epoch 107/200] [Batch 4/44] [D loss: 0.005421] [G loss: -0.010625]\n",
      "[Epoch 107/200] [Batch 6/44] [D loss: 0.006876] [G loss: -0.010632]\n",
      "[Epoch 107/200] [Batch 8/44] [D loss: 0.005696] [G loss: -0.010601]\n",
      "[Epoch 107/200] [Batch 10/44] [D loss: 0.004681] [G loss: -0.010629]\n",
      "[Epoch 107/200] [Batch 12/44] [D loss: 0.006273] [G loss: -0.010600]\n",
      "[Epoch 107/200] [Batch 14/44] [D loss: 0.004841] [G loss: -0.010631]\n",
      "[Epoch 107/200] [Batch 16/44] [D loss: 0.006016] [G loss: -0.010626]\n",
      "[Epoch 107/200] [Batch 18/44] [D loss: 0.007802] [G loss: -0.010616]\n",
      "[Epoch 107/200] [Batch 20/44] [D loss: 0.005928] [G loss: -0.010606]\n",
      "[Epoch 107/200] [Batch 22/44] [D loss: 0.004129] [G loss: -0.010610]\n",
      "[Epoch 107/200] [Batch 24/44] [D loss: 0.005221] [G loss: -0.010629]\n",
      "[Epoch 107/200] [Batch 26/44] [D loss: 0.004708] [G loss: -0.010629]\n",
      "[Epoch 107/200] [Batch 28/44] [D loss: 0.006250] [G loss: -0.010630]\n",
      "[Epoch 107/200] [Batch 30/44] [D loss: 0.005421] [G loss: -0.010615]\n",
      "[Epoch 107/200] [Batch 32/44] [D loss: 0.005213] [G loss: -0.010607]\n",
      "[Epoch 107/200] [Batch 34/44] [D loss: 0.004134] [G loss: -0.010607]\n",
      "[Epoch 107/200] [Batch 36/44] [D loss: 0.005027] [G loss: -0.010616]\n",
      "[Epoch 107/200] [Batch 38/44] [D loss: 0.005074] [G loss: -0.010636]\n",
      "[Epoch 107/200] [Batch 40/44] [D loss: 0.005734] [G loss: -0.010594]\n",
      "[Epoch 107/200] [Batch 42/44] [D loss: 0.005085] [G loss: -0.010612]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 108/200] [Batch 0/44] [D loss: 0.005966] [G loss: -0.010609]\n",
      "[Epoch 108/200] [Batch 2/44] [D loss: 0.005766] [G loss: -0.010656]\n",
      "[Epoch 108/200] [Batch 4/44] [D loss: 0.005766] [G loss: -0.010614]\n",
      "[Epoch 108/200] [Batch 6/44] [D loss: 0.005000] [G loss: -0.010629]\n",
      "[Epoch 108/200] [Batch 8/44] [D loss: 0.005465] [G loss: -0.010624]\n",
      "[Epoch 108/200] [Batch 10/44] [D loss: 0.005893] [G loss: -0.010630]\n",
      "[Epoch 108/200] [Batch 12/44] [D loss: 0.006932] [G loss: -0.010621]\n",
      "[Epoch 108/200] [Batch 14/44] [D loss: 0.005815] [G loss: -0.010621]\n",
      "[Epoch 108/200] [Batch 16/44] [D loss: 0.005673] [G loss: -0.010618]\n",
      "[Epoch 108/200] [Batch 18/44] [D loss: 0.005788] [G loss: -0.010629]\n",
      "[Epoch 108/200] [Batch 20/44] [D loss: 0.006060] [G loss: -0.010607]\n",
      "[Epoch 108/200] [Batch 22/44] [D loss: 0.006440] [G loss: -0.010607]\n",
      "[Epoch 108/200] [Batch 24/44] [D loss: 0.004835] [G loss: -0.010608]\n",
      "[Epoch 108/200] [Batch 26/44] [D loss: 0.004737] [G loss: -0.010614]\n",
      "[Epoch 108/200] [Batch 28/44] [D loss: 0.004484] [G loss: -0.010633]\n",
      "[Epoch 108/200] [Batch 30/44] [D loss: 0.006673] [G loss: -0.010623]\n",
      "[Epoch 108/200] [Batch 32/44] [D loss: 0.005199] [G loss: -0.010638]\n",
      "[Epoch 108/200] [Batch 34/44] [D loss: 0.004283] [G loss: -0.010623]\n",
      "[Epoch 108/200] [Batch 36/44] [D loss: 0.006868] [G loss: -0.010633]\n",
      "[Epoch 108/200] [Batch 38/44] [D loss: 0.006636] [G loss: -0.010613]\n",
      "[Epoch 108/200] [Batch 40/44] [D loss: 0.005175] [G loss: -0.010594]\n",
      "[Epoch 108/200] [Batch 42/44] [D loss: 0.005234] [G loss: -0.010644]\n",
      "[Epoch 109/200] [Batch 0/44] [D loss: 0.004901] [G loss: -0.010628]\n",
      "[Epoch 109/200] [Batch 2/44] [D loss: 0.006385] [G loss: -0.010621]\n",
      "[Epoch 109/200] [Batch 4/44] [D loss: 0.004787] [G loss: -0.010622]\n",
      "[Epoch 109/200] [Batch 6/44] [D loss: 0.005104] [G loss: -0.010617]\n",
      "[Epoch 109/200] [Batch 8/44] [D loss: 0.005518] [G loss: -0.010635]\n",
      "[Epoch 109/200] [Batch 10/44] [D loss: 0.007176] [G loss: -0.010603]\n",
      "[Epoch 109/200] [Batch 12/44] [D loss: 0.004834] [G loss: -0.010615]\n",
      "[Epoch 109/200] [Batch 14/44] [D loss: 0.003726] [G loss: -0.010605]\n",
      "[Epoch 109/200] [Batch 16/44] [D loss: 0.006334] [G loss: -0.010625]\n",
      "[Epoch 109/200] [Batch 18/44] [D loss: 0.007075] [G loss: -0.010631]\n",
      "[Epoch 109/200] [Batch 20/44] [D loss: 0.005142] [G loss: -0.010606]\n",
      "[Epoch 109/200] [Batch 22/44] [D loss: 0.004593] [G loss: -0.010608]\n",
      "[Epoch 109/200] [Batch 24/44] [D loss: 0.006663] [G loss: -0.010609]\n",
      "[Epoch 109/200] [Batch 26/44] [D loss: 0.005185] [G loss: -0.010627]\n",
      "[Epoch 109/200] [Batch 28/44] [D loss: 0.004762] [G loss: -0.010616]\n",
      "[Epoch 109/200] [Batch 30/44] [D loss: 0.003735] [G loss: -0.010619]\n",
      "[Epoch 109/200] [Batch 32/44] [D loss: 0.006363] [G loss: -0.010624]\n",
      "[Epoch 109/200] [Batch 34/44] [D loss: 0.005747] [G loss: -0.010607]\n",
      "[Epoch 109/200] [Batch 36/44] [D loss: 0.004262] [G loss: -0.010615]\n",
      "[Epoch 109/200] [Batch 38/44] [D loss: 0.003034] [G loss: -0.010622]\n",
      "[Epoch 109/200] [Batch 40/44] [D loss: 0.004493] [G loss: -0.010618]\n",
      "[Epoch 109/200] [Batch 42/44] [D loss: 0.004966] [G loss: -0.010615]\n",
      "[Epoch 110/200] [Batch 0/44] [D loss: 0.005175] [G loss: -0.010598]\n",
      "[Epoch 110/200] [Batch 2/44] [D loss: 0.005406] [G loss: -0.010615]\n",
      "[Epoch 110/200] [Batch 4/44] [D loss: 0.005535] [G loss: -0.010614]\n",
      "[Epoch 110/200] [Batch 6/44] [D loss: 0.007444] [G loss: -0.010617]\n",
      "[Epoch 110/200] [Batch 8/44] [D loss: 0.004697] [G loss: -0.010609]\n",
      "[Epoch 110/200] [Batch 10/44] [D loss: 0.007200] [G loss: -0.010645]\n",
      "[Epoch 110/200] [Batch 12/44] [D loss: 0.006512] [G loss: -0.010617]\n",
      "[Epoch 110/200] [Batch 14/44] [D loss: 0.004405] [G loss: -0.010613]\n",
      "[Epoch 110/200] [Batch 16/44] [D loss: 0.004466] [G loss: -0.010612]\n",
      "[Epoch 110/200] [Batch 18/44] [D loss: 0.005942] [G loss: -0.010621]\n",
      "[Epoch 110/200] [Batch 20/44] [D loss: 0.005811] [G loss: -0.010589]\n",
      "[Epoch 110/200] [Batch 22/44] [D loss: 0.006665] [G loss: -0.010629]\n",
      "[Epoch 110/200] [Batch 24/44] [D loss: 0.003922] [G loss: -0.010626]\n",
      "[Epoch 110/200] [Batch 26/44] [D loss: 0.005850] [G loss: -0.010612]\n",
      "[Epoch 110/200] [Batch 28/44] [D loss: 0.006134] [G loss: -0.010615]\n",
      "[Epoch 110/200] [Batch 30/44] [D loss: 0.004313] [G loss: -0.010600]\n",
      "[Epoch 110/200] [Batch 32/44] [D loss: 0.003309] [G loss: -0.010629]\n",
      "[Epoch 110/200] [Batch 34/44] [D loss: 0.007132] [G loss: -0.010601]\n",
      "[Epoch 110/200] [Batch 36/44] [D loss: 0.005529] [G loss: -0.010598]\n",
      "[Epoch 110/200] [Batch 38/44] [D loss: 0.004256] [G loss: -0.010602]\n",
      "[Epoch 110/200] [Batch 40/44] [D loss: 0.004683] [G loss: -0.010608]\n",
      "[Epoch 110/200] [Batch 42/44] [D loss: 0.007442] [G loss: -0.010638]\n",
      "[Epoch 111/200] [Batch 0/44] [D loss: 0.007093] [G loss: -0.010627]\n",
      "[Epoch 111/200] [Batch 2/44] [D loss: 0.004644] [G loss: -0.010615]\n",
      "[Epoch 111/200] [Batch 4/44] [D loss: 0.005540] [G loss: -0.010613]\n",
      "[Epoch 111/200] [Batch 6/44] [D loss: 0.005271] [G loss: -0.010618]\n",
      "[Epoch 111/200] [Batch 8/44] [D loss: 0.007969] [G loss: -0.010625]\n",
      "[Epoch 111/200] [Batch 10/44] [D loss: 0.006681] [G loss: -0.010637]\n",
      "[Epoch 111/200] [Batch 12/44] [D loss: 0.006038] [G loss: -0.010627]\n",
      "[Epoch 111/200] [Batch 14/44] [D loss: 0.003548] [G loss: -0.010617]\n",
      "[Epoch 111/200] [Batch 16/44] [D loss: 0.005110] [G loss: -0.010624]\n",
      "[Epoch 111/200] [Batch 18/44] [D loss: 0.006782] [G loss: -0.010621]\n",
      "[Epoch 111/200] [Batch 20/44] [D loss: 0.005362] [G loss: -0.010630]\n",
      "[Epoch 111/200] [Batch 22/44] [D loss: 0.003053] [G loss: -0.010616]\n",
      "[Epoch 111/200] [Batch 24/44] [D loss: 0.005366] [G loss: -0.010631]\n",
      "[Epoch 111/200] [Batch 26/44] [D loss: 0.005092] [G loss: -0.010621]\n",
      "[Epoch 111/200] [Batch 28/44] [D loss: 0.003280] [G loss: -0.010593]\n",
      "[Epoch 111/200] [Batch 30/44] [D loss: 0.006577] [G loss: -0.010626]\n",
      "[Epoch 111/200] [Batch 32/44] [D loss: 0.004965] [G loss: -0.010621]\n",
      "[Epoch 111/200] [Batch 34/44] [D loss: 0.005689] [G loss: -0.010622]\n",
      "[Epoch 111/200] [Batch 36/44] [D loss: 0.006991] [G loss: -0.010616]\n",
      "[Epoch 111/200] [Batch 38/44] [D loss: 0.003235] [G loss: -0.010630]\n",
      "[Epoch 111/200] [Batch 40/44] [D loss: 0.006881] [G loss: -0.010594]\n",
      "[Epoch 111/200] [Batch 42/44] [D loss: 0.005808] [G loss: -0.010611]\n",
      "[Epoch 112/200] [Batch 0/44] [D loss: 0.006131] [G loss: -0.010606]\n",
      "[Epoch 112/200] [Batch 2/44] [D loss: 0.006871] [G loss: -0.010597]\n",
      "[Epoch 112/200] [Batch 4/44] [D loss: 0.005727] [G loss: -0.010613]\n",
      "[Epoch 112/200] [Batch 6/44] [D loss: 0.001662] [G loss: -0.010615]\n",
      "[Epoch 112/200] [Batch 8/44] [D loss: 0.005164] [G loss: -0.010621]\n",
      "[Epoch 112/200] [Batch 10/44] [D loss: 0.004725] [G loss: -0.010629]\n",
      "[Epoch 112/200] [Batch 12/44] [D loss: 0.004172] [G loss: -0.010619]\n",
      "[Epoch 112/200] [Batch 14/44] [D loss: 0.007734] [G loss: -0.010604]\n",
      "[Epoch 112/200] [Batch 16/44] [D loss: 0.004043] [G loss: -0.010621]\n",
      "[Epoch 112/200] [Batch 18/44] [D loss: 0.005491] [G loss: -0.010618]\n",
      "[Epoch 112/200] [Batch 20/44] [D loss: 0.007675] [G loss: -0.010636]\n",
      "[Epoch 112/200] [Batch 22/44] [D loss: 0.005503] [G loss: -0.010613]\n",
      "[Epoch 112/200] [Batch 24/44] [D loss: 0.005063] [G loss: -0.010631]\n",
      "[Epoch 112/200] [Batch 26/44] [D loss: 0.005930] [G loss: -0.010614]\n",
      "[Epoch 112/200] [Batch 28/44] [D loss: 0.003498] [G loss: -0.010637]\n",
      "[Epoch 112/200] [Batch 30/44] [D loss: 0.005328] [G loss: -0.010634]\n",
      "[Epoch 112/200] [Batch 32/44] [D loss: 0.003867] [G loss: -0.010640]\n",
      "[Epoch 112/200] [Batch 34/44] [D loss: 0.007066] [G loss: -0.010622]\n",
      "[Epoch 112/200] [Batch 36/44] [D loss: 0.005068] [G loss: -0.010621]\n",
      "[Epoch 112/200] [Batch 38/44] [D loss: 0.006871] [G loss: -0.010609]\n",
      "[Epoch 112/200] [Batch 40/44] [D loss: 0.006146] [G loss: -0.010606]\n",
      "[Epoch 112/200] [Batch 42/44] [D loss: 0.005667] [G loss: -0.010647]\n",
      "[Epoch 113/200] [Batch 0/44] [D loss: 0.008413] [G loss: -0.010617]\n",
      "[Epoch 113/200] [Batch 2/44] [D loss: 0.005406] [G loss: -0.010620]\n",
      "[Epoch 113/200] [Batch 4/44] [D loss: 0.006834] [G loss: -0.010626]\n",
      "[Epoch 113/200] [Batch 6/44] [D loss: 0.006674] [G loss: -0.010635]\n",
      "[Epoch 113/200] [Batch 8/44] [D loss: 0.004810] [G loss: -0.010614]\n",
      "[Epoch 113/200] [Batch 10/44] [D loss: 0.007233] [G loss: -0.010619]\n",
      "[Epoch 113/200] [Batch 12/44] [D loss: 0.005562] [G loss: -0.010602]\n",
      "[Epoch 113/200] [Batch 14/44] [D loss: 0.006300] [G loss: -0.010635]\n",
      "[Epoch 113/200] [Batch 16/44] [D loss: 0.006028] [G loss: -0.010614]\n",
      "[Epoch 113/200] [Batch 18/44] [D loss: 0.005848] [G loss: -0.010626]\n",
      "[Epoch 113/200] [Batch 20/44] [D loss: 0.007166] [G loss: -0.010626]\n",
      "[Epoch 113/200] [Batch 22/44] [D loss: 0.005831] [G loss: -0.010637]\n",
      "[Epoch 113/200] [Batch 24/44] [D loss: 0.004998] [G loss: -0.010618]\n",
      "[Epoch 113/200] [Batch 26/44] [D loss: 0.006150] [G loss: -0.010607]\n",
      "[Epoch 113/200] [Batch 28/44] [D loss: 0.005563] [G loss: -0.010626]\n",
      "[Epoch 113/200] [Batch 30/44] [D loss: 0.005647] [G loss: -0.010624]\n",
      "[Epoch 113/200] [Batch 32/44] [D loss: 0.004160] [G loss: -0.010588]\n",
      "[Epoch 113/200] [Batch 34/44] [D loss: 0.006437] [G loss: -0.010621]\n",
      "[Epoch 113/200] [Batch 36/44] [D loss: 0.004942] [G loss: -0.010618]\n",
      "[Epoch 113/200] [Batch 38/44] [D loss: 0.006016] [G loss: -0.010608]\n",
      "[Epoch 113/200] [Batch 40/44] [D loss: 0.005480] [G loss: -0.010615]\n",
      "[Epoch 113/200] [Batch 42/44] [D loss: 0.004491] [G loss: -0.010625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 114/200] [Batch 0/44] [D loss: 0.006895] [G loss: -0.010627]\n",
      "[Epoch 114/200] [Batch 2/44] [D loss: 0.006248] [G loss: -0.010623]\n",
      "[Epoch 114/200] [Batch 4/44] [D loss: 0.005937] [G loss: -0.010615]\n",
      "[Epoch 114/200] [Batch 6/44] [D loss: 0.004913] [G loss: -0.010616]\n",
      "[Epoch 114/200] [Batch 8/44] [D loss: 0.004979] [G loss: -0.010615]\n",
      "[Epoch 114/200] [Batch 10/44] [D loss: 0.004996] [G loss: -0.010630]\n",
      "[Epoch 114/200] [Batch 12/44] [D loss: 0.005443] [G loss: -0.010615]\n",
      "[Epoch 114/200] [Batch 14/44] [D loss: 0.005776] [G loss: -0.010616]\n",
      "[Epoch 114/200] [Batch 16/44] [D loss: 0.005343] [G loss: -0.010610]\n",
      "[Epoch 114/200] [Batch 18/44] [D loss: 0.005684] [G loss: -0.010592]\n",
      "[Epoch 114/200] [Batch 20/44] [D loss: 0.006727] [G loss: -0.010602]\n",
      "[Epoch 114/200] [Batch 22/44] [D loss: 0.005747] [G loss: -0.010598]\n",
      "[Epoch 114/200] [Batch 24/44] [D loss: 0.005095] [G loss: -0.010607]\n",
      "[Epoch 114/200] [Batch 26/44] [D loss: 0.006453] [G loss: -0.010633]\n",
      "[Epoch 114/200] [Batch 28/44] [D loss: 0.005825] [G loss: -0.010616]\n",
      "[Epoch 114/200] [Batch 30/44] [D loss: 0.007730] [G loss: -0.010623]\n",
      "[Epoch 114/200] [Batch 32/44] [D loss: 0.004669] [G loss: -0.010634]\n",
      "[Epoch 114/200] [Batch 34/44] [D loss: 0.007301] [G loss: -0.010622]\n",
      "[Epoch 114/200] [Batch 36/44] [D loss: 0.005974] [G loss: -0.010616]\n",
      "[Epoch 114/200] [Batch 38/44] [D loss: 0.005469] [G loss: -0.010616]\n",
      "[Epoch 114/200] [Batch 40/44] [D loss: 0.005336] [G loss: -0.010624]\n",
      "[Epoch 114/200] [Batch 42/44] [D loss: 0.006652] [G loss: -0.010621]\n",
      "[Epoch 115/200] [Batch 0/44] [D loss: 0.005601] [G loss: -0.010644]\n",
      "[Epoch 115/200] [Batch 2/44] [D loss: 0.005928] [G loss: -0.010632]\n",
      "[Epoch 115/200] [Batch 4/44] [D loss: 0.004665] [G loss: -0.010613]\n",
      "[Epoch 115/200] [Batch 6/44] [D loss: 0.002531] [G loss: -0.010595]\n",
      "[Epoch 115/200] [Batch 8/44] [D loss: 0.005210] [G loss: -0.010634]\n",
      "[Epoch 115/200] [Batch 10/44] [D loss: 0.004851] [G loss: -0.010625]\n",
      "[Epoch 115/200] [Batch 12/44] [D loss: 0.003443] [G loss: -0.010609]\n",
      "[Epoch 115/200] [Batch 14/44] [D loss: 0.004026] [G loss: -0.010595]\n",
      "[Epoch 115/200] [Batch 16/44] [D loss: 0.003446] [G loss: -0.010619]\n",
      "[Epoch 115/200] [Batch 18/44] [D loss: 0.006363] [G loss: -0.010613]\n",
      "[Epoch 115/200] [Batch 20/44] [D loss: 0.005061] [G loss: -0.010635]\n",
      "[Epoch 115/200] [Batch 22/44] [D loss: 0.005537] [G loss: -0.010640]\n",
      "[Epoch 115/200] [Batch 24/44] [D loss: 0.004528] [G loss: -0.010614]\n",
      "[Epoch 115/200] [Batch 26/44] [D loss: 0.006564] [G loss: -0.010623]\n",
      "[Epoch 115/200] [Batch 28/44] [D loss: 0.006642] [G loss: -0.010607]\n",
      "[Epoch 115/200] [Batch 30/44] [D loss: 0.005220] [G loss: -0.010618]\n",
      "[Epoch 115/200] [Batch 32/44] [D loss: 0.004992] [G loss: -0.010623]\n",
      "[Epoch 115/200] [Batch 34/44] [D loss: 0.004358] [G loss: -0.010628]\n",
      "[Epoch 115/200] [Batch 36/44] [D loss: 0.007695] [G loss: -0.010617]\n",
      "[Epoch 115/200] [Batch 38/44] [D loss: 0.005911] [G loss: -0.010639]\n",
      "[Epoch 115/200] [Batch 40/44] [D loss: 0.005446] [G loss: -0.010609]\n",
      "[Epoch 115/200] [Batch 42/44] [D loss: 0.006635] [G loss: -0.010612]\n",
      "[Epoch 116/200] [Batch 0/44] [D loss: 0.003835] [G loss: -0.010593]\n",
      "[Epoch 116/200] [Batch 2/44] [D loss: 0.005739] [G loss: -0.010592]\n",
      "[Epoch 116/200] [Batch 4/44] [D loss: 0.007118] [G loss: -0.010612]\n",
      "[Epoch 116/200] [Batch 6/44] [D loss: 0.007756] [G loss: -0.010609]\n",
      "[Epoch 116/200] [Batch 8/44] [D loss: 0.006319] [G loss: -0.010626]\n",
      "[Epoch 116/200] [Batch 10/44] [D loss: 0.005233] [G loss: -0.010607]\n",
      "[Epoch 116/200] [Batch 12/44] [D loss: 0.004302] [G loss: -0.010609]\n",
      "[Epoch 116/200] [Batch 14/44] [D loss: 0.006644] [G loss: -0.010594]\n",
      "[Epoch 116/200] [Batch 16/44] [D loss: 0.004754] [G loss: -0.010628]\n",
      "[Epoch 116/200] [Batch 18/44] [D loss: 0.003722] [G loss: -0.010614]\n",
      "[Epoch 116/200] [Batch 20/44] [D loss: 0.006365] [G loss: -0.010627]\n",
      "[Epoch 116/200] [Batch 22/44] [D loss: 0.005326] [G loss: -0.010629]\n",
      "[Epoch 116/200] [Batch 24/44] [D loss: 0.005557] [G loss: -0.010594]\n",
      "[Epoch 116/200] [Batch 26/44] [D loss: 0.006035] [G loss: -0.010591]\n",
      "[Epoch 116/200] [Batch 28/44] [D loss: 0.005451] [G loss: -0.010620]\n",
      "[Epoch 116/200] [Batch 30/44] [D loss: 0.006973] [G loss: -0.010629]\n",
      "[Epoch 116/200] [Batch 32/44] [D loss: 0.005489] [G loss: -0.010601]\n",
      "[Epoch 116/200] [Batch 34/44] [D loss: 0.006123] [G loss: -0.010624]\n",
      "[Epoch 116/200] [Batch 36/44] [D loss: 0.004911] [G loss: -0.010624]\n",
      "[Epoch 116/200] [Batch 38/44] [D loss: 0.005208] [G loss: -0.010624]\n",
      "[Epoch 116/200] [Batch 40/44] [D loss: 0.005492] [G loss: -0.010597]\n",
      "[Epoch 116/200] [Batch 42/44] [D loss: 0.004874] [G loss: -0.010614]\n",
      "[Epoch 117/200] [Batch 0/44] [D loss: 0.006117] [G loss: -0.010614]\n",
      "[Epoch 117/200] [Batch 2/44] [D loss: 0.006216] [G loss: -0.010622]\n",
      "[Epoch 117/200] [Batch 4/44] [D loss: 0.004721] [G loss: -0.010610]\n",
      "[Epoch 117/200] [Batch 6/44] [D loss: 0.005560] [G loss: -0.010624]\n",
      "[Epoch 117/200] [Batch 8/44] [D loss: 0.004755] [G loss: -0.010621]\n",
      "[Epoch 117/200] [Batch 10/44] [D loss: 0.005978] [G loss: -0.010603]\n",
      "[Epoch 117/200] [Batch 12/44] [D loss: 0.005466] [G loss: -0.010619]\n",
      "[Epoch 117/200] [Batch 14/44] [D loss: 0.006782] [G loss: -0.010607]\n",
      "[Epoch 117/200] [Batch 16/44] [D loss: 0.006099] [G loss: -0.010623]\n",
      "[Epoch 117/200] [Batch 18/44] [D loss: 0.005583] [G loss: -0.010611]\n",
      "[Epoch 117/200] [Batch 20/44] [D loss: 0.004389] [G loss: -0.010622]\n",
      "[Epoch 117/200] [Batch 22/44] [D loss: 0.005398] [G loss: -0.010626]\n",
      "[Epoch 117/200] [Batch 24/44] [D loss: 0.006267] [G loss: -0.010599]\n",
      "[Epoch 117/200] [Batch 26/44] [D loss: 0.004708] [G loss: -0.010594]\n",
      "[Epoch 117/200] [Batch 28/44] [D loss: 0.004889] [G loss: -0.010601]\n",
      "[Epoch 117/200] [Batch 30/44] [D loss: 0.003466] [G loss: -0.010630]\n",
      "[Epoch 117/200] [Batch 32/44] [D loss: 0.006628] [G loss: -0.010608]\n",
      "[Epoch 117/200] [Batch 34/44] [D loss: 0.005443] [G loss: -0.010609]\n",
      "[Epoch 117/200] [Batch 36/44] [D loss: 0.005455] [G loss: -0.010609]\n",
      "[Epoch 117/200] [Batch 38/44] [D loss: 0.006553] [G loss: -0.010629]\n",
      "[Epoch 117/200] [Batch 40/44] [D loss: 0.005309] [G loss: -0.010596]\n",
      "[Epoch 117/200] [Batch 42/44] [D loss: 0.005997] [G loss: -0.010603]\n",
      "[Epoch 118/200] [Batch 0/44] [D loss: 0.006076] [G loss: -0.010616]\n",
      "[Epoch 118/200] [Batch 2/44] [D loss: 0.005285] [G loss: -0.010604]\n",
      "[Epoch 118/200] [Batch 4/44] [D loss: 0.004785] [G loss: -0.010613]\n",
      "[Epoch 118/200] [Batch 6/44] [D loss: 0.006839] [G loss: -0.010608]\n",
      "[Epoch 118/200] [Batch 8/44] [D loss: 0.005170] [G loss: -0.010615]\n",
      "[Epoch 118/200] [Batch 10/44] [D loss: 0.005294] [G loss: -0.010609]\n",
      "[Epoch 118/200] [Batch 12/44] [D loss: 0.006232] [G loss: -0.010587]\n",
      "[Epoch 118/200] [Batch 14/44] [D loss: 0.004490] [G loss: -0.010584]\n",
      "[Epoch 118/200] [Batch 16/44] [D loss: 0.006067] [G loss: -0.010616]\n",
      "[Epoch 118/200] [Batch 18/44] [D loss: 0.005705] [G loss: -0.010613]\n",
      "[Epoch 118/200] [Batch 20/44] [D loss: 0.005354] [G loss: -0.010604]\n",
      "[Epoch 118/200] [Batch 22/44] [D loss: 0.003709] [G loss: -0.010636]\n",
      "[Epoch 118/200] [Batch 24/44] [D loss: 0.002762] [G loss: -0.010615]\n",
      "[Epoch 118/200] [Batch 26/44] [D loss: 0.006833] [G loss: -0.010616]\n",
      "[Epoch 118/200] [Batch 28/44] [D loss: 0.004859] [G loss: -0.010622]\n",
      "[Epoch 118/200] [Batch 30/44] [D loss: 0.004762] [G loss: -0.010621]\n",
      "[Epoch 118/200] [Batch 32/44] [D loss: 0.005598] [G loss: -0.010610]\n",
      "[Epoch 118/200] [Batch 34/44] [D loss: 0.005352] [G loss: -0.010641]\n",
      "[Epoch 118/200] [Batch 36/44] [D loss: 0.005697] [G loss: -0.010601]\n",
      "[Epoch 118/200] [Batch 38/44] [D loss: 0.005897] [G loss: -0.010637]\n",
      "[Epoch 118/200] [Batch 40/44] [D loss: 0.003660] [G loss: -0.010606]\n",
      "[Epoch 118/200] [Batch 42/44] [D loss: 0.005344] [G loss: -0.010608]\n",
      "[Epoch 119/200] [Batch 0/44] [D loss: 0.003751] [G loss: -0.010625]\n",
      "[Epoch 119/200] [Batch 2/44] [D loss: 0.005750] [G loss: -0.010601]\n",
      "[Epoch 119/200] [Batch 4/44] [D loss: 0.007275] [G loss: -0.010637]\n",
      "[Epoch 119/200] [Batch 6/44] [D loss: 0.006458] [G loss: -0.010613]\n",
      "[Epoch 119/200] [Batch 8/44] [D loss: 0.005045] [G loss: -0.010608]\n",
      "[Epoch 119/200] [Batch 10/44] [D loss: 0.006303] [G loss: -0.010601]\n",
      "[Epoch 119/200] [Batch 12/44] [D loss: 0.005249] [G loss: -0.010618]\n",
      "[Epoch 119/200] [Batch 14/44] [D loss: 0.004621] [G loss: -0.010614]\n",
      "[Epoch 119/200] [Batch 16/44] [D loss: 0.004391] [G loss: -0.010644]\n",
      "[Epoch 119/200] [Batch 18/44] [D loss: 0.006897] [G loss: -0.010619]\n",
      "[Epoch 119/200] [Batch 20/44] [D loss: 0.006738] [G loss: -0.010615]\n",
      "[Epoch 119/200] [Batch 22/44] [D loss: 0.005453] [G loss: -0.010620]\n",
      "[Epoch 119/200] [Batch 24/44] [D loss: 0.006555] [G loss: -0.010611]\n",
      "[Epoch 119/200] [Batch 26/44] [D loss: 0.004850] [G loss: -0.010612]\n",
      "[Epoch 119/200] [Batch 28/44] [D loss: 0.005827] [G loss: -0.010612]\n",
      "[Epoch 119/200] [Batch 30/44] [D loss: 0.007294] [G loss: -0.010626]\n",
      "[Epoch 119/200] [Batch 32/44] [D loss: 0.006800] [G loss: -0.010609]\n",
      "[Epoch 119/200] [Batch 34/44] [D loss: 0.005443] [G loss: -0.010623]\n",
      "[Epoch 119/200] [Batch 36/44] [D loss: 0.006449] [G loss: -0.010643]\n",
      "[Epoch 119/200] [Batch 38/44] [D loss: 0.002623] [G loss: -0.010632]\n",
      "[Epoch 119/200] [Batch 40/44] [D loss: 0.004332] [G loss: -0.010632]\n",
      "[Epoch 119/200] [Batch 42/44] [D loss: 0.006016] [G loss: -0.010633]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 120/200] [Batch 0/44] [D loss: 0.003623] [G loss: -0.010618]\n",
      "[Epoch 120/200] [Batch 2/44] [D loss: 0.006540] [G loss: -0.010628]\n",
      "[Epoch 120/200] [Batch 4/44] [D loss: 0.005025] [G loss: -0.010619]\n",
      "[Epoch 120/200] [Batch 6/44] [D loss: 0.005780] [G loss: -0.010606]\n",
      "[Epoch 120/200] [Batch 8/44] [D loss: 0.005729] [G loss: -0.010637]\n",
      "[Epoch 120/200] [Batch 10/44] [D loss: 0.007569] [G loss: -0.010593]\n",
      "[Epoch 120/200] [Batch 12/44] [D loss: 0.006554] [G loss: -0.010619]\n",
      "[Epoch 120/200] [Batch 14/44] [D loss: 0.004535] [G loss: -0.010614]\n",
      "[Epoch 120/200] [Batch 16/44] [D loss: 0.006656] [G loss: -0.010613]\n",
      "[Epoch 120/200] [Batch 18/44] [D loss: 0.005427] [G loss: -0.010607]\n",
      "[Epoch 120/200] [Batch 20/44] [D loss: 0.005288] [G loss: -0.010619]\n",
      "[Epoch 120/200] [Batch 22/44] [D loss: 0.006811] [G loss: -0.010612]\n",
      "[Epoch 120/200] [Batch 24/44] [D loss: 0.005619] [G loss: -0.010618]\n",
      "[Epoch 120/200] [Batch 26/44] [D loss: 0.006514] [G loss: -0.010603]\n",
      "[Epoch 120/200] [Batch 28/44] [D loss: 0.004803] [G loss: -0.010630]\n",
      "[Epoch 120/200] [Batch 30/44] [D loss: 0.006254] [G loss: -0.010592]\n",
      "[Epoch 120/200] [Batch 32/44] [D loss: 0.005777] [G loss: -0.010611]\n",
      "[Epoch 120/200] [Batch 34/44] [D loss: 0.004546] [G loss: -0.010625]\n",
      "[Epoch 120/200] [Batch 36/44] [D loss: 0.005831] [G loss: -0.010633]\n",
      "[Epoch 120/200] [Batch 38/44] [D loss: 0.004815] [G loss: -0.010616]\n",
      "[Epoch 120/200] [Batch 40/44] [D loss: 0.006785] [G loss: -0.010605]\n",
      "[Epoch 120/200] [Batch 42/44] [D loss: 0.006652] [G loss: -0.010639]\n",
      "[Epoch 121/200] [Batch 0/44] [D loss: 0.004203] [G loss: -0.010623]\n",
      "[Epoch 121/200] [Batch 2/44] [D loss: 0.006825] [G loss: -0.010594]\n",
      "[Epoch 121/200] [Batch 4/44] [D loss: 0.006998] [G loss: -0.010620]\n",
      "[Epoch 121/200] [Batch 6/44] [D loss: 0.005310] [G loss: -0.010596]\n",
      "[Epoch 121/200] [Batch 8/44] [D loss: 0.005344] [G loss: -0.010612]\n",
      "[Epoch 121/200] [Batch 10/44] [D loss: 0.006210] [G loss: -0.010619]\n",
      "[Epoch 121/200] [Batch 12/44] [D loss: 0.005931] [G loss: -0.010623]\n",
      "[Epoch 121/200] [Batch 14/44] [D loss: 0.006245] [G loss: -0.010604]\n",
      "[Epoch 121/200] [Batch 16/44] [D loss: 0.005696] [G loss: -0.010622]\n",
      "[Epoch 121/200] [Batch 18/44] [D loss: 0.006346] [G loss: -0.010598]\n",
      "[Epoch 121/200] [Batch 20/44] [D loss: 0.002792] [G loss: -0.010648]\n",
      "[Epoch 121/200] [Batch 22/44] [D loss: 0.006137] [G loss: -0.010622]\n",
      "[Epoch 121/200] [Batch 24/44] [D loss: 0.006246] [G loss: -0.010620]\n",
      "[Epoch 121/200] [Batch 26/44] [D loss: 0.007107] [G loss: -0.010633]\n",
      "[Epoch 121/200] [Batch 28/44] [D loss: 0.004497] [G loss: -0.010624]\n",
      "[Epoch 121/200] [Batch 30/44] [D loss: 0.005866] [G loss: -0.010616]\n",
      "[Epoch 121/200] [Batch 32/44] [D loss: 0.005819] [G loss: -0.010628]\n",
      "[Epoch 121/200] [Batch 34/44] [D loss: 0.005665] [G loss: -0.010604]\n",
      "[Epoch 121/200] [Batch 36/44] [D loss: 0.006325] [G loss: -0.010622]\n",
      "[Epoch 121/200] [Batch 38/44] [D loss: 0.006455] [G loss: -0.010598]\n",
      "[Epoch 121/200] [Batch 40/44] [D loss: 0.006439] [G loss: -0.010615]\n",
      "[Epoch 121/200] [Batch 42/44] [D loss: 0.006082] [G loss: -0.010627]\n",
      "[Epoch 122/200] [Batch 0/44] [D loss: 0.004893] [G loss: -0.010643]\n",
      "[Epoch 122/200] [Batch 2/44] [D loss: 0.004963] [G loss: -0.010622]\n",
      "[Epoch 122/200] [Batch 4/44] [D loss: 0.005869] [G loss: -0.010618]\n",
      "[Epoch 122/200] [Batch 6/44] [D loss: 0.002797] [G loss: -0.010589]\n",
      "[Epoch 122/200] [Batch 8/44] [D loss: 0.005767] [G loss: -0.010611]\n",
      "[Epoch 122/200] [Batch 10/44] [D loss: 0.005577] [G loss: -0.010619]\n",
      "[Epoch 122/200] [Batch 12/44] [D loss: 0.006044] [G loss: -0.010614]\n",
      "[Epoch 122/200] [Batch 14/44] [D loss: 0.005630] [G loss: -0.010600]\n",
      "[Epoch 122/200] [Batch 16/44] [D loss: 0.005505] [G loss: -0.010634]\n",
      "[Epoch 122/200] [Batch 18/44] [D loss: 0.005226] [G loss: -0.010626]\n",
      "[Epoch 122/200] [Batch 20/44] [D loss: 0.006607] [G loss: -0.010639]\n",
      "[Epoch 122/200] [Batch 22/44] [D loss: 0.004850] [G loss: -0.010606]\n",
      "[Epoch 122/200] [Batch 24/44] [D loss: 0.005215] [G loss: -0.010617]\n",
      "[Epoch 122/200] [Batch 26/44] [D loss: 0.006026] [G loss: -0.010635]\n",
      "[Epoch 122/200] [Batch 28/44] [D loss: 0.005455] [G loss: -0.010623]\n",
      "[Epoch 122/200] [Batch 30/44] [D loss: 0.006225] [G loss: -0.010615]\n",
      "[Epoch 122/200] [Batch 32/44] [D loss: 0.006633] [G loss: -0.010635]\n",
      "[Epoch 122/200] [Batch 34/44] [D loss: 0.005851] [G loss: -0.010608]\n",
      "[Epoch 122/200] [Batch 36/44] [D loss: 0.006985] [G loss: -0.010624]\n",
      "[Epoch 122/200] [Batch 38/44] [D loss: 0.005685] [G loss: -0.010613]\n",
      "[Epoch 122/200] [Batch 40/44] [D loss: 0.004942] [G loss: -0.010623]\n",
      "[Epoch 122/200] [Batch 42/44] [D loss: 0.004475] [G loss: -0.010621]\n",
      "[Epoch 123/200] [Batch 0/44] [D loss: 0.006804] [G loss: -0.010608]\n",
      "[Epoch 123/200] [Batch 2/44] [D loss: 0.005324] [G loss: -0.010620]\n",
      "[Epoch 123/200] [Batch 4/44] [D loss: 0.005912] [G loss: -0.010636]\n",
      "[Epoch 123/200] [Batch 6/44] [D loss: 0.002746] [G loss: -0.010624]\n",
      "[Epoch 123/200] [Batch 8/44] [D loss: 0.005019] [G loss: -0.010609]\n",
      "[Epoch 123/200] [Batch 10/44] [D loss: 0.007799] [G loss: -0.010631]\n",
      "[Epoch 123/200] [Batch 12/44] [D loss: 0.005291] [G loss: -0.010605]\n",
      "[Epoch 123/200] [Batch 14/44] [D loss: 0.005535] [G loss: -0.010625]\n",
      "[Epoch 123/200] [Batch 16/44] [D loss: 0.005200] [G loss: -0.010614]\n",
      "[Epoch 123/200] [Batch 18/44] [D loss: 0.005128] [G loss: -0.010611]\n",
      "[Epoch 123/200] [Batch 20/44] [D loss: 0.006792] [G loss: -0.010612]\n",
      "[Epoch 123/200] [Batch 22/44] [D loss: 0.004290] [G loss: -0.010622]\n",
      "[Epoch 123/200] [Batch 24/44] [D loss: 0.005067] [G loss: -0.010618]\n",
      "[Epoch 123/200] [Batch 26/44] [D loss: 0.008053] [G loss: -0.010609]\n",
      "[Epoch 123/200] [Batch 28/44] [D loss: 0.003906] [G loss: -0.010633]\n",
      "[Epoch 123/200] [Batch 30/44] [D loss: 0.004366] [G loss: -0.010615]\n",
      "[Epoch 123/200] [Batch 32/44] [D loss: 0.005352] [G loss: -0.010598]\n",
      "[Epoch 123/200] [Batch 34/44] [D loss: 0.005038] [G loss: -0.010623]\n",
      "[Epoch 123/200] [Batch 36/44] [D loss: 0.004708] [G loss: -0.010633]\n",
      "[Epoch 123/200] [Batch 38/44] [D loss: 0.005447] [G loss: -0.010625]\n",
      "[Epoch 123/200] [Batch 40/44] [D loss: 0.004555] [G loss: -0.010615]\n",
      "[Epoch 123/200] [Batch 42/44] [D loss: 0.004761] [G loss: -0.010622]\n",
      "[Epoch 124/200] [Batch 0/44] [D loss: 0.004631] [G loss: -0.010620]\n",
      "[Epoch 124/200] [Batch 2/44] [D loss: 0.007262] [G loss: -0.010628]\n",
      "[Epoch 124/200] [Batch 4/44] [D loss: 0.004979] [G loss: -0.010624]\n",
      "[Epoch 124/200] [Batch 6/44] [D loss: 0.007071] [G loss: -0.010613]\n",
      "[Epoch 124/200] [Batch 8/44] [D loss: 0.004916] [G loss: -0.010626]\n",
      "[Epoch 124/200] [Batch 10/44] [D loss: 0.005242] [G loss: -0.010614]\n",
      "[Epoch 124/200] [Batch 12/44] [D loss: 0.003418] [G loss: -0.010624]\n",
      "[Epoch 124/200] [Batch 14/44] [D loss: 0.007061] [G loss: -0.010608]\n",
      "[Epoch 124/200] [Batch 16/44] [D loss: 0.004842] [G loss: -0.010620]\n",
      "[Epoch 124/200] [Batch 18/44] [D loss: 0.007627] [G loss: -0.010618]\n",
      "[Epoch 124/200] [Batch 20/44] [D loss: 0.006776] [G loss: -0.010601]\n",
      "[Epoch 124/200] [Batch 22/44] [D loss: 0.004434] [G loss: -0.010627]\n",
      "[Epoch 124/200] [Batch 24/44] [D loss: 0.006251] [G loss: -0.010621]\n",
      "[Epoch 124/200] [Batch 26/44] [D loss: 0.005536] [G loss: -0.010644]\n",
      "[Epoch 124/200] [Batch 28/44] [D loss: 0.005477] [G loss: -0.010590]\n",
      "[Epoch 124/200] [Batch 30/44] [D loss: 0.005373] [G loss: -0.010620]\n",
      "[Epoch 124/200] [Batch 32/44] [D loss: 0.005470] [G loss: -0.010609]\n",
      "[Epoch 124/200] [Batch 34/44] [D loss: 0.005158] [G loss: -0.010635]\n",
      "[Epoch 124/200] [Batch 36/44] [D loss: 0.004985] [G loss: -0.010598]\n",
      "[Epoch 124/200] [Batch 38/44] [D loss: 0.007074] [G loss: -0.010621]\n",
      "[Epoch 124/200] [Batch 40/44] [D loss: 0.005802] [G loss: -0.010593]\n",
      "[Epoch 124/200] [Batch 42/44] [D loss: 0.004234] [G loss: -0.010606]\n",
      "[Epoch 125/200] [Batch 0/44] [D loss: 0.007088] [G loss: -0.010635]\n",
      "[Epoch 125/200] [Batch 2/44] [D loss: 0.004539] [G loss: -0.010624]\n",
      "[Epoch 125/200] [Batch 4/44] [D loss: 0.006477] [G loss: -0.010604]\n",
      "[Epoch 125/200] [Batch 6/44] [D loss: 0.006610] [G loss: -0.010631]\n",
      "[Epoch 125/200] [Batch 8/44] [D loss: 0.006267] [G loss: -0.010640]\n",
      "[Epoch 125/200] [Batch 10/44] [D loss: 0.006469] [G loss: -0.010610]\n",
      "[Epoch 125/200] [Batch 12/44] [D loss: 0.006535] [G loss: -0.010612]\n",
      "[Epoch 125/200] [Batch 14/44] [D loss: 0.003970] [G loss: -0.010633]\n",
      "[Epoch 125/200] [Batch 16/44] [D loss: 0.003270] [G loss: -0.010618]\n",
      "[Epoch 125/200] [Batch 18/44] [D loss: 0.006246] [G loss: -0.010628]\n",
      "[Epoch 125/200] [Batch 20/44] [D loss: 0.005755] [G loss: -0.010621]\n",
      "[Epoch 125/200] [Batch 22/44] [D loss: 0.004415] [G loss: -0.010625]\n",
      "[Epoch 125/200] [Batch 24/44] [D loss: 0.005995] [G loss: -0.010625]\n",
      "[Epoch 125/200] [Batch 26/44] [D loss: 0.005831] [G loss: -0.010620]\n",
      "[Epoch 125/200] [Batch 28/44] [D loss: 0.003027] [G loss: -0.010585]\n",
      "[Epoch 125/200] [Batch 30/44] [D loss: 0.004046] [G loss: -0.010620]\n",
      "[Epoch 125/200] [Batch 32/44] [D loss: 0.008999] [G loss: -0.010616]\n",
      "[Epoch 125/200] [Batch 34/44] [D loss: 0.005435] [G loss: -0.010614]\n",
      "[Epoch 125/200] [Batch 36/44] [D loss: 0.005411] [G loss: -0.010609]\n",
      "[Epoch 125/200] [Batch 38/44] [D loss: 0.006021] [G loss: -0.010625]\n",
      "[Epoch 125/200] [Batch 40/44] [D loss: 0.006474] [G loss: -0.010611]\n",
      "[Epoch 125/200] [Batch 42/44] [D loss: 0.004816] [G loss: -0.010613]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 126/200] [Batch 0/44] [D loss: 0.003127] [G loss: -0.010616]\n",
      "[Epoch 126/200] [Batch 2/44] [D loss: 0.008079] [G loss: -0.010632]\n",
      "[Epoch 126/200] [Batch 4/44] [D loss: 0.005489] [G loss: -0.010607]\n",
      "[Epoch 126/200] [Batch 6/44] [D loss: 0.005586] [G loss: -0.010600]\n",
      "[Epoch 126/200] [Batch 8/44] [D loss: 0.005916] [G loss: -0.010594]\n",
      "[Epoch 126/200] [Batch 10/44] [D loss: 0.006834] [G loss: -0.010616]\n",
      "[Epoch 126/200] [Batch 12/44] [D loss: 0.005884] [G loss: -0.010620]\n",
      "[Epoch 126/200] [Batch 14/44] [D loss: 0.002781] [G loss: -0.010630]\n",
      "[Epoch 126/200] [Batch 16/44] [D loss: 0.004529] [G loss: -0.010623]\n",
      "[Epoch 126/200] [Batch 18/44] [D loss: 0.006473] [G loss: -0.010636]\n",
      "[Epoch 126/200] [Batch 20/44] [D loss: 0.005643] [G loss: -0.010610]\n",
      "[Epoch 126/200] [Batch 22/44] [D loss: 0.005696] [G loss: -0.010621]\n",
      "[Epoch 126/200] [Batch 24/44] [D loss: 0.004229] [G loss: -0.010605]\n",
      "[Epoch 126/200] [Batch 26/44] [D loss: 0.006230] [G loss: -0.010645]\n",
      "[Epoch 126/200] [Batch 28/44] [D loss: 0.004080] [G loss: -0.010618]\n",
      "[Epoch 126/200] [Batch 30/44] [D loss: 0.007061] [G loss: -0.010624]\n",
      "[Epoch 126/200] [Batch 32/44] [D loss: 0.005977] [G loss: -0.010612]\n",
      "[Epoch 126/200] [Batch 34/44] [D loss: 0.007238] [G loss: -0.010596]\n",
      "[Epoch 126/200] [Batch 36/44] [D loss: 0.004790] [G loss: -0.010608]\n",
      "[Epoch 126/200] [Batch 38/44] [D loss: 0.004478] [G loss: -0.010621]\n",
      "[Epoch 126/200] [Batch 40/44] [D loss: 0.004717] [G loss: -0.010633]\n",
      "[Epoch 126/200] [Batch 42/44] [D loss: 0.006723] [G loss: -0.010608]\n",
      "[Epoch 127/200] [Batch 0/44] [D loss: 0.006116] [G loss: -0.010617]\n",
      "[Epoch 127/200] [Batch 2/44] [D loss: 0.006002] [G loss: -0.010606]\n",
      "[Epoch 127/200] [Batch 4/44] [D loss: 0.006114] [G loss: -0.010602]\n",
      "[Epoch 127/200] [Batch 6/44] [D loss: 0.005160] [G loss: -0.010622]\n",
      "[Epoch 127/200] [Batch 8/44] [D loss: 0.007057] [G loss: -0.010621]\n",
      "[Epoch 127/200] [Batch 10/44] [D loss: 0.005537] [G loss: -0.010597]\n",
      "[Epoch 127/200] [Batch 12/44] [D loss: 0.004136] [G loss: -0.010599]\n",
      "[Epoch 127/200] [Batch 14/44] [D loss: 0.006447] [G loss: -0.010622]\n",
      "[Epoch 127/200] [Batch 16/44] [D loss: 0.004509] [G loss: -0.010626]\n",
      "[Epoch 127/200] [Batch 18/44] [D loss: 0.006987] [G loss: -0.010627]\n",
      "[Epoch 127/200] [Batch 20/44] [D loss: 0.006104] [G loss: -0.010618]\n",
      "[Epoch 127/200] [Batch 22/44] [D loss: 0.005858] [G loss: -0.010622]\n",
      "[Epoch 127/200] [Batch 24/44] [D loss: 0.004850] [G loss: -0.010598]\n",
      "[Epoch 127/200] [Batch 26/44] [D loss: 0.006081] [G loss: -0.010622]\n",
      "[Epoch 127/200] [Batch 28/44] [D loss: 0.006363] [G loss: -0.010626]\n",
      "[Epoch 127/200] [Batch 30/44] [D loss: 0.005491] [G loss: -0.010608]\n",
      "[Epoch 127/200] [Batch 32/44] [D loss: 0.004390] [G loss: -0.010630]\n",
      "[Epoch 127/200] [Batch 34/44] [D loss: 0.005480] [G loss: -0.010621]\n",
      "[Epoch 127/200] [Batch 36/44] [D loss: 0.005412] [G loss: -0.010632]\n",
      "[Epoch 127/200] [Batch 38/44] [D loss: 0.006474] [G loss: -0.010623]\n",
      "[Epoch 127/200] [Batch 40/44] [D loss: 0.006331] [G loss: -0.010629]\n",
      "[Epoch 127/200] [Batch 42/44] [D loss: 0.005201] [G loss: -0.010609]\n",
      "[Epoch 128/200] [Batch 0/44] [D loss: 0.004158] [G loss: -0.010595]\n",
      "[Epoch 128/200] [Batch 2/44] [D loss: 0.004888] [G loss: -0.010626]\n",
      "[Epoch 128/200] [Batch 4/44] [D loss: 0.006394] [G loss: -0.010620]\n",
      "[Epoch 128/200] [Batch 6/44] [D loss: 0.005506] [G loss: -0.010603]\n",
      "[Epoch 128/200] [Batch 8/44] [D loss: 0.006443] [G loss: -0.010620]\n",
      "[Epoch 128/200] [Batch 10/44] [D loss: 0.006014] [G loss: -0.010627]\n",
      "[Epoch 128/200] [Batch 12/44] [D loss: 0.004909] [G loss: -0.010625]\n",
      "[Epoch 128/200] [Batch 14/44] [D loss: 0.006082] [G loss: -0.010615]\n",
      "[Epoch 128/200] [Batch 16/44] [D loss: 0.004957] [G loss: -0.010600]\n",
      "[Epoch 128/200] [Batch 18/44] [D loss: 0.004406] [G loss: -0.010616]\n",
      "[Epoch 128/200] [Batch 20/44] [D loss: 0.006464] [G loss: -0.010608]\n",
      "[Epoch 128/200] [Batch 22/44] [D loss: 0.006963] [G loss: -0.010618]\n",
      "[Epoch 128/200] [Batch 24/44] [D loss: 0.006632] [G loss: -0.010623]\n",
      "[Epoch 128/200] [Batch 26/44] [D loss: 0.006362] [G loss: -0.010647]\n",
      "[Epoch 128/200] [Batch 28/44] [D loss: 0.006438] [G loss: -0.010601]\n",
      "[Epoch 128/200] [Batch 30/44] [D loss: 0.006346] [G loss: -0.010630]\n",
      "[Epoch 128/200] [Batch 32/44] [D loss: 0.005324] [G loss: -0.010592]\n",
      "[Epoch 128/200] [Batch 34/44] [D loss: 0.004490] [G loss: -0.010611]\n",
      "[Epoch 128/200] [Batch 36/44] [D loss: 0.005548] [G loss: -0.010607]\n",
      "[Epoch 128/200] [Batch 38/44] [D loss: 0.004382] [G loss: -0.010596]\n",
      "[Epoch 128/200] [Batch 40/44] [D loss: 0.004564] [G loss: -0.010613]\n",
      "[Epoch 128/200] [Batch 42/44] [D loss: 0.005931] [G loss: -0.010628]\n",
      "[Epoch 129/200] [Batch 0/44] [D loss: 0.007254] [G loss: -0.010614]\n",
      "[Epoch 129/200] [Batch 2/44] [D loss: 0.006255] [G loss: -0.010629]\n",
      "[Epoch 129/200] [Batch 4/44] [D loss: 0.004933] [G loss: -0.010626]\n",
      "[Epoch 129/200] [Batch 6/44] [D loss: 0.004990] [G loss: -0.010584]\n",
      "[Epoch 129/200] [Batch 8/44] [D loss: 0.005710] [G loss: -0.010581]\n",
      "[Epoch 129/200] [Batch 10/44] [D loss: 0.006041] [G loss: -0.010618]\n",
      "[Epoch 129/200] [Batch 12/44] [D loss: 0.004474] [G loss: -0.010633]\n",
      "[Epoch 129/200] [Batch 14/44] [D loss: 0.005755] [G loss: -0.010625]\n",
      "[Epoch 129/200] [Batch 16/44] [D loss: 0.007236] [G loss: -0.010587]\n",
      "[Epoch 129/200] [Batch 18/44] [D loss: 0.005391] [G loss: -0.010629]\n",
      "[Epoch 129/200] [Batch 20/44] [D loss: 0.004560] [G loss: -0.010613]\n",
      "[Epoch 129/200] [Batch 22/44] [D loss: 0.005484] [G loss: -0.010610]\n",
      "[Epoch 129/200] [Batch 24/44] [D loss: 0.006912] [G loss: -0.010624]\n",
      "[Epoch 129/200] [Batch 26/44] [D loss: 0.005914] [G loss: -0.010604]\n",
      "[Epoch 129/200] [Batch 28/44] [D loss: 0.005491] [G loss: -0.010625]\n",
      "[Epoch 129/200] [Batch 30/44] [D loss: 0.004691] [G loss: -0.010632]\n",
      "[Epoch 129/200] [Batch 32/44] [D loss: 0.004855] [G loss: -0.010638]\n",
      "[Epoch 129/200] [Batch 34/44] [D loss: 0.005060] [G loss: -0.010630]\n",
      "[Epoch 129/200] [Batch 36/44] [D loss: 0.005438] [G loss: -0.010633]\n",
      "[Epoch 129/200] [Batch 38/44] [D loss: 0.005295] [G loss: -0.010602]\n",
      "[Epoch 129/200] [Batch 40/44] [D loss: 0.006219] [G loss: -0.010600]\n",
      "[Epoch 129/200] [Batch 42/44] [D loss: 0.005707] [G loss: -0.010610]\n",
      "[Epoch 130/200] [Batch 0/44] [D loss: 0.005663] [G loss: -0.010587]\n",
      "[Epoch 130/200] [Batch 2/44] [D loss: 0.007396] [G loss: -0.010618]\n",
      "[Epoch 130/200] [Batch 4/44] [D loss: 0.006817] [G loss: -0.010622]\n",
      "[Epoch 130/200] [Batch 6/44] [D loss: 0.005789] [G loss: -0.010599]\n",
      "[Epoch 130/200] [Batch 8/44] [D loss: 0.006063] [G loss: -0.010618]\n",
      "[Epoch 130/200] [Batch 10/44] [D loss: 0.007293] [G loss: -0.010594]\n",
      "[Epoch 130/200] [Batch 12/44] [D loss: 0.005547] [G loss: -0.010619]\n",
      "[Epoch 130/200] [Batch 14/44] [D loss: 0.005301] [G loss: -0.010620]\n",
      "[Epoch 130/200] [Batch 16/44] [D loss: 0.005468] [G loss: -0.010592]\n",
      "[Epoch 130/200] [Batch 18/44] [D loss: 0.006000] [G loss: -0.010607]\n",
      "[Epoch 130/200] [Batch 20/44] [D loss: 0.006296] [G loss: -0.010615]\n",
      "[Epoch 130/200] [Batch 22/44] [D loss: 0.005349] [G loss: -0.010622]\n",
      "[Epoch 130/200] [Batch 24/44] [D loss: 0.002945] [G loss: -0.010614]\n",
      "[Epoch 130/200] [Batch 26/44] [D loss: 0.007445] [G loss: -0.010645]\n",
      "[Epoch 130/200] [Batch 28/44] [D loss: 0.004964] [G loss: -0.010626]\n",
      "[Epoch 130/200] [Batch 30/44] [D loss: 0.004625] [G loss: -0.010623]\n",
      "[Epoch 130/200] [Batch 32/44] [D loss: 0.003024] [G loss: -0.010608]\n",
      "[Epoch 130/200] [Batch 34/44] [D loss: 0.005482] [G loss: -0.010620]\n",
      "[Epoch 130/200] [Batch 36/44] [D loss: 0.006020] [G loss: -0.010613]\n",
      "[Epoch 130/200] [Batch 38/44] [D loss: 0.006239] [G loss: -0.010639]\n",
      "[Epoch 130/200] [Batch 40/44] [D loss: 0.004805] [G loss: -0.010627]\n",
      "[Epoch 130/200] [Batch 42/44] [D loss: 0.005288] [G loss: -0.010604]\n",
      "[Epoch 131/200] [Batch 0/44] [D loss: 0.006445] [G loss: -0.010616]\n",
      "[Epoch 131/200] [Batch 2/44] [D loss: 0.006154] [G loss: -0.010617]\n",
      "[Epoch 131/200] [Batch 4/44] [D loss: 0.005170] [G loss: -0.010629]\n",
      "[Epoch 131/200] [Batch 6/44] [D loss: 0.006851] [G loss: -0.010653]\n",
      "[Epoch 131/200] [Batch 8/44] [D loss: 0.006551] [G loss: -0.010601]\n",
      "[Epoch 131/200] [Batch 10/44] [D loss: 0.005542] [G loss: -0.010633]\n",
      "[Epoch 131/200] [Batch 12/44] [D loss: 0.006026] [G loss: -0.010626]\n",
      "[Epoch 131/200] [Batch 14/44] [D loss: 0.002786] [G loss: -0.010623]\n",
      "[Epoch 131/200] [Batch 16/44] [D loss: 0.005519] [G loss: -0.010595]\n",
      "[Epoch 131/200] [Batch 18/44] [D loss: 0.007185] [G loss: -0.010600]\n",
      "[Epoch 131/200] [Batch 20/44] [D loss: 0.006484] [G loss: -0.010607]\n",
      "[Epoch 131/200] [Batch 22/44] [D loss: 0.005306] [G loss: -0.010621]\n",
      "[Epoch 131/200] [Batch 24/44] [D loss: 0.006480] [G loss: -0.010616]\n",
      "[Epoch 131/200] [Batch 26/44] [D loss: 0.006124] [G loss: -0.010610]\n",
      "[Epoch 131/200] [Batch 28/44] [D loss: 0.004719] [G loss: -0.010585]\n",
      "[Epoch 131/200] [Batch 30/44] [D loss: 0.004868] [G loss: -0.010630]\n",
      "[Epoch 131/200] [Batch 32/44] [D loss: 0.005223] [G loss: -0.010632]\n",
      "[Epoch 131/200] [Batch 34/44] [D loss: 0.005701] [G loss: -0.010606]\n",
      "[Epoch 131/200] [Batch 36/44] [D loss: 0.005751] [G loss: -0.010633]\n",
      "[Epoch 131/200] [Batch 38/44] [D loss: 0.005437] [G loss: -0.010635]\n",
      "[Epoch 131/200] [Batch 40/44] [D loss: 0.005645] [G loss: -0.010588]\n",
      "[Epoch 131/200] [Batch 42/44] [D loss: 0.003773] [G loss: -0.010614]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 132/200] [Batch 0/44] [D loss: 0.005592] [G loss: -0.010630]\n",
      "[Epoch 132/200] [Batch 2/44] [D loss: 0.004709] [G loss: -0.010635]\n",
      "[Epoch 132/200] [Batch 4/44] [D loss: 0.006321] [G loss: -0.010626]\n",
      "[Epoch 132/200] [Batch 6/44] [D loss: 0.006177] [G loss: -0.010603]\n",
      "[Epoch 132/200] [Batch 8/44] [D loss: 0.005700] [G loss: -0.010634]\n",
      "[Epoch 132/200] [Batch 10/44] [D loss: 0.006763] [G loss: -0.010614]\n",
      "[Epoch 132/200] [Batch 12/44] [D loss: 0.003608] [G loss: -0.010614]\n",
      "[Epoch 132/200] [Batch 14/44] [D loss: 0.005002] [G loss: -0.010607]\n",
      "[Epoch 132/200] [Batch 16/44] [D loss: 0.005064] [G loss: -0.010623]\n",
      "[Epoch 132/200] [Batch 18/44] [D loss: 0.004543] [G loss: -0.010622]\n",
      "[Epoch 132/200] [Batch 20/44] [D loss: 0.006897] [G loss: -0.010632]\n",
      "[Epoch 132/200] [Batch 22/44] [D loss: 0.005241] [G loss: -0.010605]\n",
      "[Epoch 132/200] [Batch 24/44] [D loss: 0.006347] [G loss: -0.010644]\n",
      "[Epoch 132/200] [Batch 26/44] [D loss: 0.005458] [G loss: -0.010616]\n",
      "[Epoch 132/200] [Batch 28/44] [D loss: 0.007864] [G loss: -0.010604]\n",
      "[Epoch 132/200] [Batch 30/44] [D loss: 0.004806] [G loss: -0.010617]\n",
      "[Epoch 132/200] [Batch 32/44] [D loss: 0.005995] [G loss: -0.010608]\n",
      "[Epoch 132/200] [Batch 34/44] [D loss: 0.005276] [G loss: -0.010624]\n",
      "[Epoch 132/200] [Batch 36/44] [D loss: 0.004379] [G loss: -0.010607]\n",
      "[Epoch 132/200] [Batch 38/44] [D loss: 0.005915] [G loss: -0.010605]\n",
      "[Epoch 132/200] [Batch 40/44] [D loss: 0.007490] [G loss: -0.010632]\n",
      "[Epoch 132/200] [Batch 42/44] [D loss: 0.005164] [G loss: -0.010614]\n",
      "[Epoch 133/200] [Batch 0/44] [D loss: 0.004927] [G loss: -0.010607]\n",
      "[Epoch 133/200] [Batch 2/44] [D loss: 0.008410] [G loss: -0.010619]\n",
      "[Epoch 133/200] [Batch 4/44] [D loss: 0.005269] [G loss: -0.010620]\n",
      "[Epoch 133/200] [Batch 6/44] [D loss: 0.005501] [G loss: -0.010588]\n",
      "[Epoch 133/200] [Batch 8/44] [D loss: 0.004781] [G loss: -0.010638]\n",
      "[Epoch 133/200] [Batch 10/44] [D loss: 0.006362] [G loss: -0.010599]\n",
      "[Epoch 133/200] [Batch 12/44] [D loss: 0.005700] [G loss: -0.010601]\n",
      "[Epoch 133/200] [Batch 14/44] [D loss: 0.006467] [G loss: -0.010615]\n",
      "[Epoch 133/200] [Batch 16/44] [D loss: 0.004256] [G loss: -0.010616]\n",
      "[Epoch 133/200] [Batch 18/44] [D loss: 0.005693] [G loss: -0.010589]\n",
      "[Epoch 133/200] [Batch 20/44] [D loss: 0.006628] [G loss: -0.010614]\n",
      "[Epoch 133/200] [Batch 22/44] [D loss: 0.006486] [G loss: -0.010614]\n",
      "[Epoch 133/200] [Batch 24/44] [D loss: 0.004958] [G loss: -0.010622]\n",
      "[Epoch 133/200] [Batch 26/44] [D loss: 0.005963] [G loss: -0.010634]\n",
      "[Epoch 133/200] [Batch 28/44] [D loss: 0.005318] [G loss: -0.010605]\n",
      "[Epoch 133/200] [Batch 30/44] [D loss: 0.004555] [G loss: -0.010616]\n",
      "[Epoch 133/200] [Batch 32/44] [D loss: 0.004885] [G loss: -0.010637]\n",
      "[Epoch 133/200] [Batch 34/44] [D loss: 0.008106] [G loss: -0.010612]\n",
      "[Epoch 133/200] [Batch 36/44] [D loss: 0.004883] [G loss: -0.010621]\n",
      "[Epoch 133/200] [Batch 38/44] [D loss: 0.005331] [G loss: -0.010634]\n",
      "[Epoch 133/200] [Batch 40/44] [D loss: 0.006653] [G loss: -0.010624]\n",
      "[Epoch 133/200] [Batch 42/44] [D loss: 0.006677] [G loss: -0.010628]\n",
      "[Epoch 134/200] [Batch 0/44] [D loss: 0.006639] [G loss: -0.010628]\n",
      "[Epoch 134/200] [Batch 2/44] [D loss: 0.005443] [G loss: -0.010622]\n",
      "[Epoch 134/200] [Batch 4/44] [D loss: 0.006484] [G loss: -0.010655]\n",
      "[Epoch 134/200] [Batch 6/44] [D loss: 0.006352] [G loss: -0.010641]\n",
      "[Epoch 134/200] [Batch 8/44] [D loss: 0.004381] [G loss: -0.010613]\n",
      "[Epoch 134/200] [Batch 10/44] [D loss: 0.006081] [G loss: -0.010600]\n",
      "[Epoch 134/200] [Batch 12/44] [D loss: 0.005735] [G loss: -0.010614]\n",
      "[Epoch 134/200] [Batch 14/44] [D loss: 0.006030] [G loss: -0.010613]\n",
      "[Epoch 134/200] [Batch 16/44] [D loss: 0.006613] [G loss: -0.010613]\n",
      "[Epoch 134/200] [Batch 18/44] [D loss: 0.005277] [G loss: -0.010607]\n",
      "[Epoch 134/200] [Batch 20/44] [D loss: 0.007837] [G loss: -0.010617]\n",
      "[Epoch 134/200] [Batch 22/44] [D loss: 0.005867] [G loss: -0.010629]\n",
      "[Epoch 134/200] [Batch 24/44] [D loss: 0.004132] [G loss: -0.010608]\n",
      "[Epoch 134/200] [Batch 26/44] [D loss: 0.005649] [G loss: -0.010601]\n",
      "[Epoch 134/200] [Batch 28/44] [D loss: 0.004644] [G loss: -0.010627]\n",
      "[Epoch 134/200] [Batch 30/44] [D loss: 0.006598] [G loss: -0.010603]\n",
      "[Epoch 134/200] [Batch 32/44] [D loss: 0.003981] [G loss: -0.010615]\n",
      "[Epoch 134/200] [Batch 34/44] [D loss: 0.005913] [G loss: -0.010627]\n",
      "[Epoch 134/200] [Batch 36/44] [D loss: 0.003856] [G loss: -0.010582]\n",
      "[Epoch 134/200] [Batch 38/44] [D loss: 0.005302] [G loss: -0.010622]\n",
      "[Epoch 134/200] [Batch 40/44] [D loss: 0.006309] [G loss: -0.010586]\n",
      "[Epoch 134/200] [Batch 42/44] [D loss: 0.006726] [G loss: -0.010605]\n",
      "[Epoch 135/200] [Batch 0/44] [D loss: 0.003950] [G loss: -0.010631]\n",
      "[Epoch 135/200] [Batch 2/44] [D loss: 0.005992] [G loss: -0.010596]\n",
      "[Epoch 135/200] [Batch 4/44] [D loss: 0.005611] [G loss: -0.010617]\n",
      "[Epoch 135/200] [Batch 6/44] [D loss: 0.006540] [G loss: -0.010621]\n",
      "[Epoch 135/200] [Batch 8/44] [D loss: 0.006968] [G loss: -0.010610]\n",
      "[Epoch 135/200] [Batch 10/44] [D loss: 0.005226] [G loss: -0.010628]\n",
      "[Epoch 135/200] [Batch 12/44] [D loss: 0.004593] [G loss: -0.010615]\n",
      "[Epoch 135/200] [Batch 14/44] [D loss: 0.005615] [G loss: -0.010609]\n",
      "[Epoch 135/200] [Batch 16/44] [D loss: 0.004775] [G loss: -0.010618]\n",
      "[Epoch 135/200] [Batch 18/44] [D loss: 0.006401] [G loss: -0.010606]\n",
      "[Epoch 135/200] [Batch 20/44] [D loss: 0.006646] [G loss: -0.010622]\n",
      "[Epoch 135/200] [Batch 22/44] [D loss: 0.006886] [G loss: -0.010611]\n",
      "[Epoch 135/200] [Batch 24/44] [D loss: 0.004621] [G loss: -0.010607]\n",
      "[Epoch 135/200] [Batch 26/44] [D loss: 0.005889] [G loss: -0.010631]\n",
      "[Epoch 135/200] [Batch 28/44] [D loss: 0.003753] [G loss: -0.010611]\n",
      "[Epoch 135/200] [Batch 30/44] [D loss: 0.004309] [G loss: -0.010608]\n",
      "[Epoch 135/200] [Batch 32/44] [D loss: 0.004989] [G loss: -0.010641]\n",
      "[Epoch 135/200] [Batch 34/44] [D loss: 0.006900] [G loss: -0.010650]\n",
      "[Epoch 135/200] [Batch 36/44] [D loss: 0.005346] [G loss: -0.010599]\n",
      "[Epoch 135/200] [Batch 38/44] [D loss: 0.005890] [G loss: -0.010637]\n",
      "[Epoch 135/200] [Batch 40/44] [D loss: 0.005429] [G loss: -0.010618]\n",
      "[Epoch 135/200] [Batch 42/44] [D loss: 0.007482] [G loss: -0.010603]\n",
      "[Epoch 136/200] [Batch 0/44] [D loss: 0.005577] [G loss: -0.010598]\n",
      "[Epoch 136/200] [Batch 2/44] [D loss: 0.007484] [G loss: -0.010637]\n",
      "[Epoch 136/200] [Batch 4/44] [D loss: 0.005300] [G loss: -0.010609]\n",
      "[Epoch 136/200] [Batch 6/44] [D loss: 0.006219] [G loss: -0.010629]\n",
      "[Epoch 136/200] [Batch 8/44] [D loss: 0.006238] [G loss: -0.010622]\n",
      "[Epoch 136/200] [Batch 10/44] [D loss: 0.003561] [G loss: -0.010617]\n",
      "[Epoch 136/200] [Batch 12/44] [D loss: 0.005208] [G loss: -0.010614]\n",
      "[Epoch 136/200] [Batch 14/44] [D loss: 0.005688] [G loss: -0.010629]\n",
      "[Epoch 136/200] [Batch 16/44] [D loss: 0.004882] [G loss: -0.010621]\n",
      "[Epoch 136/200] [Batch 18/44] [D loss: 0.005305] [G loss: -0.010614]\n",
      "[Epoch 136/200] [Batch 20/44] [D loss: 0.004306] [G loss: -0.010607]\n",
      "[Epoch 136/200] [Batch 22/44] [D loss: 0.005502] [G loss: -0.010619]\n",
      "[Epoch 136/200] [Batch 24/44] [D loss: 0.004207] [G loss: -0.010637]\n",
      "[Epoch 136/200] [Batch 26/44] [D loss: 0.005633] [G loss: -0.010617]\n",
      "[Epoch 136/200] [Batch 28/44] [D loss: 0.006308] [G loss: -0.010620]\n",
      "[Epoch 136/200] [Batch 30/44] [D loss: 0.005543] [G loss: -0.010623]\n",
      "[Epoch 136/200] [Batch 32/44] [D loss: 0.004855] [G loss: -0.010644]\n",
      "[Epoch 136/200] [Batch 34/44] [D loss: 0.005693] [G loss: -0.010623]\n",
      "[Epoch 136/200] [Batch 36/44] [D loss: 0.005347] [G loss: -0.010609]\n",
      "[Epoch 136/200] [Batch 38/44] [D loss: 0.008739] [G loss: -0.010630]\n",
      "[Epoch 136/200] [Batch 40/44] [D loss: 0.006298] [G loss: -0.010598]\n",
      "[Epoch 136/200] [Batch 42/44] [D loss: 0.005053] [G loss: -0.010624]\n",
      "[Epoch 137/200] [Batch 0/44] [D loss: 0.007975] [G loss: -0.010615]\n",
      "[Epoch 137/200] [Batch 2/44] [D loss: 0.005394] [G loss: -0.010621]\n",
      "[Epoch 137/200] [Batch 4/44] [D loss: 0.005139] [G loss: -0.010618]\n",
      "[Epoch 137/200] [Batch 6/44] [D loss: 0.003981] [G loss: -0.010631]\n",
      "[Epoch 137/200] [Batch 8/44] [D loss: 0.006177] [G loss: -0.010606]\n",
      "[Epoch 137/200] [Batch 10/44] [D loss: 0.004351] [G loss: -0.010638]\n",
      "[Epoch 137/200] [Batch 12/44] [D loss: 0.003466] [G loss: -0.010611]\n",
      "[Epoch 137/200] [Batch 14/44] [D loss: 0.006455] [G loss: -0.010597]\n",
      "[Epoch 137/200] [Batch 16/44] [D loss: 0.006921] [G loss: -0.010626]\n",
      "[Epoch 137/200] [Batch 18/44] [D loss: 0.007101] [G loss: -0.010616]\n",
      "[Epoch 137/200] [Batch 20/44] [D loss: 0.005170] [G loss: -0.010602]\n",
      "[Epoch 137/200] [Batch 22/44] [D loss: 0.006256] [G loss: -0.010616]\n",
      "[Epoch 137/200] [Batch 24/44] [D loss: 0.005641] [G loss: -0.010625]\n",
      "[Epoch 137/200] [Batch 26/44] [D loss: 0.005244] [G loss: -0.010592]\n",
      "[Epoch 137/200] [Batch 28/44] [D loss: 0.005926] [G loss: -0.010586]\n",
      "[Epoch 137/200] [Batch 30/44] [D loss: 0.005526] [G loss: -0.010646]\n",
      "[Epoch 137/200] [Batch 32/44] [D loss: 0.006562] [G loss: -0.010625]\n",
      "[Epoch 137/200] [Batch 34/44] [D loss: 0.006667] [G loss: -0.010614]\n",
      "[Epoch 137/200] [Batch 36/44] [D loss: 0.005720] [G loss: -0.010598]\n",
      "[Epoch 137/200] [Batch 38/44] [D loss: 0.007203] [G loss: -0.010638]\n",
      "[Epoch 137/200] [Batch 40/44] [D loss: 0.006108] [G loss: -0.010618]\n",
      "[Epoch 137/200] [Batch 42/44] [D loss: 0.004945] [G loss: -0.010625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 138/200] [Batch 0/44] [D loss: 0.004512] [G loss: -0.010606]\n",
      "[Epoch 138/200] [Batch 2/44] [D loss: 0.004365] [G loss: -0.010596]\n",
      "[Epoch 138/200] [Batch 4/44] [D loss: 0.005122] [G loss: -0.010630]\n",
      "[Epoch 138/200] [Batch 6/44] [D loss: 0.004125] [G loss: -0.010635]\n",
      "[Epoch 138/200] [Batch 8/44] [D loss: 0.004129] [G loss: -0.010609]\n",
      "[Epoch 138/200] [Batch 10/44] [D loss: 0.004828] [G loss: -0.010613]\n",
      "[Epoch 138/200] [Batch 12/44] [D loss: 0.004915] [G loss: -0.010625]\n",
      "[Epoch 138/200] [Batch 14/44] [D loss: 0.004800] [G loss: -0.010604]\n",
      "[Epoch 138/200] [Batch 16/44] [D loss: 0.005094] [G loss: -0.010617]\n",
      "[Epoch 138/200] [Batch 18/44] [D loss: 0.005428] [G loss: -0.010622]\n",
      "[Epoch 138/200] [Batch 20/44] [D loss: 0.002222] [G loss: -0.010605]\n",
      "[Epoch 138/200] [Batch 22/44] [D loss: 0.006512] [G loss: -0.010616]\n",
      "[Epoch 138/200] [Batch 24/44] [D loss: 0.005075] [G loss: -0.010607]\n",
      "[Epoch 138/200] [Batch 26/44] [D loss: 0.006197] [G loss: -0.010640]\n",
      "[Epoch 138/200] [Batch 28/44] [D loss: 0.005928] [G loss: -0.010629]\n",
      "[Epoch 138/200] [Batch 30/44] [D loss: 0.006235] [G loss: -0.010606]\n",
      "[Epoch 138/200] [Batch 32/44] [D loss: 0.005693] [G loss: -0.010632]\n",
      "[Epoch 138/200] [Batch 34/44] [D loss: 0.007508] [G loss: -0.010613]\n",
      "[Epoch 138/200] [Batch 36/44] [D loss: 0.007032] [G loss: -0.010612]\n",
      "[Epoch 138/200] [Batch 38/44] [D loss: 0.005888] [G loss: -0.010618]\n",
      "[Epoch 138/200] [Batch 40/44] [D loss: 0.007280] [G loss: -0.010599]\n",
      "[Epoch 138/200] [Batch 42/44] [D loss: 0.006342] [G loss: -0.010625]\n",
      "[Epoch 139/200] [Batch 0/44] [D loss: 0.004539] [G loss: -0.010615]\n",
      "[Epoch 139/200] [Batch 2/44] [D loss: 0.005144] [G loss: -0.010617]\n",
      "[Epoch 139/200] [Batch 4/44] [D loss: 0.003619] [G loss: -0.010606]\n",
      "[Epoch 139/200] [Batch 6/44] [D loss: 0.006678] [G loss: -0.010606]\n",
      "[Epoch 139/200] [Batch 8/44] [D loss: 0.005482] [G loss: -0.010615]\n",
      "[Epoch 139/200] [Batch 10/44] [D loss: 0.006313] [G loss: -0.010604]\n",
      "[Epoch 139/200] [Batch 12/44] [D loss: 0.006932] [G loss: -0.010636]\n",
      "[Epoch 139/200] [Batch 14/44] [D loss: 0.005568] [G loss: -0.010623]\n",
      "[Epoch 139/200] [Batch 16/44] [D loss: 0.005615] [G loss: -0.010649]\n",
      "[Epoch 139/200] [Batch 18/44] [D loss: 0.004771] [G loss: -0.010622]\n",
      "[Epoch 139/200] [Batch 20/44] [D loss: 0.005872] [G loss: -0.010624]\n",
      "[Epoch 139/200] [Batch 22/44] [D loss: 0.002852] [G loss: -0.010618]\n",
      "[Epoch 139/200] [Batch 24/44] [D loss: 0.006986] [G loss: -0.010624]\n",
      "[Epoch 139/200] [Batch 26/44] [D loss: 0.007704] [G loss: -0.010619]\n",
      "[Epoch 139/200] [Batch 28/44] [D loss: 0.005571] [G loss: -0.010620]\n",
      "[Epoch 139/200] [Batch 30/44] [D loss: 0.006185] [G loss: -0.010632]\n",
      "[Epoch 139/200] [Batch 32/44] [D loss: 0.006194] [G loss: -0.010611]\n",
      "[Epoch 139/200] [Batch 34/44] [D loss: 0.004366] [G loss: -0.010632]\n",
      "[Epoch 139/200] [Batch 36/44] [D loss: 0.003499] [G loss: -0.010623]\n",
      "[Epoch 139/200] [Batch 38/44] [D loss: 0.006471] [G loss: -0.010613]\n",
      "[Epoch 139/200] [Batch 40/44] [D loss: 0.004040] [G loss: -0.010617]\n",
      "[Epoch 139/200] [Batch 42/44] [D loss: 0.004527] [G loss: -0.010617]\n",
      "[Epoch 140/200] [Batch 0/44] [D loss: 0.006353] [G loss: -0.010630]\n",
      "[Epoch 140/200] [Batch 2/44] [D loss: 0.005112] [G loss: -0.010637]\n",
      "[Epoch 140/200] [Batch 4/44] [D loss: 0.004789] [G loss: -0.010605]\n",
      "[Epoch 140/200] [Batch 6/44] [D loss: 0.005295] [G loss: -0.010630]\n",
      "[Epoch 140/200] [Batch 8/44] [D loss: 0.005625] [G loss: -0.010618]\n",
      "[Epoch 140/200] [Batch 10/44] [D loss: 0.004947] [G loss: -0.010602]\n",
      "[Epoch 140/200] [Batch 12/44] [D loss: 0.005575] [G loss: -0.010626]\n",
      "[Epoch 140/200] [Batch 14/44] [D loss: 0.006198] [G loss: -0.010604]\n",
      "[Epoch 140/200] [Batch 16/44] [D loss: 0.004917] [G loss: -0.010622]\n",
      "[Epoch 140/200] [Batch 18/44] [D loss: 0.005764] [G loss: -0.010612]\n",
      "[Epoch 140/200] [Batch 20/44] [D loss: 0.007094] [G loss: -0.010586]\n",
      "[Epoch 140/200] [Batch 22/44] [D loss: 0.004888] [G loss: -0.010616]\n",
      "[Epoch 140/200] [Batch 24/44] [D loss: 0.005190] [G loss: -0.010608]\n",
      "[Epoch 140/200] [Batch 26/44] [D loss: 0.007507] [G loss: -0.010629]\n",
      "[Epoch 140/200] [Batch 28/44] [D loss: 0.006287] [G loss: -0.010626]\n",
      "[Epoch 140/200] [Batch 30/44] [D loss: 0.003182] [G loss: -0.010612]\n",
      "[Epoch 140/200] [Batch 32/44] [D loss: 0.006343] [G loss: -0.010619]\n",
      "[Epoch 140/200] [Batch 34/44] [D loss: 0.004625] [G loss: -0.010608]\n",
      "[Epoch 140/200] [Batch 36/44] [D loss: 0.006555] [G loss: -0.010641]\n",
      "[Epoch 140/200] [Batch 38/44] [D loss: 0.004800] [G loss: -0.010624]\n",
      "[Epoch 140/200] [Batch 40/44] [D loss: 0.006910] [G loss: -0.010642]\n",
      "[Epoch 140/200] [Batch 42/44] [D loss: 0.007275] [G loss: -0.010629]\n",
      "[Epoch 141/200] [Batch 0/44] [D loss: 0.005394] [G loss: -0.010627]\n",
      "[Epoch 141/200] [Batch 2/44] [D loss: 0.006331] [G loss: -0.010638]\n",
      "[Epoch 141/200] [Batch 4/44] [D loss: 0.007125] [G loss: -0.010609]\n",
      "[Epoch 141/200] [Batch 6/44] [D loss: 0.005990] [G loss: -0.010613]\n",
      "[Epoch 141/200] [Batch 8/44] [D loss: 0.004522] [G loss: -0.010599]\n",
      "[Epoch 141/200] [Batch 10/44] [D loss: 0.005932] [G loss: -0.010625]\n",
      "[Epoch 141/200] [Batch 12/44] [D loss: 0.005304] [G loss: -0.010629]\n",
      "[Epoch 141/200] [Batch 14/44] [D loss: 0.005151] [G loss: -0.010624]\n",
      "[Epoch 141/200] [Batch 16/44] [D loss: 0.004293] [G loss: -0.010611]\n",
      "[Epoch 141/200] [Batch 18/44] [D loss: 0.005594] [G loss: -0.010611]\n",
      "[Epoch 141/200] [Batch 20/44] [D loss: 0.007572] [G loss: -0.010594]\n",
      "[Epoch 141/200] [Batch 22/44] [D loss: 0.007137] [G loss: -0.010601]\n",
      "[Epoch 141/200] [Batch 24/44] [D loss: 0.005365] [G loss: -0.010603]\n",
      "[Epoch 141/200] [Batch 26/44] [D loss: 0.005910] [G loss: -0.010619]\n",
      "[Epoch 141/200] [Batch 28/44] [D loss: 0.006931] [G loss: -0.010616]\n",
      "[Epoch 141/200] [Batch 30/44] [D loss: 0.005638] [G loss: -0.010613]\n",
      "[Epoch 141/200] [Batch 32/44] [D loss: 0.006571] [G loss: -0.010609]\n",
      "[Epoch 141/200] [Batch 34/44] [D loss: 0.007318] [G loss: -0.010598]\n",
      "[Epoch 141/200] [Batch 36/44] [D loss: 0.004718] [G loss: -0.010613]\n",
      "[Epoch 141/200] [Batch 38/44] [D loss: 0.004847] [G loss: -0.010587]\n",
      "[Epoch 141/200] [Batch 40/44] [D loss: 0.004913] [G loss: -0.010619]\n",
      "[Epoch 141/200] [Batch 42/44] [D loss: 0.004525] [G loss: -0.010609]\n",
      "[Epoch 142/200] [Batch 0/44] [D loss: 0.004869] [G loss: -0.010611]\n",
      "[Epoch 142/200] [Batch 2/44] [D loss: 0.005339] [G loss: -0.010606]\n",
      "[Epoch 142/200] [Batch 4/44] [D loss: 0.004832] [G loss: -0.010611]\n",
      "[Epoch 142/200] [Batch 6/44] [D loss: 0.005852] [G loss: -0.010627]\n",
      "[Epoch 142/200] [Batch 8/44] [D loss: 0.003235] [G loss: -0.010618]\n",
      "[Epoch 142/200] [Batch 10/44] [D loss: 0.006519] [G loss: -0.010618]\n",
      "[Epoch 142/200] [Batch 12/44] [D loss: 0.005283] [G loss: -0.010650]\n",
      "[Epoch 142/200] [Batch 14/44] [D loss: 0.005588] [G loss: -0.010609]\n",
      "[Epoch 142/200] [Batch 16/44] [D loss: 0.006553] [G loss: -0.010619]\n",
      "[Epoch 142/200] [Batch 18/44] [D loss: 0.005067] [G loss: -0.010618]\n",
      "[Epoch 142/200] [Batch 20/44] [D loss: 0.004743] [G loss: -0.010626]\n",
      "[Epoch 142/200] [Batch 22/44] [D loss: 0.003899] [G loss: -0.010640]\n",
      "[Epoch 142/200] [Batch 24/44] [D loss: 0.006015] [G loss: -0.010632]\n",
      "[Epoch 142/200] [Batch 26/44] [D loss: 0.006240] [G loss: -0.010626]\n",
      "[Epoch 142/200] [Batch 28/44] [D loss: 0.004888] [G loss: -0.010617]\n",
      "[Epoch 142/200] [Batch 30/44] [D loss: 0.003720] [G loss: -0.010590]\n",
      "[Epoch 142/200] [Batch 32/44] [D loss: 0.005555] [G loss: -0.010616]\n",
      "[Epoch 142/200] [Batch 34/44] [D loss: 0.006068] [G loss: -0.010611]\n",
      "[Epoch 142/200] [Batch 36/44] [D loss: 0.006276] [G loss: -0.010617]\n",
      "[Epoch 142/200] [Batch 38/44] [D loss: 0.005927] [G loss: -0.010632]\n",
      "[Epoch 142/200] [Batch 40/44] [D loss: 0.006660] [G loss: -0.010628]\n",
      "[Epoch 142/200] [Batch 42/44] [D loss: 0.008707] [G loss: -0.010607]\n",
      "[Epoch 143/200] [Batch 0/44] [D loss: 0.006563] [G loss: -0.010606]\n",
      "[Epoch 143/200] [Batch 2/44] [D loss: 0.006225] [G loss: -0.010610]\n",
      "[Epoch 143/200] [Batch 4/44] [D loss: 0.005331] [G loss: -0.010647]\n",
      "[Epoch 143/200] [Batch 6/44] [D loss: 0.003889] [G loss: -0.010601]\n",
      "[Epoch 143/200] [Batch 8/44] [D loss: 0.005091] [G loss: -0.010615]\n",
      "[Epoch 143/200] [Batch 10/44] [D loss: 0.005407] [G loss: -0.010617]\n",
      "[Epoch 143/200] [Batch 12/44] [D loss: 0.006700] [G loss: -0.010636]\n",
      "[Epoch 143/200] [Batch 14/44] [D loss: 0.007374] [G loss: -0.010619]\n",
      "[Epoch 143/200] [Batch 16/44] [D loss: 0.006376] [G loss: -0.010593]\n",
      "[Epoch 143/200] [Batch 18/44] [D loss: 0.003355] [G loss: -0.010621]\n",
      "[Epoch 143/200] [Batch 20/44] [D loss: 0.004935] [G loss: -0.010605]\n",
      "[Epoch 143/200] [Batch 22/44] [D loss: 0.003712] [G loss: -0.010615]\n",
      "[Epoch 143/200] [Batch 24/44] [D loss: 0.005914] [G loss: -0.010595]\n",
      "[Epoch 143/200] [Batch 26/44] [D loss: 0.005069] [G loss: -0.010620]\n",
      "[Epoch 143/200] [Batch 28/44] [D loss: 0.005412] [G loss: -0.010613]\n",
      "[Epoch 143/200] [Batch 30/44] [D loss: 0.003876] [G loss: -0.010608]\n",
      "[Epoch 143/200] [Batch 32/44] [D loss: 0.004905] [G loss: -0.010634]\n",
      "[Epoch 143/200] [Batch 34/44] [D loss: 0.004711] [G loss: -0.010629]\n",
      "[Epoch 143/200] [Batch 36/44] [D loss: 0.007933] [G loss: -0.010622]\n",
      "[Epoch 143/200] [Batch 38/44] [D loss: 0.007045] [G loss: -0.010619]\n",
      "[Epoch 143/200] [Batch 40/44] [D loss: 0.006092] [G loss: -0.010615]\n",
      "[Epoch 143/200] [Batch 42/44] [D loss: 0.003074] [G loss: -0.010628]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 144/200] [Batch 0/44] [D loss: 0.006742] [G loss: -0.010622]\n",
      "[Epoch 144/200] [Batch 2/44] [D loss: 0.004718] [G loss: -0.010624]\n",
      "[Epoch 144/200] [Batch 4/44] [D loss: 0.007872] [G loss: -0.010615]\n",
      "[Epoch 144/200] [Batch 6/44] [D loss: 0.005791] [G loss: -0.010622]\n",
      "[Epoch 144/200] [Batch 8/44] [D loss: 0.004396] [G loss: -0.010600]\n",
      "[Epoch 144/200] [Batch 10/44] [D loss: 0.004726] [G loss: -0.010614]\n",
      "[Epoch 144/200] [Batch 12/44] [D loss: 0.005013] [G loss: -0.010621]\n",
      "[Epoch 144/200] [Batch 14/44] [D loss: 0.004757] [G loss: -0.010624]\n",
      "[Epoch 144/200] [Batch 16/44] [D loss: 0.005859] [G loss: -0.010626]\n",
      "[Epoch 144/200] [Batch 18/44] [D loss: 0.005931] [G loss: -0.010624]\n",
      "[Epoch 144/200] [Batch 20/44] [D loss: 0.004320] [G loss: -0.010617]\n",
      "[Epoch 144/200] [Batch 22/44] [D loss: 0.005117] [G loss: -0.010637]\n",
      "[Epoch 144/200] [Batch 24/44] [D loss: 0.005086] [G loss: -0.010618]\n",
      "[Epoch 144/200] [Batch 26/44] [D loss: 0.006198] [G loss: -0.010656]\n",
      "[Epoch 144/200] [Batch 28/44] [D loss: 0.006164] [G loss: -0.010611]\n",
      "[Epoch 144/200] [Batch 30/44] [D loss: 0.006289] [G loss: -0.010635]\n",
      "[Epoch 144/200] [Batch 32/44] [D loss: 0.005537] [G loss: -0.010625]\n",
      "[Epoch 144/200] [Batch 34/44] [D loss: 0.005690] [G loss: -0.010616]\n",
      "[Epoch 144/200] [Batch 36/44] [D loss: 0.005851] [G loss: -0.010605]\n",
      "[Epoch 144/200] [Batch 38/44] [D loss: 0.004867] [G loss: -0.010601]\n",
      "[Epoch 144/200] [Batch 40/44] [D loss: 0.005759] [G loss: -0.010628]\n",
      "[Epoch 144/200] [Batch 42/44] [D loss: 0.007264] [G loss: -0.010611]\n",
      "[Epoch 145/200] [Batch 0/44] [D loss: 0.006777] [G loss: -0.010620]\n",
      "[Epoch 145/200] [Batch 2/44] [D loss: 0.005618] [G loss: -0.010607]\n",
      "[Epoch 145/200] [Batch 4/44] [D loss: 0.005785] [G loss: -0.010630]\n",
      "[Epoch 145/200] [Batch 6/44] [D loss: 0.004729] [G loss: -0.010631]\n",
      "[Epoch 145/200] [Batch 8/44] [D loss: 0.003672] [G loss: -0.010625]\n",
      "[Epoch 145/200] [Batch 10/44] [D loss: 0.002636] [G loss: -0.010609]\n",
      "[Epoch 145/200] [Batch 12/44] [D loss: 0.005022] [G loss: -0.010599]\n",
      "[Epoch 145/200] [Batch 14/44] [D loss: 0.006846] [G loss: -0.010614]\n",
      "[Epoch 145/200] [Batch 16/44] [D loss: 0.006681] [G loss: -0.010618]\n",
      "[Epoch 145/200] [Batch 18/44] [D loss: 0.007982] [G loss: -0.010620]\n",
      "[Epoch 145/200] [Batch 20/44] [D loss: 0.003608] [G loss: -0.010609]\n",
      "[Epoch 145/200] [Batch 22/44] [D loss: 0.004092] [G loss: -0.010613]\n",
      "[Epoch 145/200] [Batch 24/44] [D loss: 0.003986] [G loss: -0.010621]\n",
      "[Epoch 145/200] [Batch 26/44] [D loss: 0.008328] [G loss: -0.010604]\n",
      "[Epoch 145/200] [Batch 28/44] [D loss: 0.005137] [G loss: -0.010619]\n",
      "[Epoch 145/200] [Batch 30/44] [D loss: 0.004137] [G loss: -0.010617]\n",
      "[Epoch 145/200] [Batch 32/44] [D loss: 0.006245] [G loss: -0.010617]\n",
      "[Epoch 145/200] [Batch 34/44] [D loss: 0.005823] [G loss: -0.010617]\n",
      "[Epoch 145/200] [Batch 36/44] [D loss: 0.005527] [G loss: -0.010616]\n",
      "[Epoch 145/200] [Batch 38/44] [D loss: 0.005906] [G loss: -0.010617]\n",
      "[Epoch 145/200] [Batch 40/44] [D loss: 0.006224] [G loss: -0.010632]\n",
      "[Epoch 145/200] [Batch 42/44] [D loss: 0.006803] [G loss: -0.010620]\n",
      "[Epoch 146/200] [Batch 0/44] [D loss: 0.005339] [G loss: -0.010608]\n",
      "[Epoch 146/200] [Batch 2/44] [D loss: 0.004988] [G loss: -0.010609]\n",
      "[Epoch 146/200] [Batch 4/44] [D loss: 0.007308] [G loss: -0.010626]\n",
      "[Epoch 146/200] [Batch 6/44] [D loss: 0.002788] [G loss: -0.010640]\n",
      "[Epoch 146/200] [Batch 8/44] [D loss: 0.003349] [G loss: -0.010627]\n",
      "[Epoch 146/200] [Batch 10/44] [D loss: 0.005443] [G loss: -0.010620]\n",
      "[Epoch 146/200] [Batch 12/44] [D loss: 0.005282] [G loss: -0.010617]\n",
      "[Epoch 146/200] [Batch 14/44] [D loss: 0.004574] [G loss: -0.010637]\n",
      "[Epoch 146/200] [Batch 16/44] [D loss: 0.004623] [G loss: -0.010612]\n",
      "[Epoch 146/200] [Batch 18/44] [D loss: 0.003598] [G loss: -0.010620]\n",
      "[Epoch 146/200] [Batch 20/44] [D loss: 0.008197] [G loss: -0.010617]\n",
      "[Epoch 146/200] [Batch 22/44] [D loss: 0.005198] [G loss: -0.010612]\n",
      "[Epoch 146/200] [Batch 24/44] [D loss: 0.006345] [G loss: -0.010633]\n",
      "[Epoch 146/200] [Batch 26/44] [D loss: 0.005864] [G loss: -0.010597]\n",
      "[Epoch 146/200] [Batch 28/44] [D loss: 0.005867] [G loss: -0.010598]\n",
      "[Epoch 146/200] [Batch 30/44] [D loss: 0.006666] [G loss: -0.010632]\n",
      "[Epoch 146/200] [Batch 32/44] [D loss: 0.005407] [G loss: -0.010632]\n",
      "[Epoch 146/200] [Batch 34/44] [D loss: 0.004582] [G loss: -0.010606]\n",
      "[Epoch 146/200] [Batch 36/44] [D loss: 0.005718] [G loss: -0.010619]\n",
      "[Epoch 146/200] [Batch 38/44] [D loss: 0.005072] [G loss: -0.010617]\n",
      "[Epoch 146/200] [Batch 40/44] [D loss: 0.004139] [G loss: -0.010619]\n",
      "[Epoch 146/200] [Batch 42/44] [D loss: 0.004445] [G loss: -0.010609]\n",
      "[Epoch 147/200] [Batch 0/44] [D loss: 0.006011] [G loss: -0.010648]\n",
      "[Epoch 147/200] [Batch 2/44] [D loss: 0.002479] [G loss: -0.010600]\n",
      "[Epoch 147/200] [Batch 4/44] [D loss: 0.007610] [G loss: -0.010615]\n",
      "[Epoch 147/200] [Batch 6/44] [D loss: 0.005681] [G loss: -0.010630]\n",
      "[Epoch 147/200] [Batch 8/44] [D loss: 0.006978] [G loss: -0.010642]\n",
      "[Epoch 147/200] [Batch 10/44] [D loss: 0.006869] [G loss: -0.010623]\n",
      "[Epoch 147/200] [Batch 12/44] [D loss: 0.006084] [G loss: -0.010614]\n",
      "[Epoch 147/200] [Batch 14/44] [D loss: 0.006045] [G loss: -0.010625]\n",
      "[Epoch 147/200] [Batch 16/44] [D loss: 0.006457] [G loss: -0.010608]\n",
      "[Epoch 147/200] [Batch 18/44] [D loss: 0.005785] [G loss: -0.010611]\n",
      "[Epoch 147/200] [Batch 20/44] [D loss: 0.003597] [G loss: -0.010626]\n",
      "[Epoch 147/200] [Batch 22/44] [D loss: 0.004428] [G loss: -0.010638]\n",
      "[Epoch 147/200] [Batch 24/44] [D loss: 0.004896] [G loss: -0.010624]\n",
      "[Epoch 147/200] [Batch 26/44] [D loss: 0.006229] [G loss: -0.010614]\n",
      "[Epoch 147/200] [Batch 28/44] [D loss: 0.007430] [G loss: -0.010609]\n",
      "[Epoch 147/200] [Batch 30/44] [D loss: 0.005414] [G loss: -0.010599]\n",
      "[Epoch 147/200] [Batch 32/44] [D loss: 0.006004] [G loss: -0.010634]\n",
      "[Epoch 147/200] [Batch 34/44] [D loss: 0.005337] [G loss: -0.010619]\n",
      "[Epoch 147/200] [Batch 36/44] [D loss: 0.006033] [G loss: -0.010630]\n",
      "[Epoch 147/200] [Batch 38/44] [D loss: 0.006461] [G loss: -0.010619]\n",
      "[Epoch 147/200] [Batch 40/44] [D loss: 0.007073] [G loss: -0.010629]\n",
      "[Epoch 147/200] [Batch 42/44] [D loss: 0.005303] [G loss: -0.010606]\n",
      "[Epoch 148/200] [Batch 0/44] [D loss: 0.006367] [G loss: -0.010628]\n",
      "[Epoch 148/200] [Batch 2/44] [D loss: 0.004600] [G loss: -0.010623]\n",
      "[Epoch 148/200] [Batch 4/44] [D loss: 0.005141] [G loss: -0.010599]\n",
      "[Epoch 148/200] [Batch 6/44] [D loss: 0.004982] [G loss: -0.010611]\n",
      "[Epoch 148/200] [Batch 8/44] [D loss: 0.005694] [G loss: -0.010633]\n",
      "[Epoch 148/200] [Batch 10/44] [D loss: 0.005767] [G loss: -0.010616]\n",
      "[Epoch 148/200] [Batch 12/44] [D loss: 0.005949] [G loss: -0.010627]\n",
      "[Epoch 148/200] [Batch 14/44] [D loss: 0.006129] [G loss: -0.010649]\n",
      "[Epoch 148/200] [Batch 16/44] [D loss: 0.006176] [G loss: -0.010600]\n",
      "[Epoch 148/200] [Batch 18/44] [D loss: 0.003594] [G loss: -0.010605]\n",
      "[Epoch 148/200] [Batch 20/44] [D loss: 0.004990] [G loss: -0.010607]\n",
      "[Epoch 148/200] [Batch 22/44] [D loss: 0.005905] [G loss: -0.010609]\n",
      "[Epoch 148/200] [Batch 24/44] [D loss: 0.008054] [G loss: -0.010627]\n",
      "[Epoch 148/200] [Batch 26/44] [D loss: 0.006065] [G loss: -0.010614]\n",
      "[Epoch 148/200] [Batch 28/44] [D loss: 0.006461] [G loss: -0.010625]\n",
      "[Epoch 148/200] [Batch 30/44] [D loss: 0.005607] [G loss: -0.010610]\n",
      "[Epoch 148/200] [Batch 32/44] [D loss: 0.004704] [G loss: -0.010595]\n",
      "[Epoch 148/200] [Batch 34/44] [D loss: 0.004948] [G loss: -0.010617]\n",
      "[Epoch 148/200] [Batch 36/44] [D loss: 0.005497] [G loss: -0.010599]\n",
      "[Epoch 148/200] [Batch 38/44] [D loss: 0.006950] [G loss: -0.010624]\n",
      "[Epoch 148/200] [Batch 40/44] [D loss: 0.004987] [G loss: -0.010625]\n",
      "[Epoch 148/200] [Batch 42/44] [D loss: 0.005613] [G loss: -0.010626]\n",
      "[Epoch 149/200] [Batch 0/44] [D loss: 0.006445] [G loss: -0.010616]\n",
      "[Epoch 149/200] [Batch 2/44] [D loss: 0.006207] [G loss: -0.010623]\n",
      "[Epoch 149/200] [Batch 4/44] [D loss: 0.004511] [G loss: -0.010637]\n",
      "[Epoch 149/200] [Batch 6/44] [D loss: 0.005750] [G loss: -0.010611]\n",
      "[Epoch 149/200] [Batch 8/44] [D loss: 0.005254] [G loss: -0.010613]\n",
      "[Epoch 149/200] [Batch 10/44] [D loss: 0.005934] [G loss: -0.010649]\n",
      "[Epoch 149/200] [Batch 12/44] [D loss: 0.004578] [G loss: -0.010621]\n",
      "[Epoch 149/200] [Batch 14/44] [D loss: 0.005815] [G loss: -0.010631]\n",
      "[Epoch 149/200] [Batch 16/44] [D loss: 0.007377] [G loss: -0.010601]\n",
      "[Epoch 149/200] [Batch 18/44] [D loss: 0.004824] [G loss: -0.010624]\n",
      "[Epoch 149/200] [Batch 20/44] [D loss: 0.006024] [G loss: -0.010598]\n",
      "[Epoch 149/200] [Batch 22/44] [D loss: 0.006506] [G loss: -0.010633]\n",
      "[Epoch 149/200] [Batch 24/44] [D loss: 0.005188] [G loss: -0.010609]\n",
      "[Epoch 149/200] [Batch 26/44] [D loss: 0.006648] [G loss: -0.010605]\n",
      "[Epoch 149/200] [Batch 28/44] [D loss: 0.004032] [G loss: -0.010633]\n",
      "[Epoch 149/200] [Batch 30/44] [D loss: 0.006355] [G loss: -0.010621]\n",
      "[Epoch 149/200] [Batch 32/44] [D loss: 0.006188] [G loss: -0.010625]\n",
      "[Epoch 149/200] [Batch 34/44] [D loss: 0.004540] [G loss: -0.010611]\n",
      "[Epoch 149/200] [Batch 36/44] [D loss: 0.004691] [G loss: -0.010618]\n",
      "[Epoch 149/200] [Batch 38/44] [D loss: 0.005760] [G loss: -0.010623]\n",
      "[Epoch 149/200] [Batch 40/44] [D loss: 0.004330] [G loss: -0.010612]\n",
      "[Epoch 149/200] [Batch 42/44] [D loss: 0.004952] [G loss: -0.010613]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 150/200] [Batch 0/44] [D loss: 0.005592] [G loss: -0.010626]\n",
      "[Epoch 150/200] [Batch 2/44] [D loss: 0.005195] [G loss: -0.010615]\n",
      "[Epoch 150/200] [Batch 4/44] [D loss: 0.005458] [G loss: -0.010646]\n",
      "[Epoch 150/200] [Batch 6/44] [D loss: 0.003777] [G loss: -0.010630]\n",
      "[Epoch 150/200] [Batch 8/44] [D loss: 0.003869] [G loss: -0.010620]\n",
      "[Epoch 150/200] [Batch 10/44] [D loss: 0.006199] [G loss: -0.010605]\n",
      "[Epoch 150/200] [Batch 12/44] [D loss: 0.007038] [G loss: -0.010615]\n",
      "[Epoch 150/200] [Batch 14/44] [D loss: 0.004842] [G loss: -0.010609]\n",
      "[Epoch 150/200] [Batch 16/44] [D loss: 0.006113] [G loss: -0.010632]\n",
      "[Epoch 150/200] [Batch 18/44] [D loss: 0.005042] [G loss: -0.010622]\n",
      "[Epoch 150/200] [Batch 20/44] [D loss: 0.003826] [G loss: -0.010610]\n",
      "[Epoch 150/200] [Batch 22/44] [D loss: 0.006369] [G loss: -0.010627]\n",
      "[Epoch 150/200] [Batch 24/44] [D loss: 0.005447] [G loss: -0.010621]\n",
      "[Epoch 150/200] [Batch 26/44] [D loss: 0.003933] [G loss: -0.010644]\n",
      "[Epoch 150/200] [Batch 28/44] [D loss: 0.008199] [G loss: -0.010623]\n",
      "[Epoch 150/200] [Batch 30/44] [D loss: 0.005726] [G loss: -0.010622]\n",
      "[Epoch 150/200] [Batch 32/44] [D loss: 0.005546] [G loss: -0.010617]\n",
      "[Epoch 150/200] [Batch 34/44] [D loss: 0.005825] [G loss: -0.010613]\n",
      "[Epoch 150/200] [Batch 36/44] [D loss: 0.006424] [G loss: -0.010623]\n",
      "[Epoch 150/200] [Batch 38/44] [D loss: 0.006394] [G loss: -0.010619]\n",
      "[Epoch 150/200] [Batch 40/44] [D loss: 0.007079] [G loss: -0.010629]\n",
      "[Epoch 150/200] [Batch 42/44] [D loss: 0.005288] [G loss: -0.010618]\n",
      "[Epoch 151/200] [Batch 0/44] [D loss: 0.005699] [G loss: -0.010614]\n",
      "[Epoch 151/200] [Batch 2/44] [D loss: 0.006847] [G loss: -0.010616]\n",
      "[Epoch 151/200] [Batch 4/44] [D loss: 0.006304] [G loss: -0.010626]\n",
      "[Epoch 151/200] [Batch 6/44] [D loss: 0.005968] [G loss: -0.010626]\n",
      "[Epoch 151/200] [Batch 8/44] [D loss: 0.007215] [G loss: -0.010626]\n",
      "[Epoch 151/200] [Batch 10/44] [D loss: 0.005010] [G loss: -0.010618]\n",
      "[Epoch 151/200] [Batch 12/44] [D loss: 0.007889] [G loss: -0.010644]\n",
      "[Epoch 151/200] [Batch 14/44] [D loss: 0.004793] [G loss: -0.010636]\n",
      "[Epoch 151/200] [Batch 16/44] [D loss: 0.005111] [G loss: -0.010604]\n",
      "[Epoch 151/200] [Batch 18/44] [D loss: 0.004386] [G loss: -0.010609]\n",
      "[Epoch 151/200] [Batch 20/44] [D loss: 0.006243] [G loss: -0.010642]\n",
      "[Epoch 151/200] [Batch 22/44] [D loss: 0.002947] [G loss: -0.010588]\n",
      "[Epoch 151/200] [Batch 24/44] [D loss: 0.006164] [G loss: -0.010620]\n",
      "[Epoch 151/200] [Batch 26/44] [D loss: 0.005028] [G loss: -0.010600]\n",
      "[Epoch 151/200] [Batch 28/44] [D loss: 0.005107] [G loss: -0.010609]\n",
      "[Epoch 151/200] [Batch 30/44] [D loss: 0.005341] [G loss: -0.010627]\n",
      "[Epoch 151/200] [Batch 32/44] [D loss: 0.004934] [G loss: -0.010591]\n",
      "[Epoch 151/200] [Batch 34/44] [D loss: 0.002970] [G loss: -0.010621]\n",
      "[Epoch 151/200] [Batch 36/44] [D loss: 0.006127] [G loss: -0.010629]\n",
      "[Epoch 151/200] [Batch 38/44] [D loss: 0.006006] [G loss: -0.010644]\n",
      "[Epoch 151/200] [Batch 40/44] [D loss: 0.006145] [G loss: -0.010611]\n",
      "[Epoch 151/200] [Batch 42/44] [D loss: 0.003781] [G loss: -0.010621]\n",
      "[Epoch 152/200] [Batch 0/44] [D loss: 0.006129] [G loss: -0.010634]\n",
      "[Epoch 152/200] [Batch 2/44] [D loss: 0.008830] [G loss: -0.010622]\n",
      "[Epoch 152/200] [Batch 4/44] [D loss: 0.006068] [G loss: -0.010605]\n",
      "[Epoch 152/200] [Batch 6/44] [D loss: 0.006776] [G loss: -0.010624]\n",
      "[Epoch 152/200] [Batch 8/44] [D loss: 0.008769] [G loss: -0.010599]\n",
      "[Epoch 152/200] [Batch 10/44] [D loss: 0.006725] [G loss: -0.010640]\n",
      "[Epoch 152/200] [Batch 12/44] [D loss: 0.002382] [G loss: -0.010626]\n",
      "[Epoch 152/200] [Batch 14/44] [D loss: 0.006661] [G loss: -0.010638]\n",
      "[Epoch 152/200] [Batch 16/44] [D loss: 0.007026] [G loss: -0.010645]\n",
      "[Epoch 152/200] [Batch 18/44] [D loss: 0.004282] [G loss: -0.010611]\n",
      "[Epoch 152/200] [Batch 20/44] [D loss: 0.006142] [G loss: -0.010612]\n",
      "[Epoch 152/200] [Batch 22/44] [D loss: 0.003567] [G loss: -0.010632]\n",
      "[Epoch 152/200] [Batch 24/44] [D loss: 0.002648] [G loss: -0.010608]\n",
      "[Epoch 152/200] [Batch 26/44] [D loss: 0.005550] [G loss: -0.010617]\n",
      "[Epoch 152/200] [Batch 28/44] [D loss: 0.004972] [G loss: -0.010607]\n",
      "[Epoch 152/200] [Batch 30/44] [D loss: 0.004168] [G loss: -0.010612]\n",
      "[Epoch 152/200] [Batch 32/44] [D loss: 0.006003] [G loss: -0.010591]\n",
      "[Epoch 152/200] [Batch 34/44] [D loss: 0.007527] [G loss: -0.010599]\n",
      "[Epoch 152/200] [Batch 36/44] [D loss: 0.004624] [G loss: -0.010636]\n",
      "[Epoch 152/200] [Batch 38/44] [D loss: 0.002534] [G loss: -0.010615]\n",
      "[Epoch 152/200] [Batch 40/44] [D loss: 0.004994] [G loss: -0.010623]\n",
      "[Epoch 152/200] [Batch 42/44] [D loss: 0.005178] [G loss: -0.010616]\n",
      "[Epoch 153/200] [Batch 0/44] [D loss: 0.005379] [G loss: -0.010637]\n",
      "[Epoch 153/200] [Batch 2/44] [D loss: 0.005247] [G loss: -0.010627]\n",
      "[Epoch 153/200] [Batch 4/44] [D loss: 0.004267] [G loss: -0.010612]\n",
      "[Epoch 153/200] [Batch 6/44] [D loss: 0.005979] [G loss: -0.010616]\n",
      "[Epoch 153/200] [Batch 8/44] [D loss: 0.005980] [G loss: -0.010617]\n",
      "[Epoch 153/200] [Batch 10/44] [D loss: 0.006871] [G loss: -0.010613]\n",
      "[Epoch 153/200] [Batch 12/44] [D loss: 0.004856] [G loss: -0.010646]\n",
      "[Epoch 153/200] [Batch 14/44] [D loss: 0.005122] [G loss: -0.010623]\n",
      "[Epoch 153/200] [Batch 16/44] [D loss: 0.004074] [G loss: -0.010635]\n",
      "[Epoch 153/200] [Batch 18/44] [D loss: 0.004109] [G loss: -0.010617]\n",
      "[Epoch 153/200] [Batch 20/44] [D loss: 0.005227] [G loss: -0.010628]\n",
      "[Epoch 153/200] [Batch 22/44] [D loss: 0.005236] [G loss: -0.010610]\n",
      "[Epoch 153/200] [Batch 24/44] [D loss: 0.006113] [G loss: -0.010596]\n",
      "[Epoch 153/200] [Batch 26/44] [D loss: 0.006470] [G loss: -0.010632]\n",
      "[Epoch 153/200] [Batch 28/44] [D loss: 0.006658] [G loss: -0.010602]\n",
      "[Epoch 153/200] [Batch 30/44] [D loss: 0.005567] [G loss: -0.010613]\n",
      "[Epoch 153/200] [Batch 32/44] [D loss: 0.004727] [G loss: -0.010629]\n",
      "[Epoch 153/200] [Batch 34/44] [D loss: 0.007419] [G loss: -0.010633]\n",
      "[Epoch 153/200] [Batch 36/44] [D loss: 0.005600] [G loss: -0.010641]\n",
      "[Epoch 153/200] [Batch 38/44] [D loss: 0.005632] [G loss: -0.010624]\n",
      "[Epoch 153/200] [Batch 40/44] [D loss: 0.004852] [G loss: -0.010610]\n",
      "[Epoch 153/200] [Batch 42/44] [D loss: 0.005642] [G loss: -0.010632]\n",
      "[Epoch 154/200] [Batch 0/44] [D loss: 0.004100] [G loss: -0.010610]\n",
      "[Epoch 154/200] [Batch 2/44] [D loss: 0.005665] [G loss: -0.010623]\n",
      "[Epoch 154/200] [Batch 4/44] [D loss: 0.004786] [G loss: -0.010608]\n",
      "[Epoch 154/200] [Batch 6/44] [D loss: 0.005241] [G loss: -0.010652]\n",
      "[Epoch 154/200] [Batch 8/44] [D loss: 0.005514] [G loss: -0.010618]\n",
      "[Epoch 154/200] [Batch 10/44] [D loss: 0.006961] [G loss: -0.010626]\n",
      "[Epoch 154/200] [Batch 12/44] [D loss: 0.006225] [G loss: -0.010644]\n",
      "[Epoch 154/200] [Batch 14/44] [D loss: 0.005488] [G loss: -0.010591]\n",
      "[Epoch 154/200] [Batch 16/44] [D loss: 0.005900] [G loss: -0.010608]\n",
      "[Epoch 154/200] [Batch 18/44] [D loss: 0.006661] [G loss: -0.010593]\n",
      "[Epoch 154/200] [Batch 20/44] [D loss: 0.005051] [G loss: -0.010608]\n",
      "[Epoch 154/200] [Batch 22/44] [D loss: 0.006982] [G loss: -0.010640]\n",
      "[Epoch 154/200] [Batch 24/44] [D loss: 0.004833] [G loss: -0.010631]\n",
      "[Epoch 154/200] [Batch 26/44] [D loss: 0.007642] [G loss: -0.010611]\n",
      "[Epoch 154/200] [Batch 28/44] [D loss: 0.006284] [G loss: -0.010619]\n",
      "[Epoch 154/200] [Batch 30/44] [D loss: 0.003755] [G loss: -0.010628]\n",
      "[Epoch 154/200] [Batch 32/44] [D loss: 0.004868] [G loss: -0.010609]\n",
      "[Epoch 154/200] [Batch 34/44] [D loss: 0.003939] [G loss: -0.010600]\n",
      "[Epoch 154/200] [Batch 36/44] [D loss: 0.006983] [G loss: -0.010620]\n",
      "[Epoch 154/200] [Batch 38/44] [D loss: 0.003685] [G loss: -0.010615]\n",
      "[Epoch 154/200] [Batch 40/44] [D loss: 0.006686] [G loss: -0.010639]\n",
      "[Epoch 154/200] [Batch 42/44] [D loss: 0.007399] [G loss: -0.010619]\n",
      "[Epoch 155/200] [Batch 0/44] [D loss: 0.005885] [G loss: -0.010631]\n",
      "[Epoch 155/200] [Batch 2/44] [D loss: 0.004252] [G loss: -0.010614]\n",
      "[Epoch 155/200] [Batch 4/44] [D loss: 0.006040] [G loss: -0.010624]\n",
      "[Epoch 155/200] [Batch 6/44] [D loss: 0.006710] [G loss: -0.010619]\n",
      "[Epoch 155/200] [Batch 8/44] [D loss: 0.006120] [G loss: -0.010630]\n",
      "[Epoch 155/200] [Batch 10/44] [D loss: 0.003647] [G loss: -0.010656]\n",
      "[Epoch 155/200] [Batch 12/44] [D loss: 0.006066] [G loss: -0.010625]\n",
      "[Epoch 155/200] [Batch 14/44] [D loss: 0.007190] [G loss: -0.010603]\n",
      "[Epoch 155/200] [Batch 16/44] [D loss: 0.005385] [G loss: -0.010617]\n",
      "[Epoch 155/200] [Batch 18/44] [D loss: 0.006118] [G loss: -0.010593]\n",
      "[Epoch 155/200] [Batch 20/44] [D loss: 0.007578] [G loss: -0.010611]\n",
      "[Epoch 155/200] [Batch 22/44] [D loss: 0.003533] [G loss: -0.010640]\n",
      "[Epoch 155/200] [Batch 24/44] [D loss: 0.005136] [G loss: -0.010598]\n",
      "[Epoch 155/200] [Batch 26/44] [D loss: 0.005741] [G loss: -0.010639]\n",
      "[Epoch 155/200] [Batch 28/44] [D loss: 0.004642] [G loss: -0.010597]\n",
      "[Epoch 155/200] [Batch 30/44] [D loss: 0.006538] [G loss: -0.010597]\n",
      "[Epoch 155/200] [Batch 32/44] [D loss: 0.007367] [G loss: -0.010617]\n",
      "[Epoch 155/200] [Batch 34/44] [D loss: 0.004814] [G loss: -0.010622]\n",
      "[Epoch 155/200] [Batch 36/44] [D loss: 0.005308] [G loss: -0.010621]\n",
      "[Epoch 155/200] [Batch 38/44] [D loss: 0.004642] [G loss: -0.010603]\n",
      "[Epoch 155/200] [Batch 40/44] [D loss: 0.007507] [G loss: -0.010603]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 155/200] [Batch 42/44] [D loss: 0.006973] [G loss: -0.010605]\n",
      "[Epoch 156/200] [Batch 0/44] [D loss: 0.006513] [G loss: -0.010615]\n",
      "[Epoch 156/200] [Batch 2/44] [D loss: 0.004919] [G loss: -0.010620]\n",
      "[Epoch 156/200] [Batch 4/44] [D loss: 0.003885] [G loss: -0.010621]\n",
      "[Epoch 156/200] [Batch 6/44] [D loss: 0.003911] [G loss: -0.010658]\n",
      "[Epoch 156/200] [Batch 8/44] [D loss: 0.007257] [G loss: -0.010596]\n",
      "[Epoch 156/200] [Batch 10/44] [D loss: 0.005290] [G loss: -0.010607]\n",
      "[Epoch 156/200] [Batch 12/44] [D loss: 0.004410] [G loss: -0.010622]\n",
      "[Epoch 156/200] [Batch 14/44] [D loss: 0.005241] [G loss: -0.010629]\n",
      "[Epoch 156/200] [Batch 16/44] [D loss: 0.004533] [G loss: -0.010631]\n",
      "[Epoch 156/200] [Batch 18/44] [D loss: 0.004926] [G loss: -0.010623]\n",
      "[Epoch 156/200] [Batch 20/44] [D loss: 0.005059] [G loss: -0.010618]\n",
      "[Epoch 156/200] [Batch 22/44] [D loss: 0.005567] [G loss: -0.010635]\n",
      "[Epoch 156/200] [Batch 24/44] [D loss: 0.005757] [G loss: -0.010621]\n",
      "[Epoch 156/200] [Batch 26/44] [D loss: 0.006391] [G loss: -0.010608]\n",
      "[Epoch 156/200] [Batch 28/44] [D loss: 0.002806] [G loss: -0.010624]\n",
      "[Epoch 156/200] [Batch 30/44] [D loss: 0.004479] [G loss: -0.010624]\n",
      "[Epoch 156/200] [Batch 32/44] [D loss: 0.006543] [G loss: -0.010607]\n",
      "[Epoch 156/200] [Batch 34/44] [D loss: 0.004529] [G loss: -0.010629]\n",
      "[Epoch 156/200] [Batch 36/44] [D loss: 0.003232] [G loss: -0.010611]\n",
      "[Epoch 156/200] [Batch 38/44] [D loss: 0.005510] [G loss: -0.010623]\n",
      "[Epoch 156/200] [Batch 40/44] [D loss: 0.005971] [G loss: -0.010609]\n",
      "[Epoch 156/200] [Batch 42/44] [D loss: 0.007015] [G loss: -0.010645]\n",
      "[Epoch 157/200] [Batch 0/44] [D loss: 0.006352] [G loss: -0.010635]\n",
      "[Epoch 157/200] [Batch 2/44] [D loss: 0.006327] [G loss: -0.010631]\n",
      "[Epoch 157/200] [Batch 4/44] [D loss: 0.002663] [G loss: -0.010629]\n",
      "[Epoch 157/200] [Batch 6/44] [D loss: 0.006180] [G loss: -0.010633]\n",
      "[Epoch 157/200] [Batch 8/44] [D loss: 0.005707] [G loss: -0.010608]\n",
      "[Epoch 157/200] [Batch 10/44] [D loss: 0.003718] [G loss: -0.010595]\n",
      "[Epoch 157/200] [Batch 12/44] [D loss: 0.006766] [G loss: -0.010627]\n",
      "[Epoch 157/200] [Batch 14/44] [D loss: 0.008379] [G loss: -0.010619]\n",
      "[Epoch 157/200] [Batch 16/44] [D loss: 0.004888] [G loss: -0.010618]\n",
      "[Epoch 157/200] [Batch 18/44] [D loss: 0.003271] [G loss: -0.010614]\n",
      "[Epoch 157/200] [Batch 20/44] [D loss: 0.005166] [G loss: -0.010633]\n",
      "[Epoch 157/200] [Batch 22/44] [D loss: 0.007676] [G loss: -0.010622]\n",
      "[Epoch 157/200] [Batch 24/44] [D loss: 0.006771] [G loss: -0.010597]\n",
      "[Epoch 157/200] [Batch 26/44] [D loss: 0.003752] [G loss: -0.010620]\n",
      "[Epoch 157/200] [Batch 28/44] [D loss: 0.008058] [G loss: -0.010626]\n",
      "[Epoch 157/200] [Batch 30/44] [D loss: 0.005789] [G loss: -0.010638]\n",
      "[Epoch 157/200] [Batch 32/44] [D loss: 0.005684] [G loss: -0.010629]\n",
      "[Epoch 157/200] [Batch 34/44] [D loss: 0.004880] [G loss: -0.010624]\n",
      "[Epoch 157/200] [Batch 36/44] [D loss: 0.004570] [G loss: -0.010634]\n",
      "[Epoch 157/200] [Batch 38/44] [D loss: 0.005485] [G loss: -0.010625]\n",
      "[Epoch 157/200] [Batch 40/44] [D loss: 0.003610] [G loss: -0.010636]\n",
      "[Epoch 157/200] [Batch 42/44] [D loss: 0.006555] [G loss: -0.010623]\n",
      "[Epoch 158/200] [Batch 0/44] [D loss: 0.005004] [G loss: -0.010643]\n",
      "[Epoch 158/200] [Batch 2/44] [D loss: 0.005659] [G loss: -0.010621]\n",
      "[Epoch 158/200] [Batch 4/44] [D loss: 0.005757] [G loss: -0.010606]\n",
      "[Epoch 158/200] [Batch 6/44] [D loss: 0.006214] [G loss: -0.010605]\n",
      "[Epoch 158/200] [Batch 8/44] [D loss: 0.004641] [G loss: -0.010622]\n",
      "[Epoch 158/200] [Batch 10/44] [D loss: 0.004346] [G loss: -0.010605]\n",
      "[Epoch 158/200] [Batch 12/44] [D loss: 0.004308] [G loss: -0.010623]\n",
      "[Epoch 158/200] [Batch 14/44] [D loss: 0.006223] [G loss: -0.010591]\n",
      "[Epoch 158/200] [Batch 16/44] [D loss: 0.003790] [G loss: -0.010602]\n",
      "[Epoch 158/200] [Batch 18/44] [D loss: 0.004532] [G loss: -0.010608]\n",
      "[Epoch 158/200] [Batch 20/44] [D loss: 0.007129] [G loss: -0.010620]\n",
      "[Epoch 158/200] [Batch 22/44] [D loss: 0.006300] [G loss: -0.010615]\n",
      "[Epoch 158/200] [Batch 24/44] [D loss: 0.007757] [G loss: -0.010605]\n",
      "[Epoch 158/200] [Batch 26/44] [D loss: 0.004727] [G loss: -0.010620]\n",
      "[Epoch 158/200] [Batch 28/44] [D loss: 0.003879] [G loss: -0.010596]\n",
      "[Epoch 158/200] [Batch 30/44] [D loss: 0.006040] [G loss: -0.010611]\n",
      "[Epoch 158/200] [Batch 32/44] [D loss: 0.003121] [G loss: -0.010620]\n",
      "[Epoch 158/200] [Batch 34/44] [D loss: 0.007081] [G loss: -0.010622]\n",
      "[Epoch 158/200] [Batch 36/44] [D loss: 0.006423] [G loss: -0.010621]\n",
      "[Epoch 158/200] [Batch 38/44] [D loss: 0.007141] [G loss: -0.010617]\n",
      "[Epoch 158/200] [Batch 40/44] [D loss: 0.007778] [G loss: -0.010612]\n",
      "[Epoch 158/200] [Batch 42/44] [D loss: 0.007128] [G loss: -0.010582]\n",
      "[Epoch 159/200] [Batch 0/44] [D loss: 0.007410] [G loss: -0.010644]\n",
      "[Epoch 159/200] [Batch 2/44] [D loss: 0.004265] [G loss: -0.010597]\n",
      "[Epoch 159/200] [Batch 4/44] [D loss: 0.005507] [G loss: -0.010633]\n",
      "[Epoch 159/200] [Batch 6/44] [D loss: 0.007193] [G loss: -0.010607]\n",
      "[Epoch 159/200] [Batch 8/44] [D loss: 0.003708] [G loss: -0.010619]\n",
      "[Epoch 159/200] [Batch 10/44] [D loss: 0.007068] [G loss: -0.010596]\n",
      "[Epoch 159/200] [Batch 12/44] [D loss: 0.006317] [G loss: -0.010622]\n",
      "[Epoch 159/200] [Batch 14/44] [D loss: 0.005282] [G loss: -0.010599]\n",
      "[Epoch 159/200] [Batch 16/44] [D loss: 0.006397] [G loss: -0.010638]\n",
      "[Epoch 159/200] [Batch 18/44] [D loss: 0.007059] [G loss: -0.010607]\n",
      "[Epoch 159/200] [Batch 20/44] [D loss: 0.003752] [G loss: -0.010616]\n",
      "[Epoch 159/200] [Batch 22/44] [D loss: 0.006194] [G loss: -0.010615]\n",
      "[Epoch 159/200] [Batch 24/44] [D loss: 0.006028] [G loss: -0.010609]\n",
      "[Epoch 159/200] [Batch 26/44] [D loss: 0.005345] [G loss: -0.010610]\n",
      "[Epoch 159/200] [Batch 28/44] [D loss: 0.005406] [G loss: -0.010595]\n",
      "[Epoch 159/200] [Batch 30/44] [D loss: 0.005007] [G loss: -0.010615]\n",
      "[Epoch 159/200] [Batch 32/44] [D loss: 0.003262] [G loss: -0.010613]\n",
      "[Epoch 159/200] [Batch 34/44] [D loss: 0.006048] [G loss: -0.010637]\n",
      "[Epoch 159/200] [Batch 36/44] [D loss: 0.005941] [G loss: -0.010607]\n",
      "[Epoch 159/200] [Batch 38/44] [D loss: 0.006803] [G loss: -0.010625]\n",
      "[Epoch 159/200] [Batch 40/44] [D loss: 0.005978] [G loss: -0.010619]\n",
      "[Epoch 159/200] [Batch 42/44] [D loss: 0.006115] [G loss: -0.010617]\n",
      "[Epoch 160/200] [Batch 0/44] [D loss: 0.005604] [G loss: -0.010620]\n",
      "[Epoch 160/200] [Batch 2/44] [D loss: 0.004161] [G loss: -0.010623]\n",
      "[Epoch 160/200] [Batch 4/44] [D loss: 0.004948] [G loss: -0.010629]\n",
      "[Epoch 160/200] [Batch 6/44] [D loss: 0.007275] [G loss: -0.010620]\n",
      "[Epoch 160/200] [Batch 8/44] [D loss: 0.004666] [G loss: -0.010600]\n",
      "[Epoch 160/200] [Batch 10/44] [D loss: 0.006626] [G loss: -0.010607]\n",
      "[Epoch 160/200] [Batch 12/44] [D loss: 0.004362] [G loss: -0.010618]\n",
      "[Epoch 160/200] [Batch 14/44] [D loss: 0.005668] [G loss: -0.010607]\n",
      "[Epoch 160/200] [Batch 16/44] [D loss: 0.005234] [G loss: -0.010616]\n",
      "[Epoch 160/200] [Batch 18/44] [D loss: 0.004496] [G loss: -0.010605]\n",
      "[Epoch 160/200] [Batch 20/44] [D loss: 0.005209] [G loss: -0.010637]\n",
      "[Epoch 160/200] [Batch 22/44] [D loss: 0.004821] [G loss: -0.010621]\n",
      "[Epoch 160/200] [Batch 24/44] [D loss: 0.005292] [G loss: -0.010594]\n",
      "[Epoch 160/200] [Batch 26/44] [D loss: 0.004953] [G loss: -0.010620]\n",
      "[Epoch 160/200] [Batch 28/44] [D loss: 0.004644] [G loss: -0.010612]\n",
      "[Epoch 160/200] [Batch 30/44] [D loss: 0.006194] [G loss: -0.010592]\n",
      "[Epoch 160/200] [Batch 32/44] [D loss: 0.004052] [G loss: -0.010631]\n",
      "[Epoch 160/200] [Batch 34/44] [D loss: 0.004237] [G loss: -0.010629]\n",
      "[Epoch 160/200] [Batch 36/44] [D loss: 0.006081] [G loss: -0.010635]\n",
      "[Epoch 160/200] [Batch 38/44] [D loss: 0.005432] [G loss: -0.010628]\n",
      "[Epoch 160/200] [Batch 40/44] [D loss: 0.005841] [G loss: -0.010619]\n",
      "[Epoch 160/200] [Batch 42/44] [D loss: 0.008254] [G loss: -0.010616]\n",
      "[Epoch 161/200] [Batch 0/44] [D loss: 0.006128] [G loss: -0.010597]\n",
      "[Epoch 161/200] [Batch 2/44] [D loss: 0.005935] [G loss: -0.010607]\n",
      "[Epoch 161/200] [Batch 4/44] [D loss: 0.003127] [G loss: -0.010636]\n",
      "[Epoch 161/200] [Batch 6/44] [D loss: 0.005841] [G loss: -0.010594]\n",
      "[Epoch 161/200] [Batch 8/44] [D loss: 0.004986] [G loss: -0.010635]\n",
      "[Epoch 161/200] [Batch 10/44] [D loss: 0.006966] [G loss: -0.010611]\n",
      "[Epoch 161/200] [Batch 12/44] [D loss: 0.005650] [G loss: -0.010624]\n",
      "[Epoch 161/200] [Batch 14/44] [D loss: 0.004926] [G loss: -0.010602]\n",
      "[Epoch 161/200] [Batch 16/44] [D loss: 0.005359] [G loss: -0.010603]\n",
      "[Epoch 161/200] [Batch 18/44] [D loss: 0.004840] [G loss: -0.010625]\n",
      "[Epoch 161/200] [Batch 20/44] [D loss: 0.006351] [G loss: -0.010626]\n",
      "[Epoch 161/200] [Batch 22/44] [D loss: 0.006163] [G loss: -0.010615]\n",
      "[Epoch 161/200] [Batch 24/44] [D loss: 0.004979] [G loss: -0.010602]\n",
      "[Epoch 161/200] [Batch 26/44] [D loss: 0.006388] [G loss: -0.010611]\n",
      "[Epoch 161/200] [Batch 28/44] [D loss: 0.005746] [G loss: -0.010645]\n",
      "[Epoch 161/200] [Batch 30/44] [D loss: 0.004328] [G loss: -0.010615]\n",
      "[Epoch 161/200] [Batch 32/44] [D loss: 0.008521] [G loss: -0.010615]\n",
      "[Epoch 161/200] [Batch 34/44] [D loss: 0.007315] [G loss: -0.010613]\n",
      "[Epoch 161/200] [Batch 36/44] [D loss: 0.007179] [G loss: -0.010623]\n",
      "[Epoch 161/200] [Batch 38/44] [D loss: 0.004530] [G loss: -0.010653]\n",
      "[Epoch 161/200] [Batch 40/44] [D loss: 0.005759] [G loss: -0.010632]\n",
      "[Epoch 161/200] [Batch 42/44] [D loss: 0.004117] [G loss: -0.010601]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 162/200] [Batch 0/44] [D loss: 0.005346] [G loss: -0.010608]\n",
      "[Epoch 162/200] [Batch 2/44] [D loss: 0.004125] [G loss: -0.010646]\n",
      "[Epoch 162/200] [Batch 4/44] [D loss: 0.003239] [G loss: -0.010622]\n",
      "[Epoch 162/200] [Batch 6/44] [D loss: 0.006137] [G loss: -0.010621]\n",
      "[Epoch 162/200] [Batch 8/44] [D loss: 0.005575] [G loss: -0.010637]\n",
      "[Epoch 162/200] [Batch 10/44] [D loss: 0.004579] [G loss: -0.010642]\n",
      "[Epoch 162/200] [Batch 12/44] [D loss: 0.006593] [G loss: -0.010623]\n",
      "[Epoch 162/200] [Batch 14/44] [D loss: 0.005137] [G loss: -0.010627]\n",
      "[Epoch 162/200] [Batch 16/44] [D loss: 0.004775] [G loss: -0.010600]\n",
      "[Epoch 162/200] [Batch 18/44] [D loss: 0.006467] [G loss: -0.010615]\n",
      "[Epoch 162/200] [Batch 20/44] [D loss: 0.005451] [G loss: -0.010606]\n",
      "[Epoch 162/200] [Batch 22/44] [D loss: 0.004557] [G loss: -0.010619]\n",
      "[Epoch 162/200] [Batch 24/44] [D loss: 0.006359] [G loss: -0.010621]\n",
      "[Epoch 162/200] [Batch 26/44] [D loss: 0.006064] [G loss: -0.010622]\n",
      "[Epoch 162/200] [Batch 28/44] [D loss: 0.007133] [G loss: -0.010625]\n",
      "[Epoch 162/200] [Batch 30/44] [D loss: 0.005307] [G loss: -0.010608]\n",
      "[Epoch 162/200] [Batch 32/44] [D loss: 0.006025] [G loss: -0.010643]\n",
      "[Epoch 162/200] [Batch 34/44] [D loss: 0.007382] [G loss: -0.010626]\n",
      "[Epoch 162/200] [Batch 36/44] [D loss: 0.005136] [G loss: -0.010620]\n",
      "[Epoch 162/200] [Batch 38/44] [D loss: 0.005009] [G loss: -0.010620]\n",
      "[Epoch 162/200] [Batch 40/44] [D loss: 0.005943] [G loss: -0.010635]\n",
      "[Epoch 162/200] [Batch 42/44] [D loss: 0.007531] [G loss: -0.010619]\n",
      "[Epoch 163/200] [Batch 0/44] [D loss: 0.005127] [G loss: -0.010621]\n",
      "[Epoch 163/200] [Batch 2/44] [D loss: 0.005055] [G loss: -0.010604]\n",
      "[Epoch 163/200] [Batch 4/44] [D loss: 0.005285] [G loss: -0.010627]\n",
      "[Epoch 163/200] [Batch 6/44] [D loss: 0.005657] [G loss: -0.010617]\n",
      "[Epoch 163/200] [Batch 8/44] [D loss: 0.005864] [G loss: -0.010612]\n",
      "[Epoch 163/200] [Batch 10/44] [D loss: 0.006040] [G loss: -0.010609]\n",
      "[Epoch 163/200] [Batch 12/44] [D loss: 0.004639] [G loss: -0.010617]\n",
      "[Epoch 163/200] [Batch 14/44] [D loss: 0.003914] [G loss: -0.010630]\n",
      "[Epoch 163/200] [Batch 16/44] [D loss: 0.005899] [G loss: -0.010617]\n",
      "[Epoch 163/200] [Batch 18/44] [D loss: 0.006481] [G loss: -0.010618]\n",
      "[Epoch 163/200] [Batch 20/44] [D loss: 0.005529] [G loss: -0.010623]\n",
      "[Epoch 163/200] [Batch 22/44] [D loss: 0.007947] [G loss: -0.010620]\n",
      "[Epoch 163/200] [Batch 24/44] [D loss: 0.005113] [G loss: -0.010612]\n",
      "[Epoch 163/200] [Batch 26/44] [D loss: 0.006422] [G loss: -0.010596]\n",
      "[Epoch 163/200] [Batch 28/44] [D loss: 0.005174] [G loss: -0.010620]\n",
      "[Epoch 163/200] [Batch 30/44] [D loss: 0.006587] [G loss: -0.010601]\n",
      "[Epoch 163/200] [Batch 32/44] [D loss: 0.005141] [G loss: -0.010625]\n",
      "[Epoch 163/200] [Batch 34/44] [D loss: 0.003412] [G loss: -0.010628]\n",
      "[Epoch 163/200] [Batch 36/44] [D loss: 0.005041] [G loss: -0.010635]\n",
      "[Epoch 163/200] [Batch 38/44] [D loss: 0.004162] [G loss: -0.010620]\n",
      "[Epoch 163/200] [Batch 40/44] [D loss: 0.007740] [G loss: -0.010603]\n",
      "[Epoch 163/200] [Batch 42/44] [D loss: 0.004704] [G loss: -0.010600]\n",
      "[Epoch 164/200] [Batch 0/44] [D loss: 0.007745] [G loss: -0.010609]\n",
      "[Epoch 164/200] [Batch 2/44] [D loss: 0.006860] [G loss: -0.010624]\n",
      "[Epoch 164/200] [Batch 4/44] [D loss: 0.006446] [G loss: -0.010618]\n",
      "[Epoch 164/200] [Batch 6/44] [D loss: 0.005642] [G loss: -0.010613]\n",
      "[Epoch 164/200] [Batch 8/44] [D loss: 0.006710] [G loss: -0.010615]\n",
      "[Epoch 164/200] [Batch 10/44] [D loss: 0.006486] [G loss: -0.010611]\n",
      "[Epoch 164/200] [Batch 12/44] [D loss: 0.006304] [G loss: -0.010622]\n",
      "[Epoch 164/200] [Batch 14/44] [D loss: 0.005747] [G loss: -0.010610]\n",
      "[Epoch 164/200] [Batch 16/44] [D loss: 0.006182] [G loss: -0.010607]\n",
      "[Epoch 164/200] [Batch 18/44] [D loss: 0.007111] [G loss: -0.010625]\n",
      "[Epoch 164/200] [Batch 20/44] [D loss: 0.006454] [G loss: -0.010614]\n",
      "[Epoch 164/200] [Batch 22/44] [D loss: 0.007442] [G loss: -0.010651]\n",
      "[Epoch 164/200] [Batch 24/44] [D loss: 0.004321] [G loss: -0.010605]\n",
      "[Epoch 164/200] [Batch 26/44] [D loss: 0.005987] [G loss: -0.010609]\n",
      "[Epoch 164/200] [Batch 28/44] [D loss: 0.003705] [G loss: -0.010628]\n",
      "[Epoch 164/200] [Batch 30/44] [D loss: 0.004120] [G loss: -0.010621]\n",
      "[Epoch 164/200] [Batch 32/44] [D loss: 0.005294] [G loss: -0.010627]\n",
      "[Epoch 164/200] [Batch 34/44] [D loss: 0.004603] [G loss: -0.010634]\n",
      "[Epoch 164/200] [Batch 36/44] [D loss: 0.002731] [G loss: -0.010626]\n",
      "[Epoch 164/200] [Batch 38/44] [D loss: 0.007016] [G loss: -0.010626]\n",
      "[Epoch 164/200] [Batch 40/44] [D loss: 0.004803] [G loss: -0.010622]\n",
      "[Epoch 164/200] [Batch 42/44] [D loss: 0.005479] [G loss: -0.010606]\n",
      "[Epoch 165/200] [Batch 0/44] [D loss: 0.006011] [G loss: -0.010610]\n",
      "[Epoch 165/200] [Batch 2/44] [D loss: 0.006071] [G loss: -0.010611]\n",
      "[Epoch 165/200] [Batch 4/44] [D loss: 0.003441] [G loss: -0.010627]\n",
      "[Epoch 165/200] [Batch 6/44] [D loss: 0.006534] [G loss: -0.010625]\n",
      "[Epoch 165/200] [Batch 8/44] [D loss: 0.005936] [G loss: -0.010616]\n",
      "[Epoch 165/200] [Batch 10/44] [D loss: 0.005216] [G loss: -0.010641]\n",
      "[Epoch 165/200] [Batch 12/44] [D loss: 0.005941] [G loss: -0.010613]\n",
      "[Epoch 165/200] [Batch 14/44] [D loss: 0.004882] [G loss: -0.010614]\n",
      "[Epoch 165/200] [Batch 16/44] [D loss: 0.006640] [G loss: -0.010604]\n",
      "[Epoch 165/200] [Batch 18/44] [D loss: 0.006171] [G loss: -0.010625]\n",
      "[Epoch 165/200] [Batch 20/44] [D loss: 0.005340] [G loss: -0.010612]\n",
      "[Epoch 165/200] [Batch 22/44] [D loss: 0.004263] [G loss: -0.010614]\n",
      "[Epoch 165/200] [Batch 24/44] [D loss: 0.005484] [G loss: -0.010638]\n",
      "[Epoch 165/200] [Batch 26/44] [D loss: 0.003839] [G loss: -0.010605]\n",
      "[Epoch 165/200] [Batch 28/44] [D loss: 0.006565] [G loss: -0.010615]\n",
      "[Epoch 165/200] [Batch 30/44] [D loss: 0.005816] [G loss: -0.010641]\n",
      "[Epoch 165/200] [Batch 32/44] [D loss: 0.006523] [G loss: -0.010623]\n",
      "[Epoch 165/200] [Batch 34/44] [D loss: 0.003896] [G loss: -0.010610]\n",
      "[Epoch 165/200] [Batch 36/44] [D loss: 0.006043] [G loss: -0.010621]\n",
      "[Epoch 165/200] [Batch 38/44] [D loss: 0.007247] [G loss: -0.010639]\n",
      "[Epoch 165/200] [Batch 40/44] [D loss: 0.003980] [G loss: -0.010615]\n",
      "[Epoch 165/200] [Batch 42/44] [D loss: 0.005115] [G loss: -0.010603]\n",
      "[Epoch 166/200] [Batch 0/44] [D loss: 0.006045] [G loss: -0.010614]\n",
      "[Epoch 166/200] [Batch 2/44] [D loss: 0.004027] [G loss: -0.010620]\n",
      "[Epoch 166/200] [Batch 4/44] [D loss: 0.006447] [G loss: -0.010630]\n",
      "[Epoch 166/200] [Batch 6/44] [D loss: 0.005949] [G loss: -0.010609]\n",
      "[Epoch 166/200] [Batch 8/44] [D loss: 0.006415] [G loss: -0.010616]\n",
      "[Epoch 166/200] [Batch 10/44] [D loss: 0.005608] [G loss: -0.010618]\n",
      "[Epoch 166/200] [Batch 12/44] [D loss: 0.003821] [G loss: -0.010597]\n",
      "[Epoch 166/200] [Batch 14/44] [D loss: 0.005266] [G loss: -0.010626]\n",
      "[Epoch 166/200] [Batch 16/44] [D loss: 0.005628] [G loss: -0.010606]\n",
      "[Epoch 166/200] [Batch 18/44] [D loss: 0.006135] [G loss: -0.010653]\n",
      "[Epoch 166/200] [Batch 20/44] [D loss: 0.005512] [G loss: -0.010633]\n",
      "[Epoch 166/200] [Batch 22/44] [D loss: 0.005434] [G loss: -0.010636]\n",
      "[Epoch 166/200] [Batch 24/44] [D loss: 0.006852] [G loss: -0.010640]\n",
      "[Epoch 166/200] [Batch 26/44] [D loss: 0.005561] [G loss: -0.010611]\n",
      "[Epoch 166/200] [Batch 28/44] [D loss: 0.005966] [G loss: -0.010621]\n",
      "[Epoch 166/200] [Batch 30/44] [D loss: 0.005578] [G loss: -0.010625]\n",
      "[Epoch 166/200] [Batch 32/44] [D loss: 0.005585] [G loss: -0.010597]\n",
      "[Epoch 166/200] [Batch 34/44] [D loss: 0.006517] [G loss: -0.010606]\n",
      "[Epoch 166/200] [Batch 36/44] [D loss: 0.007881] [G loss: -0.010613]\n",
      "[Epoch 166/200] [Batch 38/44] [D loss: 0.004510] [G loss: -0.010622]\n",
      "[Epoch 166/200] [Batch 40/44] [D loss: 0.005177] [G loss: -0.010601]\n",
      "[Epoch 166/200] [Batch 42/44] [D loss: 0.006471] [G loss: -0.010624]\n",
      "[Epoch 167/200] [Batch 0/44] [D loss: 0.005208] [G loss: -0.010614]\n",
      "[Epoch 167/200] [Batch 2/44] [D loss: 0.006021] [G loss: -0.010620]\n",
      "[Epoch 167/200] [Batch 4/44] [D loss: 0.004612] [G loss: -0.010616]\n",
      "[Epoch 167/200] [Batch 6/44] [D loss: 0.003398] [G loss: -0.010637]\n",
      "[Epoch 167/200] [Batch 8/44] [D loss: 0.005438] [G loss: -0.010610]\n",
      "[Epoch 167/200] [Batch 10/44] [D loss: 0.006375] [G loss: -0.010600]\n",
      "[Epoch 167/200] [Batch 12/44] [D loss: 0.005249] [G loss: -0.010617]\n",
      "[Epoch 167/200] [Batch 14/44] [D loss: 0.003876] [G loss: -0.010623]\n",
      "[Epoch 167/200] [Batch 16/44] [D loss: 0.007731] [G loss: -0.010614]\n",
      "[Epoch 167/200] [Batch 18/44] [D loss: 0.004328] [G loss: -0.010598]\n",
      "[Epoch 167/200] [Batch 20/44] [D loss: 0.005330] [G loss: -0.010627]\n",
      "[Epoch 167/200] [Batch 22/44] [D loss: 0.005376] [G loss: -0.010618]\n",
      "[Epoch 167/200] [Batch 24/44] [D loss: 0.005423] [G loss: -0.010609]\n",
      "[Epoch 167/200] [Batch 26/44] [D loss: 0.004378] [G loss: -0.010615]\n",
      "[Epoch 167/200] [Batch 28/44] [D loss: 0.006468] [G loss: -0.010606]\n",
      "[Epoch 167/200] [Batch 30/44] [D loss: 0.006601] [G loss: -0.010614]\n",
      "[Epoch 167/200] [Batch 32/44] [D loss: 0.006029] [G loss: -0.010613]\n",
      "[Epoch 167/200] [Batch 34/44] [D loss: 0.005402] [G loss: -0.010609]\n",
      "[Epoch 167/200] [Batch 36/44] [D loss: 0.006005] [G loss: -0.010646]\n",
      "[Epoch 167/200] [Batch 38/44] [D loss: 0.004814] [G loss: -0.010618]\n",
      "[Epoch 167/200] [Batch 40/44] [D loss: 0.004926] [G loss: -0.010607]\n",
      "[Epoch 167/200] [Batch 42/44] [D loss: 0.006741] [G loss: -0.010643]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 168/200] [Batch 0/44] [D loss: 0.004811] [G loss: -0.010627]\n",
      "[Epoch 168/200] [Batch 2/44] [D loss: 0.005406] [G loss: -0.010600]\n",
      "[Epoch 168/200] [Batch 4/44] [D loss: 0.004622] [G loss: -0.010624]\n",
      "[Epoch 168/200] [Batch 6/44] [D loss: 0.007842] [G loss: -0.010632]\n",
      "[Epoch 168/200] [Batch 8/44] [D loss: 0.004727] [G loss: -0.010621]\n",
      "[Epoch 168/200] [Batch 10/44] [D loss: 0.006327] [G loss: -0.010634]\n",
      "[Epoch 168/200] [Batch 12/44] [D loss: 0.006850] [G loss: -0.010620]\n",
      "[Epoch 168/200] [Batch 14/44] [D loss: 0.003051] [G loss: -0.010616]\n",
      "[Epoch 168/200] [Batch 16/44] [D loss: 0.006828] [G loss: -0.010632]\n",
      "[Epoch 168/200] [Batch 18/44] [D loss: 0.003980] [G loss: -0.010609]\n",
      "[Epoch 168/200] [Batch 20/44] [D loss: 0.005078] [G loss: -0.010615]\n",
      "[Epoch 168/200] [Batch 22/44] [D loss: 0.005200] [G loss: -0.010633]\n",
      "[Epoch 168/200] [Batch 24/44] [D loss: 0.005819] [G loss: -0.010602]\n",
      "[Epoch 168/200] [Batch 26/44] [D loss: 0.004392] [G loss: -0.010642]\n",
      "[Epoch 168/200] [Batch 28/44] [D loss: 0.005017] [G loss: -0.010607]\n",
      "[Epoch 168/200] [Batch 30/44] [D loss: 0.006234] [G loss: -0.010618]\n",
      "[Epoch 168/200] [Batch 32/44] [D loss: 0.005759] [G loss: -0.010607]\n",
      "[Epoch 168/200] [Batch 34/44] [D loss: 0.005267] [G loss: -0.010623]\n",
      "[Epoch 168/200] [Batch 36/44] [D loss: 0.005736] [G loss: -0.010635]\n",
      "[Epoch 168/200] [Batch 38/44] [D loss: 0.005746] [G loss: -0.010610]\n",
      "[Epoch 168/200] [Batch 40/44] [D loss: 0.005782] [G loss: -0.010616]\n",
      "[Epoch 168/200] [Batch 42/44] [D loss: 0.005728] [G loss: -0.010617]\n",
      "[Epoch 169/200] [Batch 0/44] [D loss: 0.005855] [G loss: -0.010628]\n",
      "[Epoch 169/200] [Batch 2/44] [D loss: 0.006097] [G loss: -0.010623]\n",
      "[Epoch 169/200] [Batch 4/44] [D loss: 0.006467] [G loss: -0.010617]\n",
      "[Epoch 169/200] [Batch 6/44] [D loss: 0.005524] [G loss: -0.010623]\n",
      "[Epoch 169/200] [Batch 8/44] [D loss: 0.005711] [G loss: -0.010635]\n",
      "[Epoch 169/200] [Batch 10/44] [D loss: 0.004064] [G loss: -0.010610]\n",
      "[Epoch 169/200] [Batch 12/44] [D loss: 0.006059] [G loss: -0.010615]\n",
      "[Epoch 169/200] [Batch 14/44] [D loss: 0.006185] [G loss: -0.010633]\n",
      "[Epoch 169/200] [Batch 16/44] [D loss: 0.006681] [G loss: -0.010608]\n",
      "[Epoch 169/200] [Batch 18/44] [D loss: 0.001979] [G loss: -0.010626]\n",
      "[Epoch 169/200] [Batch 20/44] [D loss: 0.003364] [G loss: -0.010639]\n",
      "[Epoch 169/200] [Batch 22/44] [D loss: 0.006312] [G loss: -0.010633]\n",
      "[Epoch 169/200] [Batch 24/44] [D loss: 0.005207] [G loss: -0.010635]\n",
      "[Epoch 169/200] [Batch 26/44] [D loss: 0.006486] [G loss: -0.010624]\n",
      "[Epoch 169/200] [Batch 28/44] [D loss: 0.005581] [G loss: -0.010601]\n",
      "[Epoch 169/200] [Batch 30/44] [D loss: 0.004732] [G loss: -0.010608]\n",
      "[Epoch 169/200] [Batch 32/44] [D loss: 0.006458] [G loss: -0.010629]\n",
      "[Epoch 169/200] [Batch 34/44] [D loss: 0.008006] [G loss: -0.010619]\n",
      "[Epoch 169/200] [Batch 36/44] [D loss: 0.006131] [G loss: -0.010606]\n",
      "[Epoch 169/200] [Batch 38/44] [D loss: 0.005968] [G loss: -0.010591]\n",
      "[Epoch 169/200] [Batch 40/44] [D loss: 0.005363] [G loss: -0.010630]\n",
      "[Epoch 169/200] [Batch 42/44] [D loss: 0.005510] [G loss: -0.010638]\n",
      "[Epoch 170/200] [Batch 0/44] [D loss: 0.006344] [G loss: -0.010599]\n",
      "[Epoch 170/200] [Batch 2/44] [D loss: 0.006216] [G loss: -0.010626]\n",
      "[Epoch 170/200] [Batch 4/44] [D loss: 0.004504] [G loss: -0.010602]\n",
      "[Epoch 170/200] [Batch 6/44] [D loss: 0.005757] [G loss: -0.010626]\n",
      "[Epoch 170/200] [Batch 8/44] [D loss: 0.006695] [G loss: -0.010615]\n",
      "[Epoch 170/200] [Batch 10/44] [D loss: 0.004722] [G loss: -0.010618]\n",
      "[Epoch 170/200] [Batch 12/44] [D loss: 0.005815] [G loss: -0.010614]\n",
      "[Epoch 170/200] [Batch 14/44] [D loss: 0.007353] [G loss: -0.010622]\n",
      "[Epoch 170/200] [Batch 16/44] [D loss: 0.005406] [G loss: -0.010621]\n",
      "[Epoch 170/200] [Batch 18/44] [D loss: 0.005971] [G loss: -0.010614]\n",
      "[Epoch 170/200] [Batch 20/44] [D loss: 0.004780] [G loss: -0.010622]\n",
      "[Epoch 170/200] [Batch 22/44] [D loss: 0.005914] [G loss: -0.010640]\n",
      "[Epoch 170/200] [Batch 24/44] [D loss: 0.005880] [G loss: -0.010625]\n",
      "[Epoch 170/200] [Batch 26/44] [D loss: 0.004609] [G loss: -0.010605]\n",
      "[Epoch 170/200] [Batch 28/44] [D loss: 0.005971] [G loss: -0.010631]\n",
      "[Epoch 170/200] [Batch 30/44] [D loss: 0.003689] [G loss: -0.010626]\n",
      "[Epoch 170/200] [Batch 32/44] [D loss: 0.005869] [G loss: -0.010611]\n",
      "[Epoch 170/200] [Batch 34/44] [D loss: 0.005893] [G loss: -0.010611]\n",
      "[Epoch 170/200] [Batch 36/44] [D loss: 0.003663] [G loss: -0.010624]\n",
      "[Epoch 170/200] [Batch 38/44] [D loss: 0.005069] [G loss: -0.010625]\n",
      "[Epoch 170/200] [Batch 40/44] [D loss: 0.004559] [G loss: -0.010630]\n",
      "[Epoch 170/200] [Batch 42/44] [D loss: 0.005421] [G loss: -0.010610]\n",
      "[Epoch 171/200] [Batch 0/44] [D loss: 0.004432] [G loss: -0.010624]\n",
      "[Epoch 171/200] [Batch 2/44] [D loss: 0.005779] [G loss: -0.010614]\n",
      "[Epoch 171/200] [Batch 4/44] [D loss: 0.005308] [G loss: -0.010610]\n",
      "[Epoch 171/200] [Batch 6/44] [D loss: 0.006174] [G loss: -0.010627]\n",
      "[Epoch 171/200] [Batch 8/44] [D loss: 0.005075] [G loss: -0.010618]\n",
      "[Epoch 171/200] [Batch 10/44] [D loss: 0.005250] [G loss: -0.010626]\n",
      "[Epoch 171/200] [Batch 12/44] [D loss: 0.006422] [G loss: -0.010613]\n",
      "[Epoch 171/200] [Batch 14/44] [D loss: 0.004760] [G loss: -0.010601]\n",
      "[Epoch 171/200] [Batch 16/44] [D loss: 0.005786] [G loss: -0.010627]\n",
      "[Epoch 171/200] [Batch 18/44] [D loss: 0.006879] [G loss: -0.010623]\n",
      "[Epoch 171/200] [Batch 20/44] [D loss: 0.003214] [G loss: -0.010612]\n",
      "[Epoch 171/200] [Batch 22/44] [D loss: 0.006517] [G loss: -0.010639]\n",
      "[Epoch 171/200] [Batch 24/44] [D loss: 0.004880] [G loss: -0.010604]\n",
      "[Epoch 171/200] [Batch 26/44] [D loss: 0.005216] [G loss: -0.010615]\n",
      "[Epoch 171/200] [Batch 28/44] [D loss: 0.006162] [G loss: -0.010619]\n",
      "[Epoch 171/200] [Batch 30/44] [D loss: 0.007126] [G loss: -0.010605]\n",
      "[Epoch 171/200] [Batch 32/44] [D loss: 0.004998] [G loss: -0.010625]\n",
      "[Epoch 171/200] [Batch 34/44] [D loss: 0.007806] [G loss: -0.010632]\n",
      "[Epoch 171/200] [Batch 36/44] [D loss: 0.005445] [G loss: -0.010630]\n",
      "[Epoch 171/200] [Batch 38/44] [D loss: 0.004895] [G loss: -0.010616]\n",
      "[Epoch 171/200] [Batch 40/44] [D loss: 0.003951] [G loss: -0.010611]\n",
      "[Epoch 171/200] [Batch 42/44] [D loss: 0.006897] [G loss: -0.010619]\n",
      "[Epoch 172/200] [Batch 0/44] [D loss: 0.004187] [G loss: -0.010616]\n",
      "[Epoch 172/200] [Batch 2/44] [D loss: 0.004897] [G loss: -0.010617]\n",
      "[Epoch 172/200] [Batch 4/44] [D loss: 0.004948] [G loss: -0.010628]\n",
      "[Epoch 172/200] [Batch 6/44] [D loss: 0.004225] [G loss: -0.010647]\n",
      "[Epoch 172/200] [Batch 8/44] [D loss: 0.006101] [G loss: -0.010607]\n",
      "[Epoch 172/200] [Batch 10/44] [D loss: 0.003801] [G loss: -0.010599]\n",
      "[Epoch 172/200] [Batch 12/44] [D loss: 0.007076] [G loss: -0.010615]\n",
      "[Epoch 172/200] [Batch 14/44] [D loss: 0.007133] [G loss: -0.010646]\n",
      "[Epoch 172/200] [Batch 16/44] [D loss: 0.005529] [G loss: -0.010634]\n",
      "[Epoch 172/200] [Batch 18/44] [D loss: 0.007670] [G loss: -0.010619]\n",
      "[Epoch 172/200] [Batch 20/44] [D loss: 0.005858] [G loss: -0.010621]\n",
      "[Epoch 172/200] [Batch 22/44] [D loss: 0.006395] [G loss: -0.010615]\n",
      "[Epoch 172/200] [Batch 24/44] [D loss: 0.005941] [G loss: -0.010615]\n",
      "[Epoch 172/200] [Batch 26/44] [D loss: 0.006355] [G loss: -0.010617]\n",
      "[Epoch 172/200] [Batch 28/44] [D loss: 0.005470] [G loss: -0.010611]\n",
      "[Epoch 172/200] [Batch 30/44] [D loss: 0.003511] [G loss: -0.010620]\n",
      "[Epoch 172/200] [Batch 32/44] [D loss: 0.006550] [G loss: -0.010629]\n",
      "[Epoch 172/200] [Batch 34/44] [D loss: 0.003982] [G loss: -0.010617]\n",
      "[Epoch 172/200] [Batch 36/44] [D loss: 0.006008] [G loss: -0.010618]\n",
      "[Epoch 172/200] [Batch 38/44] [D loss: 0.003966] [G loss: -0.010607]\n",
      "[Epoch 172/200] [Batch 40/44] [D loss: 0.008290] [G loss: -0.010615]\n",
      "[Epoch 172/200] [Batch 42/44] [D loss: 0.005364] [G loss: -0.010630]\n",
      "[Epoch 173/200] [Batch 0/44] [D loss: 0.004825] [G loss: -0.010621]\n",
      "[Epoch 173/200] [Batch 2/44] [D loss: 0.007309] [G loss: -0.010607]\n",
      "[Epoch 173/200] [Batch 4/44] [D loss: 0.003364] [G loss: -0.010611]\n",
      "[Epoch 173/200] [Batch 6/44] [D loss: 0.005717] [G loss: -0.010619]\n",
      "[Epoch 173/200] [Batch 8/44] [D loss: 0.004568] [G loss: -0.010590]\n",
      "[Epoch 173/200] [Batch 10/44] [D loss: 0.004821] [G loss: -0.010650]\n",
      "[Epoch 173/200] [Batch 12/44] [D loss: 0.005047] [G loss: -0.010627]\n",
      "[Epoch 173/200] [Batch 14/44] [D loss: 0.006468] [G loss: -0.010615]\n",
      "[Epoch 173/200] [Batch 16/44] [D loss: 0.006807] [G loss: -0.010599]\n",
      "[Epoch 173/200] [Batch 18/44] [D loss: 0.005411] [G loss: -0.010588]\n",
      "[Epoch 173/200] [Batch 20/44] [D loss: 0.005862] [G loss: -0.010608]\n",
      "[Epoch 173/200] [Batch 22/44] [D loss: 0.005357] [G loss: -0.010622]\n",
      "[Epoch 173/200] [Batch 24/44] [D loss: 0.006105] [G loss: -0.010613]\n",
      "[Epoch 173/200] [Batch 26/44] [D loss: 0.005871] [G loss: -0.010597]\n",
      "[Epoch 173/200] [Batch 28/44] [D loss: 0.005864] [G loss: -0.010627]\n",
      "[Epoch 173/200] [Batch 30/44] [D loss: 0.006999] [G loss: -0.010611]\n",
      "[Epoch 173/200] [Batch 32/44] [D loss: 0.007069] [G loss: -0.010620]\n",
      "[Epoch 173/200] [Batch 34/44] [D loss: 0.004930] [G loss: -0.010606]\n",
      "[Epoch 173/200] [Batch 36/44] [D loss: 0.004763] [G loss: -0.010619]\n",
      "[Epoch 173/200] [Batch 38/44] [D loss: 0.004621] [G loss: -0.010621]\n",
      "[Epoch 173/200] [Batch 40/44] [D loss: 0.006226] [G loss: -0.010611]\n",
      "[Epoch 173/200] [Batch 42/44] [D loss: 0.004904] [G loss: -0.010591]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 174/200] [Batch 0/44] [D loss: 0.005906] [G loss: -0.010616]\n",
      "[Epoch 174/200] [Batch 2/44] [D loss: 0.005982] [G loss: -0.010611]\n",
      "[Epoch 174/200] [Batch 4/44] [D loss: 0.006296] [G loss: -0.010605]\n",
      "[Epoch 174/200] [Batch 6/44] [D loss: 0.005978] [G loss: -0.010596]\n",
      "[Epoch 174/200] [Batch 8/44] [D loss: 0.005763] [G loss: -0.010610]\n",
      "[Epoch 174/200] [Batch 10/44] [D loss: 0.005526] [G loss: -0.010633]\n",
      "[Epoch 174/200] [Batch 12/44] [D loss: 0.005799] [G loss: -0.010627]\n",
      "[Epoch 174/200] [Batch 14/44] [D loss: 0.005675] [G loss: -0.010616]\n",
      "[Epoch 174/200] [Batch 16/44] [D loss: 0.005548] [G loss: -0.010607]\n",
      "[Epoch 174/200] [Batch 18/44] [D loss: 0.006840] [G loss: -0.010597]\n",
      "[Epoch 174/200] [Batch 20/44] [D loss: 0.004627] [G loss: -0.010631]\n",
      "[Epoch 174/200] [Batch 22/44] [D loss: 0.003928] [G loss: -0.010608]\n",
      "[Epoch 174/200] [Batch 24/44] [D loss: 0.004060] [G loss: -0.010629]\n",
      "[Epoch 174/200] [Batch 26/44] [D loss: 0.006300] [G loss: -0.010631]\n",
      "[Epoch 174/200] [Batch 28/44] [D loss: 0.004852] [G loss: -0.010617]\n",
      "[Epoch 174/200] [Batch 30/44] [D loss: 0.005380] [G loss: -0.010641]\n",
      "[Epoch 174/200] [Batch 32/44] [D loss: 0.005370] [G loss: -0.010614]\n",
      "[Epoch 174/200] [Batch 34/44] [D loss: 0.003852] [G loss: -0.010629]\n",
      "[Epoch 174/200] [Batch 36/44] [D loss: 0.005968] [G loss: -0.010616]\n",
      "[Epoch 174/200] [Batch 38/44] [D loss: 0.005567] [G loss: -0.010616]\n",
      "[Epoch 174/200] [Batch 40/44] [D loss: 0.007352] [G loss: -0.010609]\n",
      "[Epoch 174/200] [Batch 42/44] [D loss: 0.006100] [G loss: -0.010612]\n",
      "[Epoch 175/200] [Batch 0/44] [D loss: 0.005238] [G loss: -0.010660]\n",
      "[Epoch 175/200] [Batch 2/44] [D loss: 0.003054] [G loss: -0.010581]\n",
      "[Epoch 175/200] [Batch 4/44] [D loss: 0.006781] [G loss: -0.010619]\n",
      "[Epoch 175/200] [Batch 6/44] [D loss: 0.007026] [G loss: -0.010642]\n",
      "[Epoch 175/200] [Batch 8/44] [D loss: 0.003477] [G loss: -0.010607]\n",
      "[Epoch 175/200] [Batch 10/44] [D loss: 0.007112] [G loss: -0.010614]\n",
      "[Epoch 175/200] [Batch 12/44] [D loss: 0.006323] [G loss: -0.010613]\n",
      "[Epoch 175/200] [Batch 14/44] [D loss: 0.005607] [G loss: -0.010602]\n",
      "[Epoch 175/200] [Batch 16/44] [D loss: 0.004587] [G loss: -0.010615]\n",
      "[Epoch 175/200] [Batch 18/44] [D loss: 0.006536] [G loss: -0.010606]\n",
      "[Epoch 175/200] [Batch 20/44] [D loss: 0.006643] [G loss: -0.010582]\n",
      "[Epoch 175/200] [Batch 22/44] [D loss: 0.005140] [G loss: -0.010590]\n",
      "[Epoch 175/200] [Batch 24/44] [D loss: 0.006539] [G loss: -0.010620]\n",
      "[Epoch 175/200] [Batch 26/44] [D loss: 0.005280] [G loss: -0.010621]\n",
      "[Epoch 175/200] [Batch 28/44] [D loss: 0.006858] [G loss: -0.010637]\n",
      "[Epoch 175/200] [Batch 30/44] [D loss: 0.006170] [G loss: -0.010607]\n",
      "[Epoch 175/200] [Batch 32/44] [D loss: 0.006341] [G loss: -0.010595]\n",
      "[Epoch 175/200] [Batch 34/44] [D loss: 0.005120] [G loss: -0.010614]\n",
      "[Epoch 175/200] [Batch 36/44] [D loss: 0.003910] [G loss: -0.010611]\n",
      "[Epoch 175/200] [Batch 38/44] [D loss: 0.006613] [G loss: -0.010597]\n",
      "[Epoch 175/200] [Batch 40/44] [D loss: 0.005509] [G loss: -0.010623]\n",
      "[Epoch 175/200] [Batch 42/44] [D loss: 0.005697] [G loss: -0.010644]\n",
      "[Epoch 176/200] [Batch 0/44] [D loss: 0.005888] [G loss: -0.010623]\n",
      "[Epoch 176/200] [Batch 2/44] [D loss: 0.005631] [G loss: -0.010606]\n",
      "[Epoch 176/200] [Batch 4/44] [D loss: 0.004809] [G loss: -0.010606]\n",
      "[Epoch 176/200] [Batch 6/44] [D loss: 0.004541] [G loss: -0.010599]\n",
      "[Epoch 176/200] [Batch 8/44] [D loss: 0.006659] [G loss: -0.010619]\n",
      "[Epoch 176/200] [Batch 10/44] [D loss: 0.003964] [G loss: -0.010611]\n",
      "[Epoch 176/200] [Batch 12/44] [D loss: 0.005261] [G loss: -0.010624]\n",
      "[Epoch 176/200] [Batch 14/44] [D loss: 0.007590] [G loss: -0.010626]\n",
      "[Epoch 176/200] [Batch 16/44] [D loss: 0.005295] [G loss: -0.010617]\n",
      "[Epoch 176/200] [Batch 18/44] [D loss: 0.004023] [G loss: -0.010618]\n",
      "[Epoch 176/200] [Batch 20/44] [D loss: 0.005601] [G loss: -0.010617]\n",
      "[Epoch 176/200] [Batch 22/44] [D loss: 0.006431] [G loss: -0.010610]\n",
      "[Epoch 176/200] [Batch 24/44] [D loss: 0.005388] [G loss: -0.010622]\n",
      "[Epoch 176/200] [Batch 26/44] [D loss: 0.004578] [G loss: -0.010607]\n",
      "[Epoch 176/200] [Batch 28/44] [D loss: 0.006025] [G loss: -0.010618]\n",
      "[Epoch 176/200] [Batch 30/44] [D loss: 0.004481] [G loss: -0.010613]\n",
      "[Epoch 176/200] [Batch 32/44] [D loss: 0.004147] [G loss: -0.010605]\n",
      "[Epoch 176/200] [Batch 34/44] [D loss: 0.004583] [G loss: -0.010626]\n",
      "[Epoch 176/200] [Batch 36/44] [D loss: 0.005708] [G loss: -0.010608]\n",
      "[Epoch 176/200] [Batch 38/44] [D loss: 0.003839] [G loss: -0.010605]\n",
      "[Epoch 176/200] [Batch 40/44] [D loss: 0.004974] [G loss: -0.010622]\n",
      "[Epoch 176/200] [Batch 42/44] [D loss: 0.004186] [G loss: -0.010610]\n",
      "[Epoch 177/200] [Batch 0/44] [D loss: 0.005942] [G loss: -0.010614]\n",
      "[Epoch 177/200] [Batch 2/44] [D loss: 0.004691] [G loss: -0.010610]\n",
      "[Epoch 177/200] [Batch 4/44] [D loss: 0.006941] [G loss: -0.010610]\n",
      "[Epoch 177/200] [Batch 6/44] [D loss: 0.007540] [G loss: -0.010643]\n",
      "[Epoch 177/200] [Batch 8/44] [D loss: 0.006551] [G loss: -0.010622]\n",
      "[Epoch 177/200] [Batch 10/44] [D loss: 0.003564] [G loss: -0.010631]\n",
      "[Epoch 177/200] [Batch 12/44] [D loss: 0.008401] [G loss: -0.010609]\n",
      "[Epoch 177/200] [Batch 14/44] [D loss: 0.007670] [G loss: -0.010612]\n",
      "[Epoch 177/200] [Batch 16/44] [D loss: 0.006053] [G loss: -0.010616]\n",
      "[Epoch 177/200] [Batch 18/44] [D loss: 0.004832] [G loss: -0.010622]\n",
      "[Epoch 177/200] [Batch 20/44] [D loss: 0.005145] [G loss: -0.010607]\n",
      "[Epoch 177/200] [Batch 22/44] [D loss: 0.004550] [G loss: -0.010620]\n",
      "[Epoch 177/200] [Batch 24/44] [D loss: 0.005442] [G loss: -0.010608]\n",
      "[Epoch 177/200] [Batch 26/44] [D loss: 0.004954] [G loss: -0.010612]\n",
      "[Epoch 177/200] [Batch 28/44] [D loss: 0.006821] [G loss: -0.010611]\n",
      "[Epoch 177/200] [Batch 30/44] [D loss: 0.004624] [G loss: -0.010617]\n",
      "[Epoch 177/200] [Batch 32/44] [D loss: 0.004770] [G loss: -0.010618]\n",
      "[Epoch 177/200] [Batch 34/44] [D loss: 0.006851] [G loss: -0.010617]\n",
      "[Epoch 177/200] [Batch 36/44] [D loss: 0.003926] [G loss: -0.010632]\n",
      "[Epoch 177/200] [Batch 38/44] [D loss: 0.004912] [G loss: -0.010604]\n",
      "[Epoch 177/200] [Batch 40/44] [D loss: 0.004086] [G loss: -0.010636]\n",
      "[Epoch 177/200] [Batch 42/44] [D loss: 0.005290] [G loss: -0.010624]\n",
      "[Epoch 178/200] [Batch 0/44] [D loss: 0.004993] [G loss: -0.010633]\n",
      "[Epoch 178/200] [Batch 2/44] [D loss: 0.006137] [G loss: -0.010607]\n",
      "[Epoch 178/200] [Batch 4/44] [D loss: 0.004095] [G loss: -0.010634]\n",
      "[Epoch 178/200] [Batch 6/44] [D loss: 0.005789] [G loss: -0.010617]\n",
      "[Epoch 178/200] [Batch 8/44] [D loss: 0.005093] [G loss: -0.010620]\n",
      "[Epoch 178/200] [Batch 10/44] [D loss: 0.005527] [G loss: -0.010630]\n",
      "[Epoch 178/200] [Batch 12/44] [D loss: 0.005048] [G loss: -0.010618]\n",
      "[Epoch 178/200] [Batch 14/44] [D loss: 0.007711] [G loss: -0.010632]\n",
      "[Epoch 178/200] [Batch 16/44] [D loss: 0.008065] [G loss: -0.010635]\n",
      "[Epoch 178/200] [Batch 18/44] [D loss: 0.004897] [G loss: -0.010626]\n",
      "[Epoch 178/200] [Batch 20/44] [D loss: 0.005989] [G loss: -0.010637]\n",
      "[Epoch 178/200] [Batch 22/44] [D loss: 0.004897] [G loss: -0.010606]\n",
      "[Epoch 178/200] [Batch 24/44] [D loss: 0.004031] [G loss: -0.010587]\n",
      "[Epoch 178/200] [Batch 26/44] [D loss: 0.006379] [G loss: -0.010606]\n",
      "[Epoch 178/200] [Batch 28/44] [D loss: 0.004496] [G loss: -0.010613]\n",
      "[Epoch 178/200] [Batch 30/44] [D loss: 0.004858] [G loss: -0.010628]\n",
      "[Epoch 178/200] [Batch 32/44] [D loss: 0.005793] [G loss: -0.010604]\n",
      "[Epoch 178/200] [Batch 34/44] [D loss: 0.007872] [G loss: -0.010613]\n",
      "[Epoch 178/200] [Batch 36/44] [D loss: 0.006085] [G loss: -0.010612]\n",
      "[Epoch 178/200] [Batch 38/44] [D loss: 0.006725] [G loss: -0.010619]\n",
      "[Epoch 178/200] [Batch 40/44] [D loss: 0.007728] [G loss: -0.010604]\n",
      "[Epoch 178/200] [Batch 42/44] [D loss: 0.005325] [G loss: -0.010620]\n",
      "[Epoch 179/200] [Batch 0/44] [D loss: 0.006937] [G loss: -0.010603]\n",
      "[Epoch 179/200] [Batch 2/44] [D loss: 0.004571] [G loss: -0.010625]\n",
      "[Epoch 179/200] [Batch 4/44] [D loss: 0.005135] [G loss: -0.010591]\n",
      "[Epoch 179/200] [Batch 6/44] [D loss: 0.005667] [G loss: -0.010589]\n",
      "[Epoch 179/200] [Batch 8/44] [D loss: 0.005852] [G loss: -0.010586]\n",
      "[Epoch 179/200] [Batch 10/44] [D loss: 0.002630] [G loss: -0.010600]\n",
      "[Epoch 179/200] [Batch 12/44] [D loss: 0.001917] [G loss: -0.010618]\n",
      "[Epoch 179/200] [Batch 14/44] [D loss: 0.006172] [G loss: -0.010620]\n",
      "[Epoch 179/200] [Batch 16/44] [D loss: 0.006179] [G loss: -0.010645]\n",
      "[Epoch 179/200] [Batch 18/44] [D loss: 0.007078] [G loss: -0.010613]\n",
      "[Epoch 179/200] [Batch 20/44] [D loss: 0.004730] [G loss: -0.010623]\n",
      "[Epoch 179/200] [Batch 22/44] [D loss: 0.008344] [G loss: -0.010620]\n",
      "[Epoch 179/200] [Batch 24/44] [D loss: 0.005659] [G loss: -0.010624]\n",
      "[Epoch 179/200] [Batch 26/44] [D loss: 0.006373] [G loss: -0.010621]\n",
      "[Epoch 179/200] [Batch 28/44] [D loss: 0.005389] [G loss: -0.010612]\n",
      "[Epoch 179/200] [Batch 30/44] [D loss: 0.006285] [G loss: -0.010617]\n",
      "[Epoch 179/200] [Batch 32/44] [D loss: 0.006420] [G loss: -0.010607]\n",
      "[Epoch 179/200] [Batch 34/44] [D loss: 0.007069] [G loss: -0.010585]\n",
      "[Epoch 179/200] [Batch 36/44] [D loss: 0.006042] [G loss: -0.010641]\n",
      "[Epoch 179/200] [Batch 38/44] [D loss: 0.006454] [G loss: -0.010607]\n",
      "[Epoch 179/200] [Batch 40/44] [D loss: 0.003916] [G loss: -0.010617]\n",
      "[Epoch 179/200] [Batch 42/44] [D loss: 0.006300] [G loss: -0.010614]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 180/200] [Batch 0/44] [D loss: 0.004848] [G loss: -0.010616]\n",
      "[Epoch 180/200] [Batch 2/44] [D loss: 0.004516] [G loss: -0.010624]\n",
      "[Epoch 180/200] [Batch 4/44] [D loss: 0.006966] [G loss: -0.010607]\n",
      "[Epoch 180/200] [Batch 6/44] [D loss: 0.005975] [G loss: -0.010603]\n",
      "[Epoch 180/200] [Batch 8/44] [D loss: 0.005291] [G loss: -0.010600]\n",
      "[Epoch 180/200] [Batch 10/44] [D loss: 0.006528] [G loss: -0.010605]\n",
      "[Epoch 180/200] [Batch 12/44] [D loss: 0.004911] [G loss: -0.010631]\n",
      "[Epoch 180/200] [Batch 14/44] [D loss: 0.007831] [G loss: -0.010627]\n",
      "[Epoch 180/200] [Batch 16/44] [D loss: 0.004834] [G loss: -0.010626]\n",
      "[Epoch 180/200] [Batch 18/44] [D loss: 0.005195] [G loss: -0.010614]\n",
      "[Epoch 180/200] [Batch 20/44] [D loss: 0.005993] [G loss: -0.010639]\n",
      "[Epoch 180/200] [Batch 22/44] [D loss: 0.005247] [G loss: -0.010618]\n",
      "[Epoch 180/200] [Batch 24/44] [D loss: 0.004291] [G loss: -0.010625]\n",
      "[Epoch 180/200] [Batch 26/44] [D loss: 0.003858] [G loss: -0.010636]\n",
      "[Epoch 180/200] [Batch 28/44] [D loss: 0.006777] [G loss: -0.010610]\n",
      "[Epoch 180/200] [Batch 30/44] [D loss: 0.005915] [G loss: -0.010612]\n",
      "[Epoch 180/200] [Batch 32/44] [D loss: 0.003058] [G loss: -0.010611]\n",
      "[Epoch 180/200] [Batch 34/44] [D loss: 0.006448] [G loss: -0.010612]\n",
      "[Epoch 180/200] [Batch 36/44] [D loss: 0.006874] [G loss: -0.010610]\n",
      "[Epoch 180/200] [Batch 38/44] [D loss: 0.006159] [G loss: -0.010617]\n",
      "[Epoch 180/200] [Batch 40/44] [D loss: 0.006633] [G loss: -0.010618]\n",
      "[Epoch 180/200] [Batch 42/44] [D loss: 0.006406] [G loss: -0.010607]\n",
      "[Epoch 181/200] [Batch 0/44] [D loss: 0.005119] [G loss: -0.010601]\n",
      "[Epoch 181/200] [Batch 2/44] [D loss: 0.008095] [G loss: -0.010632]\n",
      "[Epoch 181/200] [Batch 4/44] [D loss: 0.003465] [G loss: -0.010603]\n",
      "[Epoch 181/200] [Batch 6/44] [D loss: 0.005672] [G loss: -0.010623]\n",
      "[Epoch 181/200] [Batch 8/44] [D loss: 0.005352] [G loss: -0.010612]\n",
      "[Epoch 181/200] [Batch 10/44] [D loss: 0.004900] [G loss: -0.010627]\n",
      "[Epoch 181/200] [Batch 12/44] [D loss: 0.006227] [G loss: -0.010620]\n",
      "[Epoch 181/200] [Batch 14/44] [D loss: 0.006410] [G loss: -0.010611]\n",
      "[Epoch 181/200] [Batch 16/44] [D loss: 0.007074] [G loss: -0.010603]\n",
      "[Epoch 181/200] [Batch 18/44] [D loss: 0.004765] [G loss: -0.010639]\n",
      "[Epoch 181/200] [Batch 20/44] [D loss: 0.005487] [G loss: -0.010617]\n",
      "[Epoch 181/200] [Batch 22/44] [D loss: 0.006461] [G loss: -0.010624]\n",
      "[Epoch 181/200] [Batch 24/44] [D loss: 0.007034] [G loss: -0.010627]\n",
      "[Epoch 181/200] [Batch 26/44] [D loss: 0.005674] [G loss: -0.010599]\n",
      "[Epoch 181/200] [Batch 28/44] [D loss: 0.005832] [G loss: -0.010634]\n",
      "[Epoch 181/200] [Batch 30/44] [D loss: 0.005101] [G loss: -0.010630]\n",
      "[Epoch 181/200] [Batch 32/44] [D loss: 0.003302] [G loss: -0.010610]\n",
      "[Epoch 181/200] [Batch 34/44] [D loss: 0.005317] [G loss: -0.010607]\n",
      "[Epoch 181/200] [Batch 36/44] [D loss: 0.005915] [G loss: -0.010627]\n",
      "[Epoch 181/200] [Batch 38/44] [D loss: 0.006575] [G loss: -0.010603]\n",
      "[Epoch 181/200] [Batch 40/44] [D loss: 0.006283] [G loss: -0.010629]\n",
      "[Epoch 181/200] [Batch 42/44] [D loss: 0.005461] [G loss: -0.010625]\n",
      "[Epoch 182/200] [Batch 0/44] [D loss: 0.005883] [G loss: -0.010599]\n",
      "[Epoch 182/200] [Batch 2/44] [D loss: 0.006047] [G loss: -0.010629]\n",
      "[Epoch 182/200] [Batch 4/44] [D loss: 0.004724] [G loss: -0.010610]\n",
      "[Epoch 182/200] [Batch 6/44] [D loss: 0.006384] [G loss: -0.010613]\n",
      "[Epoch 182/200] [Batch 8/44] [D loss: 0.004912] [G loss: -0.010628]\n",
      "[Epoch 182/200] [Batch 10/44] [D loss: 0.005211] [G loss: -0.010632]\n",
      "[Epoch 182/200] [Batch 12/44] [D loss: 0.006209] [G loss: -0.010627]\n",
      "[Epoch 182/200] [Batch 14/44] [D loss: 0.005874] [G loss: -0.010617]\n",
      "[Epoch 182/200] [Batch 16/44] [D loss: 0.007882] [G loss: -0.010611]\n",
      "[Epoch 182/200] [Batch 18/44] [D loss: 0.006176] [G loss: -0.010635]\n",
      "[Epoch 182/200] [Batch 20/44] [D loss: 0.005595] [G loss: -0.010602]\n",
      "[Epoch 182/200] [Batch 22/44] [D loss: 0.006961] [G loss: -0.010616]\n",
      "[Epoch 182/200] [Batch 24/44] [D loss: 0.006684] [G loss: -0.010623]\n",
      "[Epoch 182/200] [Batch 26/44] [D loss: 0.007161] [G loss: -0.010604]\n",
      "[Epoch 182/200] [Batch 28/44] [D loss: 0.006398] [G loss: -0.010633]\n",
      "[Epoch 182/200] [Batch 30/44] [D loss: 0.006202] [G loss: -0.010617]\n",
      "[Epoch 182/200] [Batch 32/44] [D loss: 0.005297] [G loss: -0.010622]\n",
      "[Epoch 182/200] [Batch 34/44] [D loss: 0.005882] [G loss: -0.010594]\n",
      "[Epoch 182/200] [Batch 36/44] [D loss: 0.005840] [G loss: -0.010625]\n",
      "[Epoch 182/200] [Batch 38/44] [D loss: 0.005430] [G loss: -0.010618]\n",
      "[Epoch 182/200] [Batch 40/44] [D loss: 0.005540] [G loss: -0.010600]\n",
      "[Epoch 182/200] [Batch 42/44] [D loss: 0.006570] [G loss: -0.010640]\n",
      "[Epoch 183/200] [Batch 0/44] [D loss: 0.006688] [G loss: -0.010636]\n",
      "[Epoch 183/200] [Batch 2/44] [D loss: 0.005217] [G loss: -0.010615]\n",
      "[Epoch 183/200] [Batch 4/44] [D loss: 0.005827] [G loss: -0.010606]\n",
      "[Epoch 183/200] [Batch 6/44] [D loss: 0.004745] [G loss: -0.010611]\n",
      "[Epoch 183/200] [Batch 8/44] [D loss: 0.005257] [G loss: -0.010623]\n",
      "[Epoch 183/200] [Batch 10/44] [D loss: 0.004371] [G loss: -0.010590]\n",
      "[Epoch 183/200] [Batch 12/44] [D loss: 0.004352] [G loss: -0.010611]\n",
      "[Epoch 183/200] [Batch 14/44] [D loss: 0.007788] [G loss: -0.010613]\n",
      "[Epoch 183/200] [Batch 16/44] [D loss: 0.006486] [G loss: -0.010604]\n",
      "[Epoch 183/200] [Batch 18/44] [D loss: 0.005691] [G loss: -0.010610]\n",
      "[Epoch 183/200] [Batch 20/44] [D loss: 0.005433] [G loss: -0.010634]\n",
      "[Epoch 183/200] [Batch 22/44] [D loss: 0.005424] [G loss: -0.010622]\n",
      "[Epoch 183/200] [Batch 24/44] [D loss: 0.005209] [G loss: -0.010623]\n",
      "[Epoch 183/200] [Batch 26/44] [D loss: 0.005048] [G loss: -0.010599]\n",
      "[Epoch 183/200] [Batch 28/44] [D loss: 0.003968] [G loss: -0.010609]\n",
      "[Epoch 183/200] [Batch 30/44] [D loss: 0.005167] [G loss: -0.010624]\n",
      "[Epoch 183/200] [Batch 32/44] [D loss: 0.004494] [G loss: -0.010613]\n",
      "[Epoch 183/200] [Batch 34/44] [D loss: 0.004083] [G loss: -0.010642]\n",
      "[Epoch 183/200] [Batch 36/44] [D loss: 0.004046] [G loss: -0.010624]\n",
      "[Epoch 183/200] [Batch 38/44] [D loss: 0.003583] [G loss: -0.010609]\n",
      "[Epoch 183/200] [Batch 40/44] [D loss: 0.006207] [G loss: -0.010602]\n",
      "[Epoch 183/200] [Batch 42/44] [D loss: 0.005706] [G loss: -0.010588]\n",
      "[Epoch 184/200] [Batch 0/44] [D loss: 0.005856] [G loss: -0.010597]\n",
      "[Epoch 184/200] [Batch 2/44] [D loss: 0.005476] [G loss: -0.010632]\n",
      "[Epoch 184/200] [Batch 4/44] [D loss: 0.003791] [G loss: -0.010630]\n",
      "[Epoch 184/200] [Batch 6/44] [D loss: 0.006322] [G loss: -0.010615]\n",
      "[Epoch 184/200] [Batch 8/44] [D loss: 0.003530] [G loss: -0.010604]\n",
      "[Epoch 184/200] [Batch 10/44] [D loss: 0.004538] [G loss: -0.010607]\n",
      "[Epoch 184/200] [Batch 12/44] [D loss: 0.003699] [G loss: -0.010617]\n",
      "[Epoch 184/200] [Batch 14/44] [D loss: 0.005612] [G loss: -0.010617]\n",
      "[Epoch 184/200] [Batch 16/44] [D loss: 0.006308] [G loss: -0.010621]\n",
      "[Epoch 184/200] [Batch 18/44] [D loss: 0.004687] [G loss: -0.010614]\n",
      "[Epoch 184/200] [Batch 20/44] [D loss: 0.006786] [G loss: -0.010600]\n",
      "[Epoch 184/200] [Batch 22/44] [D loss: 0.005166] [G loss: -0.010615]\n",
      "[Epoch 184/200] [Batch 24/44] [D loss: 0.004478] [G loss: -0.010627]\n",
      "[Epoch 184/200] [Batch 26/44] [D loss: 0.006138] [G loss: -0.010620]\n",
      "[Epoch 184/200] [Batch 28/44] [D loss: 0.004178] [G loss: -0.010619]\n",
      "[Epoch 184/200] [Batch 30/44] [D loss: 0.003829] [G loss: -0.010643]\n",
      "[Epoch 184/200] [Batch 32/44] [D loss: 0.007542] [G loss: -0.010627]\n",
      "[Epoch 184/200] [Batch 34/44] [D loss: 0.005624] [G loss: -0.010646]\n",
      "[Epoch 184/200] [Batch 36/44] [D loss: 0.005551] [G loss: -0.010628]\n",
      "[Epoch 184/200] [Batch 38/44] [D loss: 0.006816] [G loss: -0.010624]\n",
      "[Epoch 184/200] [Batch 40/44] [D loss: 0.004553] [G loss: -0.010612]\n",
      "[Epoch 184/200] [Batch 42/44] [D loss: 0.005895] [G loss: -0.010614]\n",
      "[Epoch 185/200] [Batch 0/44] [D loss: 0.002354] [G loss: -0.010596]\n",
      "[Epoch 185/200] [Batch 2/44] [D loss: 0.005138] [G loss: -0.010628]\n",
      "[Epoch 185/200] [Batch 4/44] [D loss: 0.006387] [G loss: -0.010593]\n",
      "[Epoch 185/200] [Batch 6/44] [D loss: 0.004007] [G loss: -0.010635]\n",
      "[Epoch 185/200] [Batch 8/44] [D loss: 0.006081] [G loss: -0.010599]\n",
      "[Epoch 185/200] [Batch 10/44] [D loss: 0.003759] [G loss: -0.010617]\n",
      "[Epoch 185/200] [Batch 12/44] [D loss: 0.003019] [G loss: -0.010619]\n",
      "[Epoch 185/200] [Batch 14/44] [D loss: 0.005645] [G loss: -0.010626]\n",
      "[Epoch 185/200] [Batch 16/44] [D loss: 0.005893] [G loss: -0.010630]\n",
      "[Epoch 185/200] [Batch 18/44] [D loss: 0.006830] [G loss: -0.010622]\n",
      "[Epoch 185/200] [Batch 20/44] [D loss: 0.004927] [G loss: -0.010618]\n",
      "[Epoch 185/200] [Batch 22/44] [D loss: 0.006815] [G loss: -0.010627]\n",
      "[Epoch 185/200] [Batch 24/44] [D loss: 0.004520] [G loss: -0.010622]\n",
      "[Epoch 185/200] [Batch 26/44] [D loss: 0.004140] [G loss: -0.010610]\n",
      "[Epoch 185/200] [Batch 28/44] [D loss: 0.005203] [G loss: -0.010640]\n",
      "[Epoch 185/200] [Batch 30/44] [D loss: 0.003397] [G loss: -0.010609]\n",
      "[Epoch 185/200] [Batch 32/44] [D loss: 0.006347] [G loss: -0.010605]\n",
      "[Epoch 185/200] [Batch 34/44] [D loss: 0.007361] [G loss: -0.010591]\n",
      "[Epoch 185/200] [Batch 36/44] [D loss: 0.003048] [G loss: -0.010614]\n",
      "[Epoch 185/200] [Batch 38/44] [D loss: 0.006669] [G loss: -0.010635]\n",
      "[Epoch 185/200] [Batch 40/44] [D loss: 0.005224] [G loss: -0.010623]\n",
      "[Epoch 185/200] [Batch 42/44] [D loss: 0.004476] [G loss: -0.010624]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 186/200] [Batch 0/44] [D loss: 0.003978] [G loss: -0.010622]\n",
      "[Epoch 186/200] [Batch 2/44] [D loss: 0.008369] [G loss: -0.010641]\n",
      "[Epoch 186/200] [Batch 4/44] [D loss: 0.006897] [G loss: -0.010620]\n",
      "[Epoch 186/200] [Batch 6/44] [D loss: 0.006356] [G loss: -0.010610]\n",
      "[Epoch 186/200] [Batch 8/44] [D loss: 0.005822] [G loss: -0.010619]\n",
      "[Epoch 186/200] [Batch 10/44] [D loss: 0.004372] [G loss: -0.010615]\n",
      "[Epoch 186/200] [Batch 12/44] [D loss: 0.007288] [G loss: -0.010634]\n",
      "[Epoch 186/200] [Batch 14/44] [D loss: 0.004666] [G loss: -0.010620]\n",
      "[Epoch 186/200] [Batch 16/44] [D loss: 0.005612] [G loss: -0.010597]\n",
      "[Epoch 186/200] [Batch 18/44] [D loss: 0.005370] [G loss: -0.010623]\n",
      "[Epoch 186/200] [Batch 20/44] [D loss: 0.005893] [G loss: -0.010618]\n",
      "[Epoch 186/200] [Batch 22/44] [D loss: 0.006491] [G loss: -0.010626]\n",
      "[Epoch 186/200] [Batch 24/44] [D loss: 0.005747] [G loss: -0.010625]\n",
      "[Epoch 186/200] [Batch 26/44] [D loss: 0.005476] [G loss: -0.010606]\n",
      "[Epoch 186/200] [Batch 28/44] [D loss: 0.005760] [G loss: -0.010614]\n",
      "[Epoch 186/200] [Batch 30/44] [D loss: 0.004988] [G loss: -0.010628]\n",
      "[Epoch 186/200] [Batch 32/44] [D loss: 0.005842] [G loss: -0.010612]\n",
      "[Epoch 186/200] [Batch 34/44] [D loss: 0.006768] [G loss: -0.010636]\n",
      "[Epoch 186/200] [Batch 36/44] [D loss: 0.004142] [G loss: -0.010623]\n",
      "[Epoch 186/200] [Batch 38/44] [D loss: 0.006643] [G loss: -0.010636]\n",
      "[Epoch 186/200] [Batch 40/44] [D loss: 0.005358] [G loss: -0.010599]\n",
      "[Epoch 186/200] [Batch 42/44] [D loss: 0.005684] [G loss: -0.010598]\n",
      "[Epoch 187/200] [Batch 0/44] [D loss: 0.005878] [G loss: -0.010607]\n",
      "[Epoch 187/200] [Batch 2/44] [D loss: 0.007740] [G loss: -0.010626]\n",
      "[Epoch 187/200] [Batch 4/44] [D loss: 0.005148] [G loss: -0.010606]\n",
      "[Epoch 187/200] [Batch 6/44] [D loss: 0.005757] [G loss: -0.010611]\n",
      "[Epoch 187/200] [Batch 8/44] [D loss: 0.004754] [G loss: -0.010614]\n",
      "[Epoch 187/200] [Batch 10/44] [D loss: 0.007862] [G loss: -0.010603]\n",
      "[Epoch 187/200] [Batch 12/44] [D loss: 0.004744] [G loss: -0.010633]\n",
      "[Epoch 187/200] [Batch 14/44] [D loss: 0.007239] [G loss: -0.010610]\n",
      "[Epoch 187/200] [Batch 16/44] [D loss: 0.006491] [G loss: -0.010610]\n",
      "[Epoch 187/200] [Batch 18/44] [D loss: 0.003840] [G loss: -0.010614]\n",
      "[Epoch 187/200] [Batch 20/44] [D loss: 0.006857] [G loss: -0.010616]\n",
      "[Epoch 187/200] [Batch 22/44] [D loss: 0.004443] [G loss: -0.010609]\n",
      "[Epoch 187/200] [Batch 24/44] [D loss: 0.002884] [G loss: -0.010611]\n",
      "[Epoch 187/200] [Batch 26/44] [D loss: 0.005785] [G loss: -0.010620]\n",
      "[Epoch 187/200] [Batch 28/44] [D loss: 0.005701] [G loss: -0.010617]\n",
      "[Epoch 187/200] [Batch 30/44] [D loss: 0.006499] [G loss: -0.010623]\n",
      "[Epoch 187/200] [Batch 32/44] [D loss: 0.006187] [G loss: -0.010613]\n",
      "[Epoch 187/200] [Batch 34/44] [D loss: 0.003851] [G loss: -0.010620]\n",
      "[Epoch 187/200] [Batch 36/44] [D loss: 0.005856] [G loss: -0.010622]\n",
      "[Epoch 187/200] [Batch 38/44] [D loss: 0.005277] [G loss: -0.010602]\n",
      "[Epoch 187/200] [Batch 40/44] [D loss: 0.005284] [G loss: -0.010614]\n",
      "[Epoch 187/200] [Batch 42/44] [D loss: 0.005975] [G loss: -0.010614]\n",
      "[Epoch 188/200] [Batch 0/44] [D loss: 0.006798] [G loss: -0.010613]\n",
      "[Epoch 188/200] [Batch 2/44] [D loss: 0.007457] [G loss: -0.010616]\n",
      "[Epoch 188/200] [Batch 4/44] [D loss: 0.004345] [G loss: -0.010619]\n",
      "[Epoch 188/200] [Batch 6/44] [D loss: 0.003576] [G loss: -0.010608]\n",
      "[Epoch 188/200] [Batch 8/44] [D loss: 0.006637] [G loss: -0.010612]\n",
      "[Epoch 188/200] [Batch 10/44] [D loss: 0.004863] [G loss: -0.010620]\n",
      "[Epoch 188/200] [Batch 12/44] [D loss: 0.004424] [G loss: -0.010629]\n",
      "[Epoch 188/200] [Batch 14/44] [D loss: 0.005719] [G loss: -0.010616]\n",
      "[Epoch 188/200] [Batch 16/44] [D loss: 0.004922] [G loss: -0.010598]\n",
      "[Epoch 188/200] [Batch 18/44] [D loss: 0.006514] [G loss: -0.010619]\n",
      "[Epoch 188/200] [Batch 20/44] [D loss: 0.005011] [G loss: -0.010609]\n",
      "[Epoch 188/200] [Batch 22/44] [D loss: 0.005971] [G loss: -0.010622]\n",
      "[Epoch 188/200] [Batch 24/44] [D loss: 0.005763] [G loss: -0.010611]\n",
      "[Epoch 188/200] [Batch 26/44] [D loss: 0.006173] [G loss: -0.010621]\n",
      "[Epoch 188/200] [Batch 28/44] [D loss: 0.005638] [G loss: -0.010619]\n",
      "[Epoch 188/200] [Batch 30/44] [D loss: 0.006946] [G loss: -0.010610]\n",
      "[Epoch 188/200] [Batch 32/44] [D loss: 0.004012] [G loss: -0.010600]\n",
      "[Epoch 188/200] [Batch 34/44] [D loss: 0.006813] [G loss: -0.010614]\n",
      "[Epoch 188/200] [Batch 36/44] [D loss: 0.005476] [G loss: -0.010618]\n",
      "[Epoch 188/200] [Batch 38/44] [D loss: 0.004174] [G loss: -0.010595]\n",
      "[Epoch 188/200] [Batch 40/44] [D loss: 0.005492] [G loss: -0.010621]\n",
      "[Epoch 188/200] [Batch 42/44] [D loss: 0.005147] [G loss: -0.010608]\n",
      "[Epoch 189/200] [Batch 0/44] [D loss: 0.005149] [G loss: -0.010623]\n",
      "[Epoch 189/200] [Batch 2/44] [D loss: 0.006961] [G loss: -0.010613]\n",
      "[Epoch 189/200] [Batch 4/44] [D loss: 0.005794] [G loss: -0.010615]\n",
      "[Epoch 189/200] [Batch 6/44] [D loss: 0.005255] [G loss: -0.010609]\n",
      "[Epoch 189/200] [Batch 8/44] [D loss: 0.006714] [G loss: -0.010636]\n",
      "[Epoch 189/200] [Batch 10/44] [D loss: 0.007536] [G loss: -0.010627]\n",
      "[Epoch 189/200] [Batch 12/44] [D loss: 0.005836] [G loss: -0.010609]\n",
      "[Epoch 189/200] [Batch 14/44] [D loss: 0.004241] [G loss: -0.010615]\n",
      "[Epoch 189/200] [Batch 16/44] [D loss: 0.004935] [G loss: -0.010615]\n",
      "[Epoch 189/200] [Batch 18/44] [D loss: 0.006961] [G loss: -0.010626]\n",
      "[Epoch 189/200] [Batch 20/44] [D loss: 0.006136] [G loss: -0.010612]\n",
      "[Epoch 189/200] [Batch 22/44] [D loss: 0.007177] [G loss: -0.010609]\n",
      "[Epoch 189/200] [Batch 24/44] [D loss: 0.005402] [G loss: -0.010606]\n",
      "[Epoch 189/200] [Batch 26/44] [D loss: 0.006593] [G loss: -0.010627]\n",
      "[Epoch 189/200] [Batch 28/44] [D loss: 0.004549] [G loss: -0.010602]\n",
      "[Epoch 189/200] [Batch 30/44] [D loss: 0.003582] [G loss: -0.010622]\n",
      "[Epoch 189/200] [Batch 32/44] [D loss: 0.007277] [G loss: -0.010619]\n",
      "[Epoch 189/200] [Batch 34/44] [D loss: 0.006597] [G loss: -0.010622]\n",
      "[Epoch 189/200] [Batch 36/44] [D loss: 0.007289] [G loss: -0.010615]\n",
      "[Epoch 189/200] [Batch 38/44] [D loss: 0.005587] [G loss: -0.010606]\n",
      "[Epoch 189/200] [Batch 40/44] [D loss: 0.004139] [G loss: -0.010602]\n",
      "[Epoch 189/200] [Batch 42/44] [D loss: 0.005331] [G loss: -0.010625]\n",
      "[Epoch 190/200] [Batch 0/44] [D loss: 0.005082] [G loss: -0.010620]\n",
      "[Epoch 190/200] [Batch 2/44] [D loss: 0.006583] [G loss: -0.010594]\n",
      "[Epoch 190/200] [Batch 4/44] [D loss: 0.006838] [G loss: -0.010607]\n",
      "[Epoch 190/200] [Batch 6/44] [D loss: 0.006199] [G loss: -0.010621]\n",
      "[Epoch 190/200] [Batch 8/44] [D loss: 0.006550] [G loss: -0.010616]\n",
      "[Epoch 190/200] [Batch 10/44] [D loss: 0.005930] [G loss: -0.010620]\n",
      "[Epoch 190/200] [Batch 12/44] [D loss: 0.001917] [G loss: -0.010620]\n",
      "[Epoch 190/200] [Batch 14/44] [D loss: 0.006714] [G loss: -0.010623]\n",
      "[Epoch 190/200] [Batch 16/44] [D loss: 0.002080] [G loss: -0.010646]\n",
      "[Epoch 190/200] [Batch 18/44] [D loss: 0.005942] [G loss: -0.010630]\n",
      "[Epoch 190/200] [Batch 20/44] [D loss: 0.004050] [G loss: -0.010624]\n",
      "[Epoch 190/200] [Batch 22/44] [D loss: 0.005784] [G loss: -0.010609]\n",
      "[Epoch 190/200] [Batch 24/44] [D loss: 0.004639] [G loss: -0.010621]\n",
      "[Epoch 190/200] [Batch 26/44] [D loss: 0.006458] [G loss: -0.010628]\n",
      "[Epoch 190/200] [Batch 28/44] [D loss: 0.003253] [G loss: -0.010632]\n",
      "[Epoch 190/200] [Batch 30/44] [D loss: 0.005495] [G loss: -0.010636]\n",
      "[Epoch 190/200] [Batch 32/44] [D loss: 0.005673] [G loss: -0.010596]\n",
      "[Epoch 190/200] [Batch 34/44] [D loss: 0.006995] [G loss: -0.010626]\n",
      "[Epoch 190/200] [Batch 36/44] [D loss: 0.003897] [G loss: -0.010638]\n",
      "[Epoch 190/200] [Batch 38/44] [D loss: 0.006128] [G loss: -0.010611]\n",
      "[Epoch 190/200] [Batch 40/44] [D loss: 0.006985] [G loss: -0.010633]\n",
      "[Epoch 190/200] [Batch 42/44] [D loss: 0.006858] [G loss: -0.010640]\n",
      "[Epoch 191/200] [Batch 0/44] [D loss: 0.006156] [G loss: -0.010615]\n",
      "[Epoch 191/200] [Batch 2/44] [D loss: 0.005485] [G loss: -0.010640]\n",
      "[Epoch 191/200] [Batch 4/44] [D loss: 0.005014] [G loss: -0.010582]\n",
      "[Epoch 191/200] [Batch 6/44] [D loss: 0.005259] [G loss: -0.010608]\n",
      "[Epoch 191/200] [Batch 8/44] [D loss: 0.006522] [G loss: -0.010608]\n",
      "[Epoch 191/200] [Batch 10/44] [D loss: 0.005425] [G loss: -0.010616]\n",
      "[Epoch 191/200] [Batch 12/44] [D loss: 0.004650] [G loss: -0.010620]\n",
      "[Epoch 191/200] [Batch 14/44] [D loss: 0.006834] [G loss: -0.010620]\n",
      "[Epoch 191/200] [Batch 16/44] [D loss: 0.006866] [G loss: -0.010624]\n",
      "[Epoch 191/200] [Batch 18/44] [D loss: 0.004332] [G loss: -0.010611]\n",
      "[Epoch 191/200] [Batch 20/44] [D loss: 0.006558] [G loss: -0.010600]\n",
      "[Epoch 191/200] [Batch 22/44] [D loss: 0.007153] [G loss: -0.010616]\n",
      "[Epoch 191/200] [Batch 24/44] [D loss: 0.003832] [G loss: -0.010620]\n",
      "[Epoch 191/200] [Batch 26/44] [D loss: 0.003477] [G loss: -0.010632]\n",
      "[Epoch 191/200] [Batch 28/44] [D loss: 0.007139] [G loss: -0.010615]\n",
      "[Epoch 191/200] [Batch 30/44] [D loss: 0.003204] [G loss: -0.010638]\n",
      "[Epoch 191/200] [Batch 32/44] [D loss: 0.006267] [G loss: -0.010608]\n",
      "[Epoch 191/200] [Batch 34/44] [D loss: 0.006720] [G loss: -0.010632]\n",
      "[Epoch 191/200] [Batch 36/44] [D loss: 0.006779] [G loss: -0.010615]\n",
      "[Epoch 191/200] [Batch 38/44] [D loss: 0.003917] [G loss: -0.010617]\n",
      "[Epoch 191/200] [Batch 40/44] [D loss: 0.004453] [G loss: -0.010622]\n",
      "[Epoch 191/200] [Batch 42/44] [D loss: 0.004953] [G loss: -0.010618]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 192/200] [Batch 0/44] [D loss: 0.004372] [G loss: -0.010600]\n",
      "[Epoch 192/200] [Batch 2/44] [D loss: 0.004078] [G loss: -0.010618]\n",
      "[Epoch 192/200] [Batch 4/44] [D loss: 0.006381] [G loss: -0.010621]\n",
      "[Epoch 192/200] [Batch 6/44] [D loss: 0.003643] [G loss: -0.010620]\n",
      "[Epoch 192/200] [Batch 8/44] [D loss: 0.007367] [G loss: -0.010618]\n",
      "[Epoch 192/200] [Batch 10/44] [D loss: 0.004528] [G loss: -0.010640]\n",
      "[Epoch 192/200] [Batch 12/44] [D loss: 0.006784] [G loss: -0.010628]\n",
      "[Epoch 192/200] [Batch 14/44] [D loss: 0.007370] [G loss: -0.010607]\n",
      "[Epoch 192/200] [Batch 16/44] [D loss: 0.006782] [G loss: -0.010606]\n",
      "[Epoch 192/200] [Batch 18/44] [D loss: 0.007283] [G loss: -0.010598]\n",
      "[Epoch 192/200] [Batch 20/44] [D loss: 0.004692] [G loss: -0.010614]\n",
      "[Epoch 192/200] [Batch 22/44] [D loss: 0.003889] [G loss: -0.010629]\n",
      "[Epoch 192/200] [Batch 24/44] [D loss: 0.005408] [G loss: -0.010622]\n",
      "[Epoch 192/200] [Batch 26/44] [D loss: 0.007214] [G loss: -0.010619]\n",
      "[Epoch 192/200] [Batch 28/44] [D loss: 0.006698] [G loss: -0.010635]\n",
      "[Epoch 192/200] [Batch 30/44] [D loss: 0.003381] [G loss: -0.010607]\n",
      "[Epoch 192/200] [Batch 32/44] [D loss: 0.004737] [G loss: -0.010622]\n",
      "[Epoch 192/200] [Batch 34/44] [D loss: 0.008368] [G loss: -0.010637]\n",
      "[Epoch 192/200] [Batch 36/44] [D loss: 0.005789] [G loss: -0.010587]\n",
      "[Epoch 192/200] [Batch 38/44] [D loss: 0.004475] [G loss: -0.010627]\n",
      "[Epoch 192/200] [Batch 40/44] [D loss: 0.006065] [G loss: -0.010602]\n",
      "[Epoch 192/200] [Batch 42/44] [D loss: 0.005008] [G loss: -0.010599]\n",
      "[Epoch 193/200] [Batch 0/44] [D loss: 0.006479] [G loss: -0.010600]\n",
      "[Epoch 193/200] [Batch 2/44] [D loss: 0.004388] [G loss: -0.010624]\n",
      "[Epoch 193/200] [Batch 4/44] [D loss: 0.006536] [G loss: -0.010598]\n",
      "[Epoch 193/200] [Batch 6/44] [D loss: 0.005479] [G loss: -0.010620]\n",
      "[Epoch 193/200] [Batch 8/44] [D loss: 0.004122] [G loss: -0.010625]\n",
      "[Epoch 193/200] [Batch 10/44] [D loss: 0.004423] [G loss: -0.010617]\n",
      "[Epoch 193/200] [Batch 12/44] [D loss: 0.003600] [G loss: -0.010618]\n",
      "[Epoch 193/200] [Batch 14/44] [D loss: 0.007072] [G loss: -0.010596]\n",
      "[Epoch 193/200] [Batch 16/44] [D loss: 0.004935] [G loss: -0.010628]\n",
      "[Epoch 193/200] [Batch 18/44] [D loss: 0.004341] [G loss: -0.010645]\n",
      "[Epoch 193/200] [Batch 20/44] [D loss: 0.005920] [G loss: -0.010608]\n",
      "[Epoch 193/200] [Batch 22/44] [D loss: 0.005681] [G loss: -0.010632]\n",
      "[Epoch 193/200] [Batch 24/44] [D loss: 0.004945] [G loss: -0.010604]\n",
      "[Epoch 193/200] [Batch 26/44] [D loss: 0.005637] [G loss: -0.010599]\n",
      "[Epoch 193/200] [Batch 28/44] [D loss: 0.006170] [G loss: -0.010625]\n",
      "[Epoch 193/200] [Batch 30/44] [D loss: 0.006504] [G loss: -0.010619]\n",
      "[Epoch 193/200] [Batch 32/44] [D loss: 0.006451] [G loss: -0.010607]\n",
      "[Epoch 193/200] [Batch 34/44] [D loss: 0.006576] [G loss: -0.010622]\n",
      "[Epoch 193/200] [Batch 36/44] [D loss: 0.005686] [G loss: -0.010608]\n",
      "[Epoch 193/200] [Batch 38/44] [D loss: 0.006821] [G loss: -0.010617]\n",
      "[Epoch 193/200] [Batch 40/44] [D loss: 0.004442] [G loss: -0.010606]\n",
      "[Epoch 193/200] [Batch 42/44] [D loss: 0.004021] [G loss: -0.010632]\n",
      "[Epoch 194/200] [Batch 0/44] [D loss: 0.006777] [G loss: -0.010627]\n",
      "[Epoch 194/200] [Batch 2/44] [D loss: 0.006549] [G loss: -0.010606]\n",
      "[Epoch 194/200] [Batch 4/44] [D loss: 0.004823] [G loss: -0.010618]\n",
      "[Epoch 194/200] [Batch 6/44] [D loss: 0.006224] [G loss: -0.010593]\n",
      "[Epoch 194/200] [Batch 8/44] [D loss: 0.005583] [G loss: -0.010616]\n",
      "[Epoch 194/200] [Batch 10/44] [D loss: 0.006157] [G loss: -0.010614]\n",
      "[Epoch 194/200] [Batch 12/44] [D loss: 0.004896] [G loss: -0.010605]\n",
      "[Epoch 194/200] [Batch 14/44] [D loss: 0.002887] [G loss: -0.010619]\n",
      "[Epoch 194/200] [Batch 16/44] [D loss: 0.006560] [G loss: -0.010603]\n",
      "[Epoch 194/200] [Batch 18/44] [D loss: 0.004631] [G loss: -0.010601]\n",
      "[Epoch 194/200] [Batch 20/44] [D loss: 0.007044] [G loss: -0.010589]\n",
      "[Epoch 194/200] [Batch 22/44] [D loss: 0.003998] [G loss: -0.010611]\n",
      "[Epoch 194/200] [Batch 24/44] [D loss: 0.005695] [G loss: -0.010638]\n",
      "[Epoch 194/200] [Batch 26/44] [D loss: 0.005535] [G loss: -0.010602]\n",
      "[Epoch 194/200] [Batch 28/44] [D loss: 0.004987] [G loss: -0.010613]\n",
      "[Epoch 194/200] [Batch 30/44] [D loss: 0.004802] [G loss: -0.010648]\n",
      "[Epoch 194/200] [Batch 32/44] [D loss: 0.006656] [G loss: -0.010600]\n",
      "[Epoch 194/200] [Batch 34/44] [D loss: 0.004783] [G loss: -0.010629]\n",
      "[Epoch 194/200] [Batch 36/44] [D loss: 0.004537] [G loss: -0.010615]\n",
      "[Epoch 194/200] [Batch 38/44] [D loss: 0.005262] [G loss: -0.010619]\n",
      "[Epoch 194/200] [Batch 40/44] [D loss: 0.005003] [G loss: -0.010595]\n",
      "[Epoch 194/200] [Batch 42/44] [D loss: 0.007272] [G loss: -0.010608]\n",
      "[Epoch 195/200] [Batch 0/44] [D loss: 0.003837] [G loss: -0.010626]\n",
      "[Epoch 195/200] [Batch 2/44] [D loss: 0.003678] [G loss: -0.010607]\n",
      "[Epoch 195/200] [Batch 4/44] [D loss: 0.005796] [G loss: -0.010626]\n",
      "[Epoch 195/200] [Batch 6/44] [D loss: 0.006518] [G loss: -0.010607]\n",
      "[Epoch 195/200] [Batch 8/44] [D loss: 0.006916] [G loss: -0.010634]\n",
      "[Epoch 195/200] [Batch 10/44] [D loss: 0.005017] [G loss: -0.010638]\n",
      "[Epoch 195/200] [Batch 12/44] [D loss: 0.005899] [G loss: -0.010634]\n",
      "[Epoch 195/200] [Batch 14/44] [D loss: 0.006412] [G loss: -0.010637]\n",
      "[Epoch 195/200] [Batch 16/44] [D loss: 0.006958] [G loss: -0.010614]\n",
      "[Epoch 195/200] [Batch 18/44] [D loss: 0.005250] [G loss: -0.010609]\n",
      "[Epoch 195/200] [Batch 20/44] [D loss: 0.003637] [G loss: -0.010628]\n",
      "[Epoch 195/200] [Batch 22/44] [D loss: 0.006957] [G loss: -0.010632]\n",
      "[Epoch 195/200] [Batch 24/44] [D loss: 0.003759] [G loss: -0.010616]\n",
      "[Epoch 195/200] [Batch 26/44] [D loss: 0.005623] [G loss: -0.010621]\n",
      "[Epoch 195/200] [Batch 28/44] [D loss: 0.004931] [G loss: -0.010613]\n",
      "[Epoch 195/200] [Batch 30/44] [D loss: 0.007297] [G loss: -0.010599]\n",
      "[Epoch 195/200] [Batch 32/44] [D loss: 0.002981] [G loss: -0.010627]\n",
      "[Epoch 195/200] [Batch 34/44] [D loss: 0.004852] [G loss: -0.010619]\n",
      "[Epoch 195/200] [Batch 36/44] [D loss: 0.004946] [G loss: -0.010622]\n",
      "[Epoch 195/200] [Batch 38/44] [D loss: 0.005401] [G loss: -0.010617]\n",
      "[Epoch 195/200] [Batch 40/44] [D loss: 0.006664] [G loss: -0.010635]\n",
      "[Epoch 195/200] [Batch 42/44] [D loss: 0.005282] [G loss: -0.010616]\n",
      "[Epoch 196/200] [Batch 0/44] [D loss: 0.002719] [G loss: -0.010637]\n",
      "[Epoch 196/200] [Batch 2/44] [D loss: 0.003707] [G loss: -0.010611]\n",
      "[Epoch 196/200] [Batch 4/44] [D loss: 0.004502] [G loss: -0.010625]\n",
      "[Epoch 196/200] [Batch 6/44] [D loss: 0.004012] [G loss: -0.010621]\n",
      "[Epoch 196/200] [Batch 8/44] [D loss: 0.004953] [G loss: -0.010610]\n",
      "[Epoch 196/200] [Batch 10/44] [D loss: 0.005041] [G loss: -0.010630]\n",
      "[Epoch 196/200] [Batch 12/44] [D loss: 0.008230] [G loss: -0.010598]\n",
      "[Epoch 196/200] [Batch 14/44] [D loss: 0.005025] [G loss: -0.010621]\n",
      "[Epoch 196/200] [Batch 16/44] [D loss: 0.005252] [G loss: -0.010600]\n",
      "[Epoch 196/200] [Batch 18/44] [D loss: 0.003229] [G loss: -0.010622]\n",
      "[Epoch 196/200] [Batch 20/44] [D loss: 0.004866] [G loss: -0.010606]\n",
      "[Epoch 196/200] [Batch 22/44] [D loss: 0.007189] [G loss: -0.010610]\n",
      "[Epoch 196/200] [Batch 24/44] [D loss: 0.006195] [G loss: -0.010600]\n",
      "[Epoch 196/200] [Batch 26/44] [D loss: 0.005900] [G loss: -0.010631]\n",
      "[Epoch 196/200] [Batch 28/44] [D loss: 0.007425] [G loss: -0.010622]\n",
      "[Epoch 196/200] [Batch 30/44] [D loss: 0.005241] [G loss: -0.010605]\n",
      "[Epoch 196/200] [Batch 32/44] [D loss: 0.006418] [G loss: -0.010628]\n",
      "[Epoch 196/200] [Batch 34/44] [D loss: 0.004086] [G loss: -0.010615]\n",
      "[Epoch 196/200] [Batch 36/44] [D loss: 0.004246] [G loss: -0.010611]\n",
      "[Epoch 196/200] [Batch 38/44] [D loss: 0.005354] [G loss: -0.010589]\n",
      "[Epoch 196/200] [Batch 40/44] [D loss: 0.006102] [G loss: -0.010639]\n",
      "[Epoch 196/200] [Batch 42/44] [D loss: 0.004801] [G loss: -0.010616]\n",
      "[Epoch 197/200] [Batch 0/44] [D loss: 0.005204] [G loss: -0.010636]\n",
      "[Epoch 197/200] [Batch 2/44] [D loss: 0.004634] [G loss: -0.010623]\n",
      "[Epoch 197/200] [Batch 4/44] [D loss: 0.005540] [G loss: -0.010651]\n",
      "[Epoch 197/200] [Batch 6/44] [D loss: 0.005224] [G loss: -0.010640]\n",
      "[Epoch 197/200] [Batch 8/44] [D loss: 0.003783] [G loss: -0.010614]\n",
      "[Epoch 197/200] [Batch 10/44] [D loss: 0.004432] [G loss: -0.010637]\n",
      "[Epoch 197/200] [Batch 12/44] [D loss: 0.004637] [G loss: -0.010624]\n",
      "[Epoch 197/200] [Batch 14/44] [D loss: 0.005423] [G loss: -0.010634]\n",
      "[Epoch 197/200] [Batch 16/44] [D loss: 0.004841] [G loss: -0.010615]\n",
      "[Epoch 197/200] [Batch 18/44] [D loss: 0.006115] [G loss: -0.010635]\n",
      "[Epoch 197/200] [Batch 20/44] [D loss: 0.005704] [G loss: -0.010617]\n",
      "[Epoch 197/200] [Batch 22/44] [D loss: 0.006037] [G loss: -0.010626]\n",
      "[Epoch 197/200] [Batch 24/44] [D loss: 0.005345] [G loss: -0.010623]\n",
      "[Epoch 197/200] [Batch 26/44] [D loss: 0.004779] [G loss: -0.010630]\n",
      "[Epoch 197/200] [Batch 28/44] [D loss: 0.005492] [G loss: -0.010627]\n",
      "[Epoch 197/200] [Batch 30/44] [D loss: 0.006334] [G loss: -0.010603]\n",
      "[Epoch 197/200] [Batch 32/44] [D loss: 0.004547] [G loss: -0.010614]\n",
      "[Epoch 197/200] [Batch 34/44] [D loss: 0.006544] [G loss: -0.010614]\n",
      "[Epoch 197/200] [Batch 36/44] [D loss: 0.007012] [G loss: -0.010632]\n",
      "[Epoch 197/200] [Batch 38/44] [D loss: 0.006287] [G loss: -0.010622]\n",
      "[Epoch 197/200] [Batch 40/44] [D loss: 0.004438] [G loss: -0.010614]\n",
      "[Epoch 197/200] [Batch 42/44] [D loss: 0.006230] [G loss: -0.010605]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 198/200] [Batch 0/44] [D loss: 0.005831] [G loss: -0.010615]\n",
      "[Epoch 198/200] [Batch 2/44] [D loss: 0.007165] [G loss: -0.010607]\n",
      "[Epoch 198/200] [Batch 4/44] [D loss: 0.004847] [G loss: -0.010605]\n",
      "[Epoch 198/200] [Batch 6/44] [D loss: 0.006707] [G loss: -0.010630]\n",
      "[Epoch 198/200] [Batch 8/44] [D loss: 0.004408] [G loss: -0.010595]\n",
      "[Epoch 198/200] [Batch 10/44] [D loss: 0.005707] [G loss: -0.010624]\n",
      "[Epoch 198/200] [Batch 12/44] [D loss: 0.004157] [G loss: -0.010621]\n",
      "[Epoch 198/200] [Batch 14/44] [D loss: 0.007536] [G loss: -0.010622]\n",
      "[Epoch 198/200] [Batch 16/44] [D loss: 0.003958] [G loss: -0.010628]\n",
      "[Epoch 198/200] [Batch 18/44] [D loss: 0.005873] [G loss: -0.010602]\n",
      "[Epoch 198/200] [Batch 20/44] [D loss: 0.006679] [G loss: -0.010640]\n",
      "[Epoch 198/200] [Batch 22/44] [D loss: 0.005788] [G loss: -0.010634]\n",
      "[Epoch 198/200] [Batch 24/44] [D loss: 0.005695] [G loss: -0.010613]\n",
      "[Epoch 198/200] [Batch 26/44] [D loss: 0.005146] [G loss: -0.010627]\n",
      "[Epoch 198/200] [Batch 28/44] [D loss: 0.004180] [G loss: -0.010610]\n",
      "[Epoch 198/200] [Batch 30/44] [D loss: 0.005327] [G loss: -0.010610]\n",
      "[Epoch 198/200] [Batch 32/44] [D loss: 0.005600] [G loss: -0.010624]\n",
      "[Epoch 198/200] [Batch 34/44] [D loss: 0.005067] [G loss: -0.010628]\n",
      "[Epoch 198/200] [Batch 36/44] [D loss: 0.005320] [G loss: -0.010632]\n",
      "[Epoch 198/200] [Batch 38/44] [D loss: 0.005349] [G loss: -0.010621]\n",
      "[Epoch 198/200] [Batch 40/44] [D loss: 0.003692] [G loss: -0.010598]\n",
      "[Epoch 198/200] [Batch 42/44] [D loss: 0.002205] [G loss: -0.010592]\n",
      "[Epoch 199/200] [Batch 0/44] [D loss: 0.005803] [G loss: -0.010618]\n",
      "[Epoch 199/200] [Batch 2/44] [D loss: 0.005814] [G loss: -0.010597]\n",
      "[Epoch 199/200] [Batch 4/44] [D loss: 0.004114] [G loss: -0.010614]\n",
      "[Epoch 199/200] [Batch 6/44] [D loss: 0.005946] [G loss: -0.010629]\n",
      "[Epoch 199/200] [Batch 8/44] [D loss: 0.005004] [G loss: -0.010609]\n",
      "[Epoch 199/200] [Batch 10/44] [D loss: 0.005546] [G loss: -0.010622]\n",
      "[Epoch 199/200] [Batch 12/44] [D loss: 0.004778] [G loss: -0.010603]\n",
      "[Epoch 199/200] [Batch 14/44] [D loss: 0.004738] [G loss: -0.010612]\n",
      "[Epoch 199/200] [Batch 16/44] [D loss: 0.006106] [G loss: -0.010610]\n",
      "[Epoch 199/200] [Batch 18/44] [D loss: 0.004041] [G loss: -0.010626]\n",
      "[Epoch 199/200] [Batch 20/44] [D loss: 0.004540] [G loss: -0.010626]\n",
      "[Epoch 199/200] [Batch 22/44] [D loss: 0.005093] [G loss: -0.010630]\n",
      "[Epoch 199/200] [Batch 24/44] [D loss: 0.006876] [G loss: -0.010602]\n",
      "[Epoch 199/200] [Batch 26/44] [D loss: 0.003700] [G loss: -0.010608]\n",
      "[Epoch 199/200] [Batch 28/44] [D loss: 0.005985] [G loss: -0.010627]\n",
      "[Epoch 199/200] [Batch 30/44] [D loss: 0.003568] [G loss: -0.010624]\n",
      "[Epoch 199/200] [Batch 32/44] [D loss: 0.006337] [G loss: -0.010626]\n",
      "[Epoch 199/200] [Batch 34/44] [D loss: 0.005887] [G loss: -0.010626]\n",
      "[Epoch 199/200] [Batch 36/44] [D loss: 0.005162] [G loss: -0.010628]\n",
      "[Epoch 199/200] [Batch 38/44] [D loss: 0.005022] [G loss: -0.010596]\n",
      "[Epoch 199/200] [Batch 40/44] [D loss: 0.006776] [G loss: -0.010620]\n",
      "[Epoch 199/200] [Batch 42/44] [D loss: 0.006887] [G loss: -0.010619]\n"
     ]
    }
   ],
   "source": [
    "generator = Generator().cuda()\n",
    "discriminator = Discriminator().cuda()\n",
    "\n",
    "def train_gan(dataloader):\n",
    "    batches_done = 0\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        for i, imgs in enumerate(dataloader):\n",
    "\n",
    "            real_imgs = Variable(imgs.type(Tensor))\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            optimizer_D.zero_grad()\n",
    "\n",
    "            # Sample noise as generator input\n",
    "            z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], latent_dim))))\n",
    "\n",
    "            # Generate a batch of images\n",
    "            fake_imgs = generator(z).detach()\n",
    "            # Adversarial loss\n",
    "            loss_D = -torch.mean(discriminator(real_imgs)) + torch.mean(discriminator(fake_imgs))\n",
    "\n",
    "            loss_D.backward()\n",
    "            optimizer_D.step()\n",
    "\n",
    "            # Clip weights of discriminator\n",
    "            for p in discriminator.parameters():\n",
    "                p.data.clamp_(-clip_value, clip_value)\n",
    "\n",
    "            # Train the generator every n_critic iterations\n",
    "            if i % n_critic == 0:\n",
    "\n",
    "                # -----------------\n",
    "                #  Train Generator\n",
    "                # -----------------\n",
    "\n",
    "                optimizer_G.zero_grad()\n",
    "\n",
    "                # Generate a batch of images\n",
    "                gen_imgs = generator(z)\n",
    "                # Adversarial loss\n",
    "                loss_G = -torch.mean(discriminator(gen_imgs))\n",
    "\n",
    "                loss_G.backward()\n",
    "                optimizer_G.step()\n",
    "\n",
    "                print(\n",
    "                    \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "                    % (epoch, n_epochs, batches_done % len(dataloader), len(dataloader), loss_D.item(), loss_G.item())\n",
    "                )\n",
    "\n",
    "            if batches_done % sample_interval == 0:\n",
    "                save_image(gen_imgs.data[:25], \"images/%d.png\" % batches_done, nrow=5, normalize=True)\n",
    "            batches_done += 1\n",
    "            \n",
    "train_gan(dataloader3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
